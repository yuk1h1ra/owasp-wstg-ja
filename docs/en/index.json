[
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/0-foreword/",
	"title": "Foreword",
	"tags": [],
	"description": "",
	"content": "Foreword by Eoin Keary The problem of insecure software is perhaps the most important technical challenge of our time. The dramatic rise of web applications enabling business, social networking etc has only compounded the requirements to establish a robust approach to writing and securing our Internet, Web Applications and Data.\nAt the Open Web Application Security Project® (OWASP®), we\u0026rsquo;re trying to make the world a place where insecure software is the anomaly, not the norm. The OWASP Testing Guide has an important role to play in solving this serious issue. It is vitally important that our approach to testing software for security issues is based on the principles of engineering and science. We need a consistent, repeatable and defined approach to testing web applications. A world without some minimal standards in terms of engineering and technology is a world in chaos.\nIt goes without saying that you can\u0026rsquo;t build a secure application without performing security testing on it. Testing is part of a wider approach to build a secure system. Many software development organizations do not include security testing as part of their standard software development process. What is even worse is that many security vendors deliver testing with varying degrees of quality and rigor.\nSecurity testing, by itself, isn\u0026rsquo;t a particularly good stand alone measure of how secure an application is, because there are an infinite number of ways that an attacker might be able to make an application break, and it simply isn\u0026rsquo;t possible to test them all. We can\u0026rsquo;t hack ourselves secure as we only have a limited time to test and defend where an attacker does not have such constraints.\nIn conjunction with other OWASP projects such as the Code Review Guide, the Development Guide and tools such as OWASP ZAP, this is a great start towards building and maintaining secure applications. This Testing Guide will show you how to verify the security of your running application. I highly recommend using these guides as part of your application security initiatives.\nWhy OWASP? Creating a guide like this is a huge undertaking, requiring the expertise of hundreds of people around the world. There are many different ways to test for security flaws and this guide captures the consensus of the leading experts on how to perform this testing quickly, accurately, and efficiently. OWASP gives like minded security folks the ability to work together and form a leading practice approach to a security problem.\nThe importance of having this guide available in a completely free and open way is important for the foundation\u0026rsquo;s mission. It gives anyone the ability to understand the techniques used to test for common security issues. Security should not be a black art or closed secret that only a few can practice. It should be open to all and not exclusive to security practitioners but also QA, Developers and Technical Managers. The project to build this guide keeps this expertise in the hands of the people who need it - you, me and anyone that is involved in building software.\nThis guide must make its way into the hands of developers and software testers. There are not nearly enough application security experts in the world to make any significant dent in the overall problem. The initial responsibility for application security must fall on the shoulders of the developers because they write the code. It shouldn\u0026rsquo;t be a surprise that developers aren\u0026rsquo;t producing secure code if they\u0026rsquo;re not testing for it or consider the types of bugs which introduce vulnerability.\nKeeping this information up to date is a critical aspect of this guide project. By adopting the wiki approach, the OWASP community can evolve and expand the information in this guide to keep pace with the fast moving application security threat landscape.\nThis Guide is a great testament to the passion and energy our members and project volunteers have for this subject. It shall certainly help to change the world a line of code at a time.\nTailoring and Prioritizing You should adopt this guide in your organization. You may need to tailor the information to match your organization\u0026rsquo;s technologies, processes, and organizational structure.\nIn general there are several different roles within organizations that may use this guide:\n Developers should use this guide to ensure that they are producing secure code. These tests should be a part of normal code and unit testing procedures. Software testers and QA should use this guide to expand the set of test cases they apply to applications. Catching these vulnerabilities early saves considerable time and effort later. Security specialists should use this guide in combination with other techniques as one way to verify that no security holes have been missed in an application. Project Managers should consider the reason this guide exists and that security issues are manifested via bugs in code and design.  The most important thing to remember when performing security testing is to continuously re-prioritize. There are an infinite number of possible ways that an application could fail, and organizations always have limited testing time and resources. Be sure time and resources are spent wisely. Try to focus on the security holes that are a real risk to your business. Try to contextualize risk in terms of the application and its use cases.\nThis guide is best viewed as a set of techniques that you can use to find different types of security holes. But not all the techniques are equally important. Try to avoid using the guide as a checklist, new vulnerabilities are always manifesting and no guide can be an exhaustive list of \u0026ldquo;things to test for\u0026rdquo;, but rather a great place to start.\nThe Role of Automated Tools There are a number of companies selling automated security analysis and testing tools. Remember the limitations of these tools so that you can use them for what they\u0026rsquo;re good at. As Michael Howard put it at the 2006 OWASP AppSec Conference in Seattle, \u0026ldquo;Tools do not make software secure! They help scale the process and help enforce policy.\u0026rdquo;\nMost importantly, these tools are generic - meaning that they are not designed for your custom code, but for applications in general. That means that while they can find some generic problems, they do not have enough knowledge of your application to allow them to detect most flaws. In my experience, the most serious security issues are the ones that are not generic, but deeply intertwined in your business logic and custom application design.\nThese tools can also be very useful, since they do find lots of potential issues. While running the tools doesn\u0026rsquo;t take much time, each one of the potential problems takes time to investigate and verify. If the goal is to find and eliminate the most serious flaws as quickly as possible, consider whether your time is best spent with automated tools or with the techniques described in this guide. Still, these tools are certainly part of a well-balanced application security program. Used wisely, they can support your overall processes to produce more secure code.\nCall to Action If you\u0026rsquo;re building, designing or testing software, I strongly encourage you to get familiar with the security testing guidance in this document. It is a great road map for testing the most common issues that applications are facing today, but it is not exhaustive. If you find errors, please add a note to the discussion page or make the change yourself. You\u0026rsquo;ll be helping thousands of others who use this guide.\nPlease consider joining us as an individual or corporate member so that we can continue to produce materials like this testing guide and all the other great projects at OWASP.\nThank you to all the past and future contributors to this guide, your work will help to make applications worldwide more secure.\n\u0026ndash;Eoin Keary, OWASP Board Member, April 19, 2013\nOpen Web Application Security Project and OWASP are registered trademarks of the OWASP Foundation, Inc.\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/1-frontispiece/",
	"title": "Frontispiece",
	"tags": [],
	"description": "",
	"content": "Frontispiece Welcome  As we focus on incremental improvement, this release introduces numerous updates. We\u0026rsquo;ve standardized scenario formats to create a better reading experience, added objectives for each testing scenario, merged sections, and added new scenarios on some modern testing topics.\n— Rick Mitchell\n OWASP thanks the many authors, reviewers, and editors for their hard work in bringing this guide to where it is today. If you have any comments or suggestions on the Testing Guide, please feel free to open an Issue or submit a fix/contribution via Pull Request to our GitHub repository.\nCopyright and Licensee Copyright (c) 2020 The OWASP Foundation.\nThis document is released under the Creative Commons 4.0 License. Please read and understand the license and copyright conditions.\nLeaders  Elie Saad Rick Mitchell  Core Team  Rejah Rehim Victoria Drake  Authors  Aaron Williams Alessia Michela Di Campi Elie Saad Ismael Goncalves Janos Zold Jeremy Bonghwan Choi Joel Espunya Manh Pham Tien Mark Clayton Or Asaf rbsec Rick Mitchell Rishu Ranjan Rubal Jain Samuele Casarin Stefano Calzavara Tal Argoni Victoria Drake Phu Nguyen (Tony)  Graphic Designers  Hugo Costa Jishnu Vijayan C K Muhammed Anees Ramzi Fazah  Reviewers or Editors  Abhi M Balakrishnan Asharaf Ali Elie Saad Eoin Murphy Francisco Bustos frozensolid Hsiang-Chih Hsu Jeremy Bonghwan Choi Lukasz Lubczynski Miguel Arevalo Najam Ul Saqib Nikoleta Misheva Patrick Santos Rejah Rehim Rick Mitchell Roman Mueller Thomas Lim Tom Bowyer Victoria Drake  Trademarks  Java, Java Web Server, and JSP are registered trademarks of Sun Microsystems, Inc. Merriam-Webster is a trademark of Merriam-Webster, Inc. Microsoft is a registered trademark of Microsoft Corporation. Octave is a service mark of Carnegie Mellon University. Open Web Application Security Project and OWASP are registered trademarks of the OWASP Foundation, Inc. VeriSign and Thawte are registered trademarks of VeriSign, Inc. Visa is a registered trademark of VISA USA.  All other products and company names may be trademarks of their respective owners. Use of a term in this document should not be regarded as affecting the validity of any trademark or service mark.\nContacting OWASP Contact details for the OWASP Foundation are available online. If you have a question concerning a particular project, we strongly recommend using the Google Group for that project. Many questions can also be answered by searching the OWASP web site, so please check there first.\nFollow Us \n\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/2-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction The OWASP Testing Project The OWASP Testing Project has been in development for many years. The aim of the project is to help people understand the what, why, when, where, and how of testing web applications. The project has delivered a complete testing framework, not merely a simple checklist or prescription of issues that should be addressed. Readers can use this framework as a template to build their own testing programs or to qualify other people’s processes. The Testing Guide describes in detail both the general testing framework and the techniques required to implement the framework in practice.\nWriting the Testing Guide has proven to be a difficult task. It was a challenge to obtain consensus and develop content that allowed people to apply the concepts described in the guide, while also enabling them to work in their own environment and culture. It was also a challenge to change the focus of web application testing from penetration testing to testing integrated in the software development life cycle.\nHowever, the group is very satisfied with the results of the project. Many industry experts and security professionals, some of whom are responsible for software security at some of the largest companies in the world, are validating the testing framework. This framework helps organizations test their web applications in order to build reliable and secure software. The framework does not simply highlight areas of weakness, although that is certainly a by-product of many of the OWASP guides and checklists. As such, hard decisions had to be made about the appropriateness of certain testing techniques and technologies. The group fully understands that not everyone will agree with all of these decisions. However, OWASP is able to take the high ground and change culture over time through awareness and education, based on consensus and experience.\nThe rest of this guide is organized as follows: this introduction covers the pre-requisites of testing web applications and the scope of testing. It also covers the principles of successful testing and testing techniques, best practices for reporting, and business cases for security testing. Chapter 3 presents the OWASP Testing Framework and explains its techniques and tasks in relation to the various phases of the software development life cycle. Chapter 4 covers how to test for specific vulnerabilities (e.g., SQL Injection) by code inspection and penetration testing.\nMeasuring Security: the Economics of Insecure Software A basic tenet of software engineering is summed up in a quote from Controlling Software Projects: Management, Measurement, and Estimates by Tom DeMarco:\n You can\u0026rsquo;t control what you can\u0026rsquo;t measure.\n Security testing is no different. Unfortunately, measuring security is a notoriously difficult process.\nOne aspect that should be emphasized is that security measurements are about both the specific technical issues (e.g., how prevalent a certain vulnerability is) and how these issues affect the economics of software. Most technical people will at least understand the basic issues, or they may have a deeper understanding of the vulnerabilities. Sadly, few are able to translate that technical knowledge into monetary terms and quantify the potential cost of vulnerabilities to the application owner\u0026rsquo;s business. Until this happens, CIOs will not be able to develop an accurate return on security investment and, subsequently, assign appropriate budgets for software security.\nWhile estimating the cost of insecure software may appear a daunting task, there has been a significant amount of work in this direction. In 2018 the Consortium for IT Software Quality summarized:\n \u0026hellip;the cost of poor quality software in the US in 2018 is approximately $2.84 trillion\u0026hellip;\n The framework described in this document encourages people to measure security throughout the entire development process. They can then relate the cost of insecure software to the impact it has on the business, and consequently develop appropriate business processes, and assign resources to manage the risk. Remember that measuring and testing web applications is even more critical than for other software, since web applications are exposed to millions of users through the Internet.\nWhat is Testing? Many things need to be tested during the development life cycle of a web application, but what does testing actually mean? The Oxford Dictionary of English defines \u0026ldquo;test\u0026rdquo; as:\n test (noun): a procedure intended to establish the quality, performance, or reliability of something, especially before it is taken into widespread use.\n For the purposes of this document, testing is a process of comparing the state of a system or application against a set of criteria. In the security industry, people frequently test against a set of mental criteria that are neither well defined nor complete. As a result of this, many outsiders regard security testing as a black art. The aim of this document is to change that perception, and to make it easier for people without in-depth security knowledge to make a difference in testing.\nWhy Perform Testing? This document is designed to help organizations understand what comprises a testing program, and to help them identify the steps that need to be undertaken to build and operate a modern web application testing program. The guide gives a broad view of the elements required to make a comprehensive web application security program. This guide can be used as a reference and as a methodology to help determine the gap between existing practices and industry best practices. This guide allows organizations to compare themselves against industry peers, to understand the magnitude of resources required to test and maintain software, or to prepare for an audit. This chapter does not go into the technical details of how to test an application, as the intent is to provide a typical security organizational framework. The technical details about how to test an application, as part of a penetration test or code review, will be covered in the remaining parts of this document.\nWhen to Test? Most people today don’t test software until it has already been created and is in the deployment phase of its life cycle (i.e., code has been created and instantiated into a working web application). This is generally a very ineffective and cost-prohibitive practice. One of the best methods to prevent security bugs from appearing in production applications is to improve the Software Development Life Cycle (SDLC) by including security in each of its phases. An SDLC is a structure imposed on the development of software artifacts. If an SDLC is not currently being used in your environment, it is time to pick one! The following figure shows a generic SDLC model as well as the (estimated) increasing cost of fixing security bugs in such a model.\nFigure 2-1: Generic SDLC Model\nCompanies should inspect their overall SDLC to ensure that security is an integral part of the development process. SDLCs should include security tests to ensure security is adequately covered and controls are effective throughout the development process.\nWhat to Test? It can be helpful to think of software development as a combination of people, process, and technology. If these are the factors that \u0026ldquo;create\u0026rdquo; software, then it is logical that these are the factors that must be tested. Today most people generally test the technology or the software itself.\nAn effective testing program should have components that test the following:\n People – to ensure that there is adequate education and awareness; Process – to ensure that there are adequate policies and standards and that people know how to follow these policies; Technology – to ensure that the process has been effective in its implementation.  Unless a holistic approach is adopted, testing just the technical implementation of an application will not uncover management or operational vulnerabilities that could be present. By testing the people, policies, and processes, an organization can catch issues that would later manifest themselves into defects in the technology, thus eradicating bugs early and identifying the root causes of defects. Likewise, testing only some of the technical issues that can be present in a system will result in an incomplete and inaccurate security posture assessment.\nDenis Verdon, Head of Information Security at Fidelity National Financial, presented an excellent analogy for this misconception at the OWASP AppSec 2004 Conference in New York:\n If cars were built like applications \u0026hellip; safety tests would assume frontal impact only. Cars would not be roll tested, or tested for stability in emergency maneuvers, brake effectiveness, side impact, and resistance to theft.\n How To Reference WSTG Scenarios Each scenario has an identifier in the format WSTG-\u0026lt;category\u0026gt;-\u0026lt;number\u0026gt;, where: \u0026lsquo;category\u0026rsquo; is a 4 character upper case string that identifies the type of test or weakness, and \u0026lsquo;number\u0026rsquo; is a zero-padded numeric value from 01 to 99. For example:WSTG-INFO-02 is the second Information Gathering test.\nThe identifiers may change between versions therefore it is preferable that other documents, reports, or tools use the format: WSTG-\u0026lt;version\u0026gt;-\u0026lt;category\u0026gt;-\u0026lt;number\u0026gt;, where: \u0026lsquo;version\u0026rsquo; is the version tag with punctuation removed. For example: WSTG-v42-INFO-02 would be understood to mean specifically the second Information Gathering test from version 4.2.\nIf identifiers are used without including the \u0026lt;version\u0026gt; element then they should be assumed to refer to the latest Web Security Testing Guide content. Obviously as the guide grows and changes this becomes problematic, which is why writers or developers should include the version element.\nLinking Linking to Web Security Testing Guide scenarios should be done using versioned links not stable or latest which will definitely change with time. However, it is the project team\u0026rsquo;s intention that versioned links not change. For example: https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/01-Information_Gathering/02-Fingerprint_Web_Server.html. Note: the v42 element refers to version 4.2.\nFeedback and Comments As with all OWASP projects, we welcome comments and feedback. We especially like to know that our work is being used and that it is effective and accurate.\nPrinciples of Testing There are some common misconceptions when developing a testing methodology to find security bugs in software. This chapter covers some of the basic principles that professionals should take into account when performing security tests on software.\nThere is No Silver Bullet While it is tempting to think that a security scanner or application firewall will provide many defenses against attack or identify a multitude of problems, in reality there is no silver bullet to the problem of insecure software. Application security assessment software, while useful as a first pass to find low-hanging fruit, is generally immature and ineffective at in-depth assessment or providing adequate test coverage. Remember that security is a process and not a product.\nThink Strategically, Not Tactically Security professionals have come to realize the fallacy of the patch-and-penetrate model that was pervasive in information security during the 1990’s. The patch-and-penetrate model involves fixing a reported bug, but without proper investigation of the root cause. This model is usually associated with the window of vulnerability, also referred to as window of exposure, shown in the figure below. The evolution of vulnerabilities in common software used worldwide has shown the ineffectiveness of this model. For more information about windows of exposure, see Schneier on Security.\nVulnerability studies such as Symantec\u0026rsquo;s Internet Security Threat Report have shown that with the reaction time of attackers worldwide, the typical window of vulnerability does not provide enough time for patch installation, since the time between a vulnerability being uncovered and an automated attack against it being developed and released is decreasing every year.\nThere are several incorrect assumptions in the patch-and-penetrate model. Many users believe that patches interfere with normal operations or might break existing applications. It is also incorrect to assume that all users are aware of newly released patches. Consequently not all users of a product will apply patches, either because they think patching may interfere with how the software works, or because they lack knowledge about the existence of the patch.\nFigure 2-2: Window of Vulnerability\nIt is essential to build security into the Software Development Life Cycle (SDLC) to prevent reoccurring security problems within an application. Developers can build security into the SDLC by developing standards, policies, and guidelines that fit and work within the development methodology. Threat modeling and other techniques should be used to help assign appropriate resources to those parts of a system that are most at risk.\nThe SDLC is King The SDLC is a process that is well-known to developers. By integrating security into each phase of the SDLC, it allows for a holistic approach to application security that leverages the procedures already in place within the organization. Be aware that while the names of the various phases may change depending on the SDLC model used by an organization, each conceptual phase of the archetype SDLC will be used to develop the application (i.e., define, design, develop, deploy, maintain). Each phase has security considerations that should become part of the existing process, to ensure a cost-effective and comprehensive security program.\nThere are several secure SDLC frameworks in existence that provide both descriptive and prescriptive advice. Whether a person takes descriptive or prescriptive advice depends on the maturity of the SDLC process. Essentially, prescriptive advice shows how the secure SDLC should work, and descriptive advice shows how it is used in the real world. Both have their place. For example, if you don\u0026rsquo;t know where to start, a prescriptive framework can provide a menu of potential security controls that can be applied within the SDLC. Descriptive advice can then help drive the decision process by presenting what has worked well for other organizations. Descriptive secure SDLCs include BSIMM; and the prescriptive secure SDLCs include OWASP\u0026rsquo;s Open Software Assurance Maturity Model (OpenSAMM), and ISO/IEC 27034 Parts 1-7, all published (except part 4).\nTest Early and Test Often When a bug is detected early within the SDLC it can be addressed faster and at a lower cost. A security bug is no different from a functional or performance-based bug in this regard. A key step in making this possible is to educate the development and QA teams about common security issues and the ways to detect and prevent them. Although new libraries, tools, or languages can help design programs with fewer security bugs, new threats arise constantly and developers must be aware of the threats that affect the software they are developing. Education in security testing also helps developers acquire the appropriate mindset to test an application from an attacker\u0026rsquo;s perspective. This allows each organization to consider security issues as part of their existing responsibilities.\nTest Automation In modern development methodologies such as (but not limited to): agile, devops/devsecops, or rapid application development (RAD) consideration should be put into integrating security tests in to continuous integration/continuous deployment (CI/CD) workflows in order to maintain baseline security information/analysis and identify \u0026ldquo;low hanging fruit\u0026rdquo; type weaknesses. This can be done by leveraging dynamic application security testing (DAST), static application security testing (SAST), and software composition analysis (SCA) or dependency tracking tools during standard automated release workflows or on a regularly scheduled basis.\nUnderstand the Scope of Security It is important to know how much security a given project will require. The assets that are to be protected should be given a classification that states how they are to be handled (e.g., confidential, secret, top secret). Discussions should occur with legal council to ensure that any specific security requirements will be met. In the USA, requirements might come from federal regulations, such as the Gramm-Leach-Bliley Act, or from state laws, such as the California SB-1386. For organizations based in EU countries, both country-specific regulation and EU Directives may apply. For example, Directive 96/46/EC4 and Regulation (EU) 2016/679 (General Data Protection Regulation) make it mandatory to treat personal data in applications with due care, whatever the application.\nDevelop the Right Mindset Successfully testing an application for security vulnerabilities requires thinking \u0026ldquo;outside of the box.\u0026rdquo; Normal use cases will test the normal behavior of the application when a user is using it in the manner that is expected. Good security testing requires going beyond what is expected and thinking like an attacker who is trying to break the application. Creative thinking can help to determine what unexpected data may cause an application to fail in an insecure manner. It can also help find any assumptions made by web developers that are not always true, and how those assumptions can be subverted. One reason that automated tools do a poor job of testing for vulnerabilities is that automated tools do not think creatively. Creative thinking must be done on a case-by-case basis, as most web applications are being developed in a unique way (even when using common frameworks).\nUnderstand the Subject One of the first major initiatives in any good security program should be to require accurate documentation of the application. The architecture, data-flow diagrams, use cases, etc. should be recorded in formal documents and made available for review. The technical specification and application documents should include information that lists not only the desired use cases, but also any specifically disallowed use cases. Finally, it is good to have at least a basic security infrastructure that allows the monitoring and trending of attacks against an organization\u0026rsquo;s applications and network (e.g., intrusion detection systems).\nUse the Right Tools While we have already stated that there is no silver bullet tool, tools do play a critical role in the overall security program. There is a range of Open Source and commercial tools that can automate many routine security tasks. These tools can simplify and speed up the security process by assisting security personnel in their tasks. However, it is important to understand exactly what these tools can and cannot do so that they are not oversold or used incorrectly.\nThe Devil is in the Details It is critical not to perform a superficial security review of an application and consider it complete. This will instill a false sense of confidence that can be as dangerous as not having done a security review in the first place. It is vital to carefully review the findings and weed out any false positives that may remain in the report. Reporting an incorrect security finding can often undermine the valid message of the rest of a security report. Care should be taken to verify that every possible section of application logic has been tested, and that every use case scenario was explored for possible vulnerabilities.\nUse Source Code When Available While black-box penetration test results can be impressive and useful to demonstrate how vulnerabilities are exposed in a production environment, they are not the most effective or efficient way to secure an application. It is difficult for dynamic testing to test the entire code base, particularly if many nested conditional statements exist. If the source code for the application is available, it should be given to the security staff to assist them while performing their review. It is possible to discover vulnerabilities within the application source that would be missed during a black-box engagement.\nDevelop Metrics An important part of a good security program is the ability to determine if things are getting better. It is important to track the results of testing engagements, and develop metrics that will reveal the application security trends within the organization.\nGood metrics will show:\n If more education and training are required; If there is a particular security mechanism that is not clearly understood by the development team; If the total number of security related problems being found is decreasing.  Consistent metrics that can be generated in an automated way from available source code will also help the organization in assessing the effectiveness of mechanisms introduced to reduce security bugs in software development. Metrics are not easily developed, so using a standard such as the one provided by the IEEE is a good starting point.\nDocument the Test Results To conclude the testing process, it is important to produce a formal record of what testing actions were taken, by whom, when they were performed, and details of the test findings. It is wise to agree on an acceptable format for the report that is useful to all concerned parties, which may include developers, project management, business owners, IT department, audit, and compliance.\nThe report should clearly identify to the business owner where material risks exist, and do so in a manner sufficient to get their backing for subsequent mitigation actions. The report should also be clear to the developer in pin-pointing the exact function that is affected by the vulnerability and associated recommendations for resolving issues in a language that the developer will understand. The report should also allow another security tester to reproduce the results. Writing the report should not be overly burdensome on the security tester themselves. Security testers are not generally renowned for their creative writing skills, and agreeing on a complex report can lead to instances where test results are not properly documented. Using a security test report template can save time and ensure that results are documented accurately and consistently, and are in a format that is suitable for the audience.\nTesting Techniques Explained This section presents a high-level overview of various testing techniques that can be employed when building a testing program. It does not present specific methodologies for these techniques, as this information is covered in Chapter 3. This section is included to provide context for the framework presented in the next chapter and to highlight the advantages or disadvantages of some of the techniques that should be considered. In particular, we will cover:\n Manual Inspections \u0026amp; Reviews Threat Modeling Code Review Penetration Testing  Manual Inspections and Reviews Overview Manual inspections are human reviews that typically test the security implications of people, policies, and processes. Manual inspections can also include inspection of technology decisions such as architectural designs. They are usually conducted by analyzing documentation or performing interviews with the designers or system owners.\nWhile the concept of manual inspections and human reviews is simple, they can be among the most powerful and effective techniques available. By asking someone how something works and why it was implemented in a specific way, the tester can quickly determine if any security concerns are likely to be evident. Manual inspections and reviews are one of the few ways to test the software development life-cycle process itself and to ensure that there is an adequate policy or skill set in place.\nAs with many things in life, when conducting manual inspections and reviews it is recommended that a trust-but-verify model is adopted. Not everything that the tester is shown or told will be accurate. Manual reviews are particularly good for testing whether people understand the security process, have been made aware of policy, and have the appropriate skills to design or implement secure applications.\nOther activities, including manually reviewing the documentation, secure coding policies, security requirements, and architectural designs, should all be accomplished using manual inspections.\nAdvantages  Requires no supporting technology Can be applied to a variety of situations Flexible Promotes teamwork Early in the SDLC  Disadvantages  Can be time-consuming Supporting material not always available Requires significant human thought and skill to be effective  Threat Modeling Overview Threat modeling has become a popular technique to help system designers think about the security threats that their systems and applications might face. Therefore, threat modeling can be seen as risk assessment for applications. It enables the designer to develop mitigation strategies for potential vulnerabilities and helps them focus their inevitably limited resources and attention on the parts of the system that most require it. It is recommended that all applications have a threat model developed and documented. Threat models should be created as early as possible in the SDLC, and should be revisited as the application evolves and development progresses.\nTo develop a threat model, we recommend taking a simple approach that follows the NIST 800-30 standard for risk assessment. This approach involves:\n Decomposing the application – use a process of manual inspection to understand how the application works, its assets, functionality, and connectivity. Defining and classifying the assets – classify the assets into tangible and intangible assets and rank them according to business importance. Exploring potential vulnerabilities - whether technical, operational, or managerial. Exploring potential threats – develop a realistic view of potential attack vectors from an attacker’s perspective by using threat scenarios or attack trees. Creating mitigation strategies – develop mitigating controls for each of the threats deemed to be realistic.  The output from a threat model itself can vary but is typically a collection of lists and diagrams. Various Open Source projects and commercial products support application threat modeling methodologies that can be used as a reference for testing applications for potential security flaws in the design of the application. There is no right or wrong way to develop threat models and perform information risk assessments on applications.\nAdvantages  Practical attacker view of the system Flexible Early in the SDLC  Disadvantages  Good threat models don’t automatically mean good software  Source Code Review Overview Source code review is the process of manually checking the source code of a web application for security issues. Many serious security vulnerabilities cannot be detected with any other form of analysis or testing. As the popular saying goes \u0026ldquo;if you want to know what’s really going on, go straight to the source.\u0026rdquo; Almost all security experts agree that there is no substitute for actually looking at the code. All the information for identifying security problems is there in the code, somewhere. Unlike testing closed software such as operating systems, when testing web applications (especially if they have been developed in-house) the source code should be made available for testing purposes.\nMany unintentional but significant security problems are extremely difficult to discover with other forms of analysis or testing, such as penetration testing. This makes source code analysis the technique of choice for technical testing. With the source code, a tester can accurately determine what is happening (or is supposed to be happening) and remove the guess work of black-box testing.\nExamples of issues that are particularly conducive to being found through source code reviews include concurrency problems, flawed business logic, access control problems, and cryptographic weaknesses, as well as backdoors, Trojans, Easter eggs, time bombs, logic bombs, and other forms of malicious code. These issues often manifest themselves as the most harmful vulnerabilities in web applications. Source code analysis can also be extremely efficient to find implementation issues such as places where input validation was not performed or where fail-open control procedures may be present. Operational procedures need to be reviewed as well, since the source code being deployed might not be the same as the one being analyzed herein. Ken Thompson\u0026rsquo;s Turing Award speech describes one possible manifestation of this issue.\nAdvantages  Completeness and effectiveness Accuracy Fast (for competent reviewers)  Disadvantages  Requires highly skilled security aware developers Can miss issues in compiled libraries Cannot detect runtime errors easily The source code actually deployed might differ from the one being analyzed  For more on code review, see the OWASP code review project.\nPenetration Testing Overview Penetration testing has been a common technique used to test network security for decades. It is also commonly known as black-box testing or ethical hacking. Penetration testing is essentially the \u0026ldquo;art\u0026rdquo; of testing a system or application remotely to find security vulnerabilities, without knowing the inner workings of the target itself. Typically, the penetration test team is able to access an application as if they were users. The tester acts like an attacker and attempts to find and exploit vulnerabilities. In many cases the tester will be given one or more valid accounts on the system.\nWhile penetration testing has proven to be effective in network security, the technique does not naturally translate to applications. When penetration testing is performed on networks and operating systems, the majority of the work involved is in finding, and then exploiting, known vulnerabilities in specific technologies. As web applications are almost exclusively bespoke, penetration testing in the web application arena is more akin to pure research. Some automated penetration testing tools have been developed, but considering the bespoke nature of web applications, their effectiveness alone can be poor.\nMany people use web application penetration testing as their primary security testing technique. Whilst it certainly has its place in a testing program, we do not believe it should be considered as the primary or only testing technique. As Gary McGraw wrote in Software Penetration Testing, \u0026ldquo;In practice, a penetration test can only identify a small representative sample of all possible security risks in a system.\u0026rdquo; However, focused penetration testing (i.e., testing that attempts to exploit known vulnerabilities detected in previous reviews) can be useful in detecting if some specific vulnerabilities are actually fixed in the deployed source code.\nAdvantages  Can be fast (and therefore cheap) Requires a relatively lower skill-set than source code review Tests the code that is actually being exposed  Disadvantages  Too late in the SDLC Front-impact testing only  The Need for a Balanced Approach With so many techniques and approaches to testing the security of web applications, it can be difficult to understand which techniques to use or when to use them. Experience shows that there is no right or wrong answer to the question of exactly which techniques should be used to build a testing framework. In fact, all techniques should be used to test all the areas that need to be tested.\nAlthough it is clear that there is no single technique that can be performed to effectively cover all security testing and ensure that all issues have been addressed, many companies adopt only one approach. The single approach used has historically been penetration testing. Penetration testing, while useful, cannot effectively address many of the issues that need to be tested. It is simply \u0026ldquo;too little too late\u0026rdquo; in the SDLC.\nThe correct approach is a balanced approach that includes several techniques, from manual reviews to technical testing, to CI/CD integrated testing. A balanced approach should cover testing in all phases of the SDLC. This approach leverages the most appropriate techniques available, depending on the current SDLC phase.\nOf course there are times and circumstances where only one technique is possible. For example, consider a test of a web application that has already been created, but where the testing party does not have access to the source code. In this case, penetration testing is clearly better than no testing at all. However, the testing parties should be encouraged to challenge assumptions, such as not having access to source code, and to explore the possibility of more complete testing.\nA balanced approach varies depending on many factors, such as the maturity of the testing process and corporate culture. It is recommended that a balanced testing framework should look something like the representations shown in Figure 3 and Figure 4. The following figure shows a typical proportional representation overlaid onto the SLDC. In keeping with research and experience, it is essential that companies place a higher emphasis on the early stages of development.\nFigure 2-3: Proportion of Test Effort in SDLC\nThe following figure shows a typical proportional representation overlaid onto testing techniques.\nFigure 2-4: Proportion of Test Effort According to Test Technique\nA Note about Web Application Scanners Many organizations have started to use automated web application scanners. While they undoubtedly have a place in a testing program, some fundamental issues need to be highlighted about why it is believed that automating black-box testing is not (nor will ever be) completely effective. However, highlighting these issues should not discourage the use of web application scanners. Rather, the aim is to ensure the limitations are understood and testing frameworks are planned appropriately.\nIt is helpful to understand the efficacy and limitations of automated vulnerability detection tools. To this end, the OWASP Benchmark Project is a test suite designed to evaluate the speed, coverage, and accuracy of automated software vulnerability detection tools and services. Benchmarking can help to test the capabilities of these automated tools, and help to make their usefulness explicit.\nThe following examples show why automated black-box testing may not be effective.\nExample 1: Magic Parameters Imagine a simple web application that accepts a name-value pair of \u0026ldquo;magic\u0026rdquo; and then the value. For simplicity, the GET request may be: http://www.host/application?magic=value\nTo further simplify the example, the values in this case can only be ASCII characters a – z (upper or lowercase) and integers 0 – 9.\nThe designers of this application created an administrative backdoor during testing, but obfuscated it to prevent the casual observer from discovering it. By submitting the value sf8g7sfjdsurtsdieerwqredsgnfg8d (30 characters), the user will then be logged in and presented with an administrative screen with total control of the application. The HTTP request is now: http://www.host/application?magic=sf8g7sfjdsurtsdieerwqredsgnfg8d\nGiven that all of the other parameters were simple two- and three-characters fields, it is not possible to start guessing combinations at approximately 28 characters. A web application scanner will need to brute force (or guess) the entire key space of 30 characters. That is up to 30^28 permutations, or trillions of HTTP requests. That is an electron in a digital haystack.\nThe code for this exemplar Magic Parameter check may look like the following:\npublic void doPost( HttpServletRequest request, HttpServletResponse response) { String magic = \u0026#34;sf8g7sfjdsurtsdieerwqredsgnfg8d\u0026#34;; boolean admin = magic.equals( request.getParameter(\u0026#34;magic\u0026#34;)); if (admin) doAdmin( request, response); else … // normal processing } By looking in the code, the vulnerability practically leaps off the page as a potential problem.\nExample 2: Bad Cryptography Cryptography is widely used in web applications. Imagine that a developer decided to write a simple cryptography algorithm to sign a user in from site A to site B automatically. In their wisdom, the developer decides that if a user is logged into site A, then they will generate a key using an MD5 hash function that comprises: Hash { username : date }\nWhen a user is passed to site B, they will send the key on the query string to site B in an HTTP redirect. Site B independently computes the hash, and compares it to the hash passed on the request. If they match, site B signs the user in as the user they claim to be.\nAs the scheme is explained the inadequacies can be worked out. Anyone that figures out the scheme (or is told how it works, or downloads the information from Bugtraq) can log in as any user. Manual inspection, such as a review or code inspection, would have uncovered this security issue quickly. A black-box web application scanner would not have uncovered the vulnerability. It would have seen a 128-bit hash that changed with each user, and by the nature of hash functions, did not change in any predictable way.\nA Note about Static Source Code Review Tools Many organizations have started to use static source code scanners. While they undoubtedly have a place in a comprehensive testing program, it is necessary to highlight some fundamental issues about why this approach is not effective when used alone. Static source code analysis alone cannot identify issues due to flaws in the design, since it cannot understand the context in which the code is constructed. Source code analysis tools are useful in determining security issues due to coding errors, however significant manual effort is required to validate the findings.\nDeriving Security Test Requirements To have a successful testing program, one must know what the testing objectives are. These objectives are specified by the security requirements. This section discusses in detail how to document requirements for security testing by deriving them from applicable standards and regulations, from positive application requirements (specifying what the application is supposed to do), and from negative application requirements (specifying what the application should not do). It also discusses how security requirements effectively drive security testing during the SDLC and how security test data can be used to effectively manage software security risks.\nTesting Objectives One of the objectives of security testing is to validate that security controls operate as expected. This is documented via security requirements that describe the functionality of the security control. At a high level, this means proving confidentiality, integrity, and availability of the data as well as the service. The other objective is to validate that security controls are implemented with few or no vulnerabilities. These are common vulnerabilities, such as the OWASP Top Ten, as well as vulnerabilities that have been previously identified with security assessments during the SDLC, such as threat modeling, source code analysis, and penetration test.\nSecurity Requirements Documentation The first step in the documentation of security requirements is to understand the business requirements. A business requirement document can provide initial high-level information on the expected functionality of the application. For example, the main purpose of an application may be to provide financial services to customers or to allow goods to be purchased from an on-line catalog. A security section of the business requirements should highlight the need to protect the customer data as well as to comply with applicable security documentation such as regulations, standards, and policies.\nA general checklist of the applicable regulations, standards, and policies is a good preliminary security compliance analysis for web applications. For example, compliance regulations can be identified by checking information about the business sector and the country or state where the application will operate. Some of these compliance guidelines and regulations might translate into specific technical requirements for security controls. For example, in the case of financial applications, compliance with the Federal Financial Institutions Examination Council (FFIEC) Cybersecurity Assessment Tool \u0026amp; Documentation requires that financial institutions implement applications that mitigate weak authentication risks with multi-layered security controls and multi-factor authentication.\nApplicable industry standards for security must also be captured by the general security requirement checklist. For example, in the case of applications that handle customer credit card data, compliance with the PCI Security Standards Council Data Security Standard (DSS) forbids the storage of PINs and CVV2 data and requires that the merchant protect magnetic strip data in storage and transmission with encryption and on display by masking. Such PCI DSS security requirements could be validated via source code analysis.\nAnother section of the checklist needs to enforce general requirements for compliance with the organization\u0026rsquo;s information security standards and policies. From the functional requirements perspective, requirements for the security control need to map to a specific section of the information security standards. An example of such a requirement can be: \u0026ldquo;a password complexity of ten alphanumeric characters must be enforced by the authentication controls used by the application.\u0026rdquo; When security requirements map to compliance rules, a security test can validate the exposure of compliance risks. If violation with information security standards and policies are found, these will result in a risk that can be documented and that the business has to manage or address. Since these security compliance requirements are enforceable, they need to be well documented and validated with security tests.\nSecurity Requirements Validation From the functionality perspective, the validation of security requirements is the main objective of security testing. From the risk management perspective, the validation of security requirements is the objective of information security assessments. At a high level, the main goal of information security assessments is the identification of gaps in security controls, such as lack of basic authentication, authorization, or encryption controls. Examined further, the security assessment objective is risk analysis, such as the identification of potential weaknesses in security controls that ensure the confidentiality, integrity, and availability of the data. For example, when the application deals with personally identifiable information (PII) and sensitive data, the security requirement to be validated is the compliance with the company information security policy requiring encryption of such data in transit and in storage. Assuming encryption is used to protect the data, encryption algorithms and key lengths need to comply with the organization\u0026rsquo;s encryption standards. These might require that only certain algorithms and key lengths be used. For example, a security requirement that can be security tested is verifying that only allowed ciphers are used (e.g., SHA-256, RSA, AES) with allowed minimum key lengths (e.g., more than 128 bit for symmetric and more than 1024 for asymmetric encryption).\nFrom the security assessment perspective, security requirements can be validated at different phases of the SDLC by using different artifacts and testing methodologies. For example, threat modeling focuses on identifying security flaws during design; secure code analysis and reviews focus on identifying security issues in source code during development; and penetration testing focuses on identifying vulnerabilities in the application during testing or validation.\nSecurity issues that are identified early in the SDLC can be documented in a test plan so they can be validated later with security tests. By combining the results of different testing techniques, it is possible to derive better security test cases and increase the level of assurance of the security requirements. For example, distinguishing true vulnerabilities from the un-exploitable ones is possible when the results of penetration tests and source code analysis are combined. Considering the security test for a SQL injection vulnerability, for example, a black-box test might first involve a scan of the application to fingerprint the vulnerability. The first evidence of a potential SQL injection vulnerability that can be validated is the generation of a SQL exception. A further validation of the SQL vulnerability might involve manually injecting attack vectors to modify the grammar of the SQL query for an information disclosure exploit. This might involve a lot of trial-and-error analysis before the malicious query is executed. Assuming the tester has the source code, they might directly learn from the source code analysis how to construct the SQL attack vector that will successfully exploit the vulnerability (e.g., execute a malicious query returning confidential data to unauthorized user). This can expedite the validation of the SQL vulnerability.\nThreats and Countermeasures Taxonomies A threat and countermeasure classification, which takes into consideration root causes of vulnerabilities, is the critical factor in verifying that security controls are designed, coded, and built to mitigate the impact of the exposure of such vulnerabilities. In the case of web applications, the exposure of security controls to common vulnerabilities, such as the OWASP Top Ten, can be a good starting point to derive general security requirements. The OWASP Testing Guide Checklist is a helpful resource for guiding testers through specific vulnerabilities and validation tests.\nThe focus of a threat and countermeasure categorization is to define security requirements in terms of the threats and the root cause of the vulnerability. A threat can be categorized by using STRIDE, an acronym for Spoofing, Tampering, Repudiation, Information disclosure, Denial of service, and Elevation of privilege. The root cause can be categorized as security flaw in design, a security bug in coding, or an issue due to insecure configuration. For example, the root cause of weak authentication vulnerability might be the lack of mutual authentication when data crosses a trust boundary between the client and server tiers of the application. A security requirement that captures the threat of non-repudiation during an architecture design review allows for the documentation of the requirement for the countermeasure (e.g., mutual authentication) that can be validated later on with security tests.\nA threat and countermeasure categorization for vulnerabilities can also be used to document security requirements for secure coding such as secure coding standards. An example of a common coding error in authentication controls consists of applying a hash function to encrypt a password, without applying a seed to the value. From the secure coding perspective, this is a vulnerability that affects the encryption used for authentication with a vulnerability root cause in a coding error. Since the root cause is insecure coding, the security requirement can be documented in secure coding standards and validated through secure code reviews during the development phase of the SDLC.\nSecurity Testing and Risk Analysis Security requirements need to take into consideration the severity of the vulnerabilities to support a risk mitigation strategy. Assuming that the organization maintains a repository of vulnerabilities found in applications (i.e, a vulnerability knowledge base), the security issues can be reported by type, issue, mitigation, root cause, and mapped to the applications where they are found. Such a vulnerability knowledge base can also be used to establish a metrics to analyze the effectiveness of the security tests throughout the SDLC.\nFor example, consider an input validation issue, such as a SQL injection, which was identified via source code analysis and reported with a coding error root cause and input validation vulnerability type. The exposure of such vulnerability can be assessed via a penetration test, by probing input fields with several SQL injection attack vectors. This test might validate that special characters are filtered before hitting the database and mitigate the vulnerability. By combining the results of source code analysis and penetration testing, it is possible to determine the likelihood and exposure of the vulnerability and calculate the risk rating of the vulnerability. By reporting vulnerability risk ratings in the findings (e.g., test report) it is possible to decide on the mitigation strategy. For example, high and medium risk vulnerabilities can be prioritized for remediation, while low risk vulnerabilities can be fixed in future releases.\nBy considering the threat scenarios of exploiting common vulnerabilities, it is possible to identify potential risks that the application security control needs to be security tested for. For example, the OWASP Top Ten vulnerabilities can be mapped to attacks such as phishing, privacy violations, identify theft, system compromise, data alteration or data destruction, financial loss, and reputation loss. Such issues should be documented as part of the threat scenarios. By thinking in terms of threats and vulnerabilities, it is possible to devise a battery of tests that simulate such attack scenarios. Ideally, the organization\u0026rsquo;s vulnerability knowledge base can be used to derive security-risk-driven test cases to validate the most likely attack scenarios. For example, if identity theft is considered high risk, negative test scenarios should validate the mitigation of impacts deriving from the exploit of vulnerabilities in authentication, cryptographic controls, input validation, and authorization controls.\nDeriving Functional and Non-Functional Test Requirements Functional Security Requirements From the perspective of functional security requirements, the applicable standards, policies, and regulations drive both the need for a type of security control as well as the control functionality. These requirements are also referred to as \u0026ldquo;positive requirements\u0026rdquo;, since they state the expected functionality that can be validated through security tests. Examples of positive requirements are: \u0026ldquo;the application will lockout the user after six failed log on attempts\u0026rdquo; or \u0026ldquo;passwords need to be a minimum of ten alphanumeric characters\u0026rdquo;. The validation of positive requirements consists of asserting the expected functionality and can be tested by re-creating the testing conditions and running the test according to predefined inputs. The results are then shown as a fail or pass condition.\nIn order to validate security requirements with security tests, security requirements need to be function-driven. They need to highlight the expected functionality (the what) and imply the implementation (the how). Examples of high-level security design requirements for authentication can be:\n Protect user credentials or shared secrets in transit and in storage. Mask any confidential data in display (e.g., passwords, accounts). Lock the user account after a certain number of failed log in attempts. Do not show specific validation errors to the user as a result of a failed log on. Only allow passwords that are alphanumeric, include special characters, and are a minimum ten characters in length, to limit the attack surface. Allow for password change functionality only to authenticated users by validating the old password, the new password, and the user\u0026rsquo;s answer to the challenge question, to prevent brute forcing of a password via password change. The password reset form should validate the user’s username and the user’s registered email before sending the temporary password to the user via email. The temporary password issued should be a one-time password. A link to the password reset web page will be sent to the user. The password reset web page should validate the user\u0026rsquo;s temporary password, the new password, as well as the user\u0026rsquo;s answer to the challenge question.  Risk-Driven Security Requirements Security tests must also be risk-driven. They need to validate the application for unexpected behavior, or negative requirements.\nExamples of negative requirements are:\n The application should not allow for the data to be altered or destroyed. The application should not be compromised or misused for unauthorized financial transactions by a malicious user.  Negative requirements are more difficult to test, because there is no expected behavior to look for. Looking for expected behavior to suit the above requirements might require a threat analyst to unrealistically come up with unforeseeable input conditions, causes, and effects. Hence, security testing needs to be driven by risk analysis and threat modeling. The key is to document the threat scenarios, and the functionality of the countermeasure as a factor to mitigate a threat.\nFor example, in the case of authentication controls, the following security requirements can be documented from the threats and countermeasures perspective:\n Encrypt authentication data in storage and transit to mitigate risk of information disclosure and authentication protocol attacks. Encrypt passwords using non-reversible encryption such as using a digest (e.g., HASH) and a seed to prevent dictionary attacks. Lock out accounts after reaching a log on failure threshold and enforce password complexity to mitigate risk of brute force password attacks. Display generic error messages upon validation of credentials to mitigate risk of account harvesting or enumeration. Mutually authenticate client and server to prevent non-repudiation and Manipulator In the Middle (MiTM) attacks.  Threat modeling tools such as threat trees and attack libraries can be useful to derive the negative test scenarios. A threat tree will assume a root attack (e.g., attacker might be able to read other users' messages) and identify different exploits of security controls (e.g., data validation fails because of a SQL injection vulnerability) and necessary countermeasures (e.g., implement data validation and parametrized queries) that could be validated to be effective in mitigating such attacks.\nDeriving Security Test Requirements Through Use and Misuse Cases A prerequisite to describing the application functionality is to understand what the application is supposed to do and how. This can be done by describing use cases. Use cases, in the graphical form as is commonly used in software engineering, show the interactions of actors and their relations. They help to identify the actors in the application, their relationships, the intended sequence of actions for each scenario, alternative actions, special requirements, preconditions, and post-conditions.\nSimilar to use cases, misuse or abuse cases describe unintended and malicious use scenarios of the application. These misuse cases provide a way to describe scenarios of how an attacker could misuse and abuse the application. By going through the individual steps in a use scenario and thinking about how it can be maliciously exploited, potential flaws or aspects of the application that are not well defined can be discovered. The key is to describe all possible or, at least, the most critical use and misuse scenarios.\nMisuse scenarios allow the analysis of the application from the attacker\u0026rsquo;s point of view and contribute to identifying potential vulnerabilities and the countermeasures that need to be implemented to mitigate the impact caused by the potential exposure to such vulnerabilities. Given all of the use and abuse cases, it is important to analyze them to determine which are the most critical and need to be documented in security requirements. The identification of the most critical misuse and abuse cases drives the documentation of security requirements and the necessary controls where security risks should be mitigated.\nTo derive security requirements from both use and misuse cases, it is important to define the functional scenarios and the negative scenarios and put these in graphical form. The following example is a step-by-step methodology for the case of deriving security requirements for authentication.\nStep 1: Describe the Functional Scenario User authenticates by supplying a username and password. The application grants access to users based upon authentication of user credentials by the application and provides specific errors to the user when validation fails.\nStep 2: Describe the Negative Scenario Attacker breaks the authentication through a brute force or dictionary attack of passwords and account harvesting vulnerabilities in the application. The validation errors provide specific information to an attacker that is used to guess which accounts are valid registered accounts (usernames). The attacker then attempts to brute force the password for a valid account. A brute force attack on passwords with a minimum length of four digits can succeed with a limited number of attempts (i.e., 10^4).\nStep 3: Describe Functional and Negative Scenarios with Use and Misuse Case The graphical example below depicts the derivation of security requirements via use and misuse cases. The functional scenario consists of the user actions (entering a username and password) and the application actions (authenticating the user and providing an error message if validation fails). The misuse case consists of the attacker actions, i.e. trying to break authentication by brute forcing the password via a dictionary attack and by guessing the valid usernames from error messages. By graphically representing the threats to the user actions (misuses), it is possible to derive the countermeasures as the application actions that mitigate such threats.\nFigure 2-5: Use and Misuse Case\nStep 4: Elicit the Security Requirements In this case, the following security requirements for authentication are derived:\n Passwords requirements must be aligned with the current standards for sufficient complexity. Accounts must be to locked out after five unsuccessful log in attempts. Log in error messages must be generic.  These security requirements need to be documented and tested.\nSecurity Tests Integrated in Development and Testing Workflows Security Testing in the Development Workflow Security testing during the development phase of the SDLC represents the first opportunity for developers to ensure that the individual software components they have developed are security tested before they are integrated with other components or built into the application. Software components might consist of software artifacts such as functions, methods, and classes, as well as application programming interfaces, libraries, and executable files. For security testing, developers can rely on the results of the source code analysis to verify statically that the developed source code does not include potential vulnerabilities and is compliant with the secure coding standards. Security unit tests can further verify dynamically (i.e., at run time) that the components function as expected. Before integrating both new and existing code changes in the application build, the results of the static and dynamic analysis should be reviewed and validated.\nThe validation of source code before integration in application builds is usually the responsibility of the senior developer. Senior developers are often the subject matter experts in software security and their role is to lead the secure code review. They must make decisions on whether to accept the code to be released in the application build, or to require further changes and testing. This secure code review workflow can be enforced via formal acceptance, as well as a check in a workflow management tool. For example, assuming the typical defect management workflow used for functional bugs, security bugs that have been fixed by a developer can be reported on a defect or change management system. The build master then can look at the test results reported by the developers in the tool, and grant approvals for checking in the code changes into the application build.\nSecurity Testing in the Test Workflow After components and code changes are tested by developers and checked in to the application build, the most likely next step in the software development process workflow is to perform tests on the application as a whole entity. This level of testing is usually referred to as integrated test and system level test. When security tests are part of these testing activities, they can be used to validate both the security functionality of the application as a whole, as well as the exposure to application level vulnerabilities. These security tests on the application include both white-box testing, such as source code analysis, and black-box testing, such as penetration testing. Tests can also include gray-box testing, in which it is assumed that the tester has some partial knowledge about the application. For example, with some knowledge about the session management of the application, the tester can better understand whether the log out and timeout functions are properly secured.\nThe target for the security tests is the complete system that is vulnerable to attack. During this phase, it is possible for security testers to determine whether vulnerabilities can be exploited. These include common web application vulnerabilities, as well as security issues that have been identified earlier in the SDLC with other activities such as threat modeling, source code analysis, and secure code reviews.\nUsually, testing engineers, rather then software developers, perform security tests when the application is in scope for integration system tests. Testing engineers have security knowledge of web application vulnerabilities, black-box and white-box testing techniques, and own the validation of security requirements in this phase. In order to perform security tests, it is a prerequisite that security test cases are documented in the security testing guidelines and procedures.\nA testing engineer who validates the security of the application in the integrated system environment might release the application for testing in the operational environment (e.g., user acceptance tests). At this stage of the SDLC (i.e., validation), the application\u0026rsquo;s functional testing is usually a responsibility of QA testers, while white-hat hackers or security consultants are usually responsible for security testing. Some organizations rely on their own specialized ethical hacking team to conduct such tests when a third party assessment is not required (such as for auditing purposes).\nSince these tests can sometimes be the last line of defense for fixing vulnerabilities before the application is released to production, it is important that issues are addressed as recommended by the testing team. The recommendations can include code, design, or configuration change. At this level, security auditors and information security officers discuss the reported security issues and analyze the potential risks according to information risk management procedures. Such procedures might require the development team to fix all high risk vulnerabilities before the application can be deployed, unless such risks are acknowledged and accepted.\nDeveloper\u0026rsquo;s Security Tests Security Testing in the Coding Phase: Unit Tests From the developer’s perspective, the main objective of security tests is to validate that code is being developed in compliance with secure coding standards requirements. Developers' own coding artifacts (such as functions, methods, classes, APIs, and libraries) need to be functionally validated before being integrated into the application build.\nThe security requirements that developers have to follow should be documented in secure coding standards and validated with static and dynamic analysis. If the unit test activity follows a secure code review, unit tests can validate that code changes required by secure code reviews are properly implemented. Both secure code reviews and source code analysis through source code analysis tools can help developers in identifying security issues in source code as it is developed. By using unit tests and dynamic analysis (e.g., debugging) developers can validate the security functionality of components as well as verify that the countermeasures being developed mitigate any security risks previously identified through threat modeling and source code analysis.\nA good practice for developers is to build security test cases as a generic security test suite that is part of the existing unit testing framework. A generic security test suite could be derived from previously defined use and misuse cases to security test functions, methods and classes. A generic security test suite might include security test cases to validate both positive and negative requirements for security controls such as:\n Identity, authentication \u0026amp; access control Input validation \u0026amp; encoding Encryption User and session management Error and exception handling Auditing and logging  Developers empowered with a source code analysis tool integrated into their IDE, secure coding standards, and a security unit testing framework can assess and verify the security of the software components being developed. Security test cases can be run to identify potential security issues that have root causes in source code: besides input and output validation of parameters entering and exiting the components, these issues include authentication and authorization checks done by the component, protection of the data within the component, secure exception and error handling, and secure auditing and logging. Unit test frameworks such as JUnit, NUnit, and CUnit can be adapted to verify security test requirements. In the case of security functional tests, unit level tests can test the functionality of security controls at the software component level, such as functions, methods, or classes. For example, a test case could validate input and output validation (e.g., variable sanitation) and boundary checks for variables by asserting the expected functionality of the component.\nThe threat scenarios identified with use and misuse cases can be used to document the procedures for testing software components. In the case of authentication components, for example, security unit tests can assert the functionality of setting an account lockout as well as the fact that user input parameters cannot be abused to bypass the account lockout (e.g., by setting the account lockout counter to a negative number).\nAt the component level, security unit tests can validate positive assertions as well as negative assertions, such as errors and exception handling. Exceptions should be caught without leaving the system in an insecure state, such as potential denial of service caused by resources not being de-allocated (e.g., connection handles not closed within a final statement block), as well as potential elevation of privileges (e.g., higher privileges acquired before the exception is thrown and not re-set to the previous level before exiting the function). Secure error handling can validate potential information disclosure via informative error messages and stack traces.\nUnit level security test cases can be developed by a security engineer who is the subject matter expert in software security and is also responsible for validating that the security issues in the source code have been fixed and can be checked in to the integrated system build. Typically, the manager of the application builds also makes sure that third-party libraries and executable files are security assessed for potential vulnerabilities before being integrated in the application build.\nThreat scenarios for common vulnerabilities that have root causes in insecure coding can also be documented in the developer’s security testing guide. When a fix is implemented for a coding defect identified with source code analysis, for example, security test cases can verify that the implementation of the code change follows the secure coding requirements documented in the secure coding standards.\nSource code analysis and unit tests can validate that the code change mitigates the vulnerability exposed by the previously identified coding defect. The results of automated secure code analysis can also be used as automatic check-in gates for version control, for example, software artifacts cannot be checked into the build with high or medium severity coding issues.\nFunctional Testers' Security Tests Security Testing During the Integration and Validation Phase: Integrated System Tests and Operation Tests The main objective of integrated system tests is to validate the \u0026ldquo;defense in depth\u0026rdquo; concept, that is, that the implementation of security controls provides security at different layers. For example, the lack of input validation when calling a component integrated with the application is often a factor that can be tested with integration testing.\nThe integration system test environment is also the first environment where testers can simulate real attack scenarios as can be potentially executed by a malicious external or internal user of the application. Security testing at this level can validate whether vulnerabilities are real and can be exploited by attackers. For example, a potential vulnerability found in source code can be rated as high risk because of the exposure to potential malicious users, as well as because of the potential impact (e.g., access to confidential information).\nReal attack scenarios can be tested with both manual testing techniques and penetration testing tools. Security tests of this type are also referred to as ethical hacking tests. From the security testing perspective, these are risk-driven tests and have the objective of testing the application in the operational environment. The target is the application build that is representative of the version of the application being deployed into production.\nIncluding security testing in the integration and validation phase is critical to identifying vulnerabilities due to integration of components, as well as validating the exposure of such vulnerabilities. Application security testing requires a specialized set of skills, including both software and security knowledge, that are not typical of security engineers. As a result, organizations are often required to security-train their software developers on ethical hacking techniques, and security assessment procedures and tools. A realistic scenario is to develop such resources in-house and document them in security testing guides and procedures that take into account the developer’s security testing knowledge. A so called \u0026ldquo;security test cases cheat sheet or checklist\u0026rdquo;, for example, can provide simple test cases and attack vectors that can be used by testers to validate exposure to common vulnerabilities such as spoofing, information disclosures, buffer overflows, format strings, SQL injection and XSS injection, XML, SOAP, canonicalization issues, denial of service, and managed code and ActiveX controls (e.g., .NET). A first battery of these tests can be performed manually with a very basic knowledge of software security.\nThe first objective of security tests might be the validation of a set of minimum security requirements. These security test cases might consist of manually forcing the application into error and exceptional states and gathering knowledge from the application behavior. For example, SQL injection vulnerabilities can be tested manually by injecting attack vectors through user input, and by checking if SQL exceptions are thrown back to the user. The evidence of a SQL exception error might be a manifestation of a vulnerability that can be exploited.\nA more in-depth security test might require the tester’s knowledge of specialized testing techniques and tools. Besides source code analysis and penetration testing, these techniques include, for example: source code and binary fault injection, fault propagation analysis and code coverage, fuzz testing, and reverse engineering. The security testing guide should provide procedures and recommend tools that can be used by security testers to perform such in-depth security assessments.\nThe next level of security testing after integration system tests is to perform security tests in the user acceptance environment. There are unique advantages to performing security tests in the operational environment. The user acceptance test (UAT) environment is the one that is most representative of the release configuration, with the exception of the data (e.g., test data is used in place of real data). A characteristic of security testing in UAT is testing for security configuration issues. In some cases these vulnerabilities might represent high risks. For example, the server that hosts the web application might not be configured with minimum privileges, valid SSL certificate and secure configuration, essential services disabled, and web root directory cleaned of test and administration web pages.\nSecurity Test Data Analysis and Reporting Goals for Security Test Metrics and Measurements Defining the goals for the security testing metrics and measurements is a prerequisite for using security testing data for risk analysis and management processes. For example, a measurement, such as the total number of vulnerabilities found with security tests, might quantify the security posture of the application. These measurements also help to identify security objectives for software security testing, for example, reducing the number of vulnerabilities to an acceptable minimum number before the application is deployed into production.\nAnother manageable goal could be to compare the application security posture against a baseline to assess improvements in application security processes. For example, the security metrics baseline might consist of an application that was tested only with penetration tests. The security data obtained from an application that was also security tested during coding should show an improvement (e.g., fewer vulnerabilities) when compared with the baseline.\nIn traditional software testing, the number of software defects, such as the bugs found in an application, could provide a measure of software quality. Similarly, security testing can provide a measure of software security. From the defect management and reporting perspective, software quality and security testing can use similar categorizations for root causes and defect remediation efforts. From the root cause perspective, a security defect can be due to an error in design (e.g., security flaws) or due to an error in coding (e.g., security bug). From the perspective of the effort required to fix a defect, both security and quality defects can be measured in terms of developer hours to implement the fix, the tools and resources required, and the cost to implement the fix.\nA characteristic of security test data, compared to quality data, is the categorization in terms of the threat, the exposure of the vulnerability, and the potential impact posed by the vulnerability to determine the risk. Testing applications for security consists of managing technical risks to make sure that the application countermeasures meet acceptable levels. For this reason, security testing data needs to support the security risk strategy at critical checkpoints during the SDLC. For example, vulnerabilities found in source code with source code analysis represent an initial measure of risk. A measure of risk (e.g., high, medium, low) for the vulnerability can be calculated by determining the exposure and likelihood factors, and by validating the vulnerability with penetration tests. The risk metrics associated to vulnerabilities found with security tests empower business management to make risk management decisions, such as to decide whether risks can be accepted, mitigated, or transferred at different levels within the organization (e.g., business as well as technical risks).\nWhen evaluating the security posture of an application, it is important to take into consideration certain factors, such as the size of the application being developed. Application size has been statistically proven to be related to the number of issues found in the application during testing. Since testing reduces issues, it is logical for larger size applications to be tested more often than smaller size applications.\nWhen security testing is done in several phases of the SDLC, the test data can prove the capability of the security tests in detecting vulnerabilities as soon as they are introduced. The test data can also prove the effectiveness of removing the vulnerabilities by implementing countermeasures at different checkpoints of the SDLC. A measurement of this type is also defined as \u0026ldquo;containment metrics\u0026rdquo; and provides a measure of the ability of a security assessment performed at each phase of the development process to maintain security within each phase. These containment metrics are also a critical factor in lowering the cost of fixing the vulnerabilities. It is less expensive to deal with vulnerabilities in the same phase of the SDLC that they are found, rather then fixing them later in another phase.\nSecurity test metrics can support security risk, cost, and defect management analysis when they are associated with tangible and timed goals such as:\n Reducing the overall number of vulnerabilities by 30%. Fixing security issues by a certain deadline (e.g., before beta release).  Security test data can be absolute, such as the number of vulnerabilities detected during manual code review, as well as comparative, such as the number of vulnerabilities detected in code reviews compared to penetration tests. To answer questions about the quality of the security process, it is important to determine a baseline for what could be considered acceptable and good.\nSecurity test data can also support specific objectives of the security analysis. These objectives could be compliance with security regulations and information security standards, management of security processes, the identification of security root causes and process improvements, and security cost benefit analysis.\nWhen security test data is reported, it has to provide metrics to support the analysis. The scope of the analysis is the interpretation of test data to find clues about the security of the software being produced, as well as the effectiveness of the process.\nSome examples of clues supported by security test data can be:\n Are vulnerabilities reduced to an acceptable level for release? How does the security quality of this product compare with similar software products? Are all security test requirements being met? What are the major root causes of security issues? How numerous are security flaws compared to security bugs? Which security activity is most effective in finding vulnerabilities? Which team is more productive in fixing security defects and vulnerabilities? What percentage of overall vulnerabilities are high risk? Which tools are most effective in detecting security vulnerabilities? What kind of security tests are most effective in finding vulnerabilities (e.g., white-box vs. black-box) tests? How many security issues are found during secure code reviews? How many security issues are found during secure design reviews?  In order to make a sound judgment using the testing data, it is important to have a good understanding of the testing process as well as the testing tools. A tool taxonomy should be adopted to decide which security tools to use. Security tools can be qualified as being good at finding common, known vulnerabilities, when targeting different artifacts.\nIt is important to note that unknown security issues are not tested. The fact that a security test is clear of issues does not mean that the software or application is good.\nEven the most sophisticated automation tools are not a match for an experienced security tester. Just relying on successful test results from automated tools will give security practitioners a false sense of security. Typically, the more experienced the security testers are with the security testing methodology and testing tools, the better the results of the security test and analysis will be. It is important that managers making an investment in security testing tools also consider an investment in hiring skilled human resources, as well as security test training.\nReporting Requirements The security posture of an application can be characterized from the perspective of the effect, such as number of vulnerabilities and the risk rating of the vulnerabilities, as well as from the perspective of the cause or origin, such as coding errors, architectural flaws, and configuration issues.\nVulnerabilities can be classified according to different criteria. The most commonly used vulnerability severity metric is the Common Vulnerability Scoring System (CVSS), a standard maintained by the Forum of Incident Response and Security Teams (FIRST).\nWhen reporting security test data, the best practice is to include the following information:\n a categorization of each vulnerability by type; the security threat that each issue is exposed to; the root cause of each security issue, such as the bug or flaw; each testing technique used to find the issues; the remediation, or countermeasure, for each vulnerability; and the severity rating of each vulnerability (e.g., high, medium, low, or CVSS score).  By describing what the security threat is, it will be possible to understand if and why the mitigation control is ineffective in mitigating the threat.\nReporting the root cause of the issue can help pinpoint what needs to be fixed. In the case of white-box testing, for example, the software security root cause of the vulnerability will be the offending source code.\nOnce issues are reported, it is also important to provide guidance to the software developer on how to re-test and find the vulnerability. This might involve using a white-box testing technique (e.g., security code review with a static code analyzer) to find if the code is vulnerable. If a vulnerability can be found via a black-box penetration test, the test report also needs to provide information on how to validate the exposure of the vulnerability to the front end (e.g., client).\nThe information about how to fix the vulnerability should be detailed enough for a developer to implement a fix. It should provide secure coding examples, configuration changes, and provide adequate references.\nFinally, the severity rating contributes to the calculation of risk rating and helps to prioritize the remediation effort. Typically, assigning a risk rating to the vulnerability involves external risk analysis based upon factors such as impact and exposure.\nBusiness Cases For the security test metrics to be useful, they need to provide value back to the organization\u0026rsquo;s security test data stakeholders. The stakeholders can include project managers, developers, information security offices, auditors, and chief information officers. The value can be in terms of the business case that each project stakeholder has, in terms of role and responsibility.\nSoftware developers look at security test data to show that software is coded securely and efficiently. This allows them to make the case for using source code analysis tools, following secure coding standards, and attending software security training.\nProject managers look for data that allows them to successfully manage and utilize security testing activities and resources according to the project plan. To project managers, security test data can show that projects are on schedule and moving on target for delivery dates, and are getting better during tests.\nSecurity test data also helps the business case for security testing if the initiative comes from information security officers (ISOs). For example, it can provide evidence that security testing during the SDLC does not impact the project delivery, but rather reduces the overall workload needed to address vulnerabilities later in production.\nTo compliance auditors, security test metrics provide a level of software security assurance and confidence that security standard compliance is addressed through the security review processes within the organization.\nFinally, Chief Information Officers (CIOs), and Chief Information Security Officers (CISOs), who are responsible for the budget that needs to be allocated in security resources, look for derivation of a cost-benefit analysis from security test data. This allows them to make informed decisions about which security activities and tools to invest in. One of the metrics that supports such analysis is the Return On Investment (ROI) in security. To derive such metrics from security test data, it is important to quantify the differential between the risk, due to the exposure of vulnerabilities, and the effectiveness of the security tests in mitigating the security risk, then factor this gap with the cost of the security testing activity or the testing tools adopted.\nReferences  US National Institute of Standards (NIST) 2002 survey on the cost of insecure software to the US economy due to inadequate software testing  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/3-the_owasp_testing_framework/",
	"title": "The OWASP Testing Framework",
	"tags": [],
	"description": "",
	"content": "Chapter 3 The Owasp Testing Framework "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/",
	"title": "Web Application Security Testing",
	"tags": [],
	"description": "",
	"content": "Chapter 4 Web Application Security Testing "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/",
	"title": "WSTG",
	"tags": [],
	"description": "",
	"content": "Lorem Ipsum.\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/3-the_owasp_testing_framework/0-the_web_security_testing_framework/",
	"title": "The Web Security Testing Framework",
	"tags": [],
	"description": "",
	"content": "The Web Security Testing Framework Overview This section describes a typical testing framework that can be developed within an organization. It can be seen as a reference framework comprised of techniques and tasks that are appropriate at various phases of the software development life cycle (SDLC). Companies and project teams can use this model to develop their own testing framework, and to scope testing services from vendors. This framework should not be seen as prescriptive, but as a flexible approach that can be extended and molded to fit an organization\u0026rsquo;s development process and culture.\nThis section aims to help organizations build a complete strategic testing process, and is not aimed at consultants or contractors who tend to be engaged in more tactical, specific areas of testing.\nIt is critical to understand why building an end-to-end testing framework is crucial to assessing and improving software security. In Writing Secure Code, Howard and LeBlanc note that issuing a security bulletin costs Microsoft at least $100,000, and it costs their customers collectively far more than that to implement the security patches. They also note that the US government\u0026rsquo;s CyberCrime web site details recent criminal cases and the loss to organizations. Typical losses far exceed USD $100,000.\nWith economics like this, it is little wonder why software vendors move from solely performing black-box security testing, which can only be performed on applications that have already been developed, to concentrating on testing in the early cycles of application development, such as during definition, design, and development.\nMany security practitioners still see security testing in the realm of penetration testing. As discussed in the previous chapter, while penetration testing has a role to play, it is generally inefficient at finding bugs and relies excessively on the skill of the tester. It should only be considered as an implementation technique, or to raise awareness of production issues. To improve the security of applications, the security quality of the software must be improved. That means testing security during the definition, design, development, deployment, and maintenance stages, and not relying on the costly strategy of waiting until code is completely built.\nAs discussed in the introduction of this document, there are many development methodologies, such as the Rational Unified Process, eXtreme and Agile development, and traditional waterfall methodologies. The intent of this guide is to suggest neither a particular development methodology, nor provide specific guidance that adheres to any particular methodology. Instead, we are presenting a generic development model, and the reader should follow it according to their company process.\nThis testing framework consists of activities that should take place:\n Before development begins, During definition and design, During development, During deployment, and During maintenance and operations.  Phase 1 Before Development Begins Phase 1.1 Define a SDLC Before application development starts, an adequate SDLC must be defined where security is inherent at each stage.\nPhase 1.2 Review Policies and Standards Ensure that there are appropriate policies, standards, and documentation in place. Documentation is extremely important as it gives development teams guidelines and policies that they can follow. People can only do the right thing if they know what the right thing is.\nIf the application is to be developed in Java, it is essential that there is a Java secure coding standard. If the application is to use cryptography, it is essential that there is a cryptography standard. No policies or standards can cover every situation that the development team will face. By documenting the common and predictable issues, there will be fewer decisions that need to be made during the development process.\nPhase 1.3 Develop Measurement and Metrics Criteria and Ensure Traceability Before development begins, plan the measurement program. By defining criteria that need to be measured, it provides visibility into defects in both the process and product. It is essential to define the metrics before development begins, as there may be a need to modify the process in order to capture the data.\nPhase 2 During Definition and Design Phase 2.1 Review Security Requirements Security requirements define how an application works from a security perspective. It is essential that the security requirements are tested. Testing in this case means testing the assumptions that are made in the requirements and testing to see if there are gaps in the requirements definitions.\nFor example, if there is a security requirement that states that users must be registered before they can get access to the whitepapers section of a website, does this mean that the user must be registered with the system or should the user be authenticated? Ensure that requirements are as unambiguous as possible.\nWhen looking for requirements gaps, consider looking at security mechanisms such as:\n User management Authentication Authorization Data confidentiality Integrity Accountability Session management Transport security Tiered system segregation Legislative and standards compliance (including privacy, government, and industry standards)  Phase 2.2 Review Design and Architecture Applications should have a documented design and architecture. This documentation can include models, textual documents, and other similar artifacts. It is essential to test these artifacts to ensure that the design and architecture enforce the appropriate level of security as defined in the requirements.\nIdentifying security flaws in the design phase is not only one of the most cost-efficient places to identify flaws, but can be one of the most effective places to make changes. For example, if it is identified that the design calls for authorization decisions to be made in multiple places, it may be appropriate to consider a central authorization component. If the application is performing data validation at multiple places, it may be appropriate to develop a central validation framework (ie, fixing input validation in one place, rather than in hundreds of places, is far cheaper).\nIf weaknesses are discovered, they should be given to the system architect for alternative approaches.\nPhase 2.3 Create and Review UML Models Once the design and architecture is complete, build Unified Modeling Language (UML) models that describe how the application works. In some cases, these may already be available. Use these models to confirm with the systems designers an exact understanding of how the application works. If weaknesses are discovered, they should be given to the system architect for alternative approaches.\nPhase 2.4 Create and Review Threat Models Armed with design and architecture reviews and the UML models explaining exactly how the system works, undertake a threat modeling exercise. Develop realistic threat scenarios. Analyze the design and architecture to ensure that these threats have been mitigated, accepted by the business, or assigned to a third party, such as an insurance firm. When identified threats have no mitigation strategies, revisit the design and architecture with the systems architect to modify the design.\nPhase 3 During Development Theoretically, development is the implementation of a design. However, in the real world, many design decisions are made during code development. These are often smaller decisions that were either too detailed to be described in the design, or issues where no policy or standard guidance was offered. If the design and architecture were not adequate, the developer will be faced with many decisions. If there were insufficient policies and standards, the developer will be faced with even more decisions.\nPhase 3.1 Code Walkthrough The security team should perform a code walkthrough with the developers, and in some cases, the system architects. A code walkthrough is a high-level look at the code during which the developers can explain the logic and flow of the implemented code. It allows the code review team to obtain a general understanding of the code, and allows the developers to explain why certain things were developed the way they were.\nThe purpose is not to perform a code review, but to understand at a high level the flow, the layout, and the structure of the code that makes up the application.\nPhase 3.2 Code Reviews Armed with a good understanding of how the code is structured and why certain things were coded the way they were, the tester can now examine the actual code for security defects.\nStatic code reviews validate the code against a set of checklists, including:\n Business requirements for availability, confidentiality, and integrity; OWASP Guide or Top 10 Checklists for technical exposures (depending on the depth of the review); Specific issues relating to the language or framework in use, such as the Scarlet paper for PHP or Microsoft Secure Coding checklists for ASP.NET; and Any industry-specific requirements, such as Sarbanes-Oxley 404, COPPA, ISO/IEC 27002, APRA, HIPAA, Visa Merchant guidelines, or other regulatory regimes.  In terms of return on resources invested (mostly time), static code reviews produce far higher quality returns than any other security review method and rely least on the skill of the reviewer. However, they are not a silver bullet and need to be considered carefully within a full-spectrum testing regime.\nFor more details on OWASP checklists, please refer to the latest edition of the OWASP Top 10.\nPhase 4 During Deployment Phase 4.1 Application Penetration Testing Having tested the requirements, analyzed the design, and performed code review, it might be assumed that all issues have been caught. Hopefully this is the case, but penetration testing the application after it has been deployed provides an additional check to ensure that nothing has been missed.\nPhase 4.2 Configuration Management Testing The application penetration test should include an examination of how the infrastructure was deployed and secured. It is important to review configuration aspects, no matter how small, to ensure that none are left at a default setting that may be vulnerable to exploitation.\nPhase 5 During Maintenance and Operations Phase 5.1 Conduct Operational Management Reviews There needs to be a process in place which details how the operational side of both the application and infrastructure is managed.\nPhase 5.2 Conduct Periodic Health Checks Monthly or quarterly health checks should be performed on both the application and infrastructure to ensure no new security risks have been introduced and that the level of security is still intact.\nPhase 5.3 Ensure Change Verification After every change has been approved and tested in the QA environment and deployed into the production environment, it is vital that the change is checked to ensure that the level of security has not been affected by the change. This should be integrated into the change management process.\nA Typical SDLC Testing Workflow The following figure shows a typical SDLC Testing Workflow.\nFigure 3-1: Typical SDLC testing workflow\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/3-the_owasp_testing_framework/1-penetration_testing_methodologies/",
	"title": "Penetration Testing Methodologies",
	"tags": [],
	"description": "",
	"content": "Penetration Testing Methodologies Summary  Penetration Testing Methodologies  Summary OWASP Testing Guides Penetration Testing Execution Standard PCI Penetration Testing Guide  PCI DSS Penetration Testing Guidance PCI DSS Penetration Testing Requirements   Penetration Testing Framework Technical Guide to Information Security Testing and Assessment Open Source Security Testing Methodology Manual References    OWASP Testing Guides In terms of technical security testing execution, the OWASP testing guides are highly recommended. Depending on the types of the applications, the testing guides are listed below for the web/cloud services, Mobile app (Android/iOS), or IoT firmware respectively.\n OWASP Web Security Testing Guide OWASP Mobile Security Testing Guide OWASP Firmware Security Testing Methodology  Penetration Testing Execution Standard Penetration Testing Execution Standard (PTES) defines penetration testing as 7 phases. Particularly, PTES Technical Guidelines give hands-on suggestions on testing procedures, and recommendation for security testing tools.\n Pre-engagement Interactions Intelligence Gathering Threat Modeling Vulnerability Analysis Exploitation Post Exploitation Reporting  PTES Technical Guidelines\nPCI Penetration Testing Guide Payment Card Industry Data Security Standard (PCI DSS) Requirement 11.3 defines the penetration testing. PCI also defines Penetration Testing Guidance.\nPCI DSS Penetration Testing Guidance The PCI DSS Penetration testing guideline provides guidance on the following:\n Penetration Testing Components Qualifications of a Penetration Tester Penetration Testing Methodologies Penetration Testing Reporting Guidelines  PCI DSS Penetration Testing Requirements The PCI DSS requirement refer to Payment Card Industry Data Security Standard (PCI DSS) Requirement 11.3\n Based on industry-accepted approaches Coverage for CDE and critical systems Includes external and internal testing Test to validate scope reduction Application-layer testing Network-layer tests for network and OS  PCI DSS Penetration Test Guidance\nPenetration Testing Framework The Penetration Testing Framework (PTF) provides comprehensive hands-on penetration testing guide. It also lists usages of the security testing tools in each testing category. The major area of penetration testing includes:\n Network Footprinting (Reconnaissance) Discovery \u0026amp; Probing Enumeration Password cracking Vulnerability Assessment AS/400 Auditing Bluetooth Specific Testing Cisco Specific Testing Citrix Specific Testing Network Backbone Server Specific Tests VoIP Security Wireless Penetration Physical Security Final Report - template  Penetration Testing Framework\nTechnical Guide to Information Security Testing and Assessment Technical Guide to Information Security Testing and Assessment (NIST 800-115) was published by NIST, it includes some assessment techniques listed below.\n Review Techniques Target Identification and Analysis Techniques Target Vulnerability Validation Techniques Security Assessment Planning Security Assessment Execution Post-Testing Activities  The NIST 800-115 can be accessed here\nOpen Source Security Testing Methodology Manual The Open Source Security Testing Methodology Manual (OSSTMM) is a methodology to test the operational security of physical locations, workflow, human security testing, physical security testing, wireless security testing, telecommunication security testing, data networks security testing and compliance. OSSTMM can be supporting reference of ISO 27001 instead of a hands-on or technical application penetration testing guide.\nOSSTMM includes the following key sections:\n Security Analysis Operational Security Metrics Trust Analysis Work Flow Human Security Testing Physical Security Testing Wireless Security Testing Telecommunications Security Testing Data Networks Security Testing Compliance Regulations Reporting with the STAR (Security Test Audit Report)  Open Source Security Testing Methodology Manual\nReferences  PCI Data Security Standard - Penetration TestingGuidance PTES Standard Open Source Security Testing Methodology Manual (OSSTMM) Technical Guide to Information Security Testing and Assessment NIST SP 800-115 HIPAA Security Testing Assessment 2012 Penetration Testing Framework 0.59 OWASP Mobile Security Testing Guide Security Testing Guidelines for Mobile Apps Kali Linux Information Supplement: Requirement 11.3 Penetration Testing  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/00-introdution_and_objectives/",
	"title": "Introdution and Objectives",
	"tags": [],
	"description": "",
	"content": "4.0 Introduction and Objectives This section describes the OWASP web application security testing methodology and explains how to test for evidence of vulnerabilities within the application due to deficiencies with identified security controls.\nWhat is Web Application Security Testing? A security test is a method of evaluating the security of a computer system or network by methodically validating and verifying the effectiveness of application security controls. A web application security test focuses only on evaluating the security of a web application. The process involves an active analysis of the application for any weaknesses, technical flaws, or vulnerabilities. Any security issues that are found will be presented to the system owner, together with an assessment of the impact, a proposal for mitigation or a technical solution.\nWhat is a Vulnerability? A vulnerability is a flaw or weakness in a system\u0026rsquo;s design, implementation, operation or management that could be exploited to compromise the system\u0026rsquo;s security objectives.\nWhat is a Threat? A threat is anything (a malicious external attacker, an internal user, a system instability, etc) that may harm the assets owned by an application (resources of value, such as the data in a database or in the file system) by exploiting a vulnerability.\nWhat is a Test? A test is an action to demonstrate that an application meets the security requirements of its stakeholders.\nThe Approach in Writing this Guide The OWASP approach is open and collaborative:\n Open: every security expert can participate with their experience in the project. Everything is free. Collaborative: brainstorming is performed before the articles are written so the team can share ideas and develop a collective vision of the project. That means rough consensus, a wider audience and increased participation.  This approach tends to create a defined Testing Methodology that will be:\n Consistent Reproducible Rigorous Under quality control  The problems to be addressed are fully documented and tested. It is important to use a method to test all known vulnerabilities and document all the security test activities.\nWhat Is the OWASP Testing Methodology? Security testing will never be an exact science where a complete list of all possible issues that should be tested can be defined. Indeed, security testing is only an appropriate technique for testing the security of web applications under certain circumstances. The goal of this project is to collect all the possible testing techniques, explain these techniques, and keep the guide updated. The OWASP Web Application Security Testing method is based on the black box approach. The tester knows nothing or has very little information about the application to be tested.\nThe testing model consists of:\n Tester: Who performs the testing activities Tools and methodology: The core of this Testing Guide project Application: The black box to test  Testing can be categorized as passive or active:\nPassive Testing During passive testing, a tester tries to understand the application\u0026rsquo;s logic and explores the application as a user. Tools can be used for information gathering. For example, an HTTP proxy can be used to observe all the HTTP requests and responses. At the end of this phase, the tester should generally understand all the access points and functionality of the system (e.g., HTTP headers, parameters, cookies, APIs, technology usage/patterns, etc). The Information Gathering section explains how to perform passive testing.\nFor example, a tester may find a page at the following URL: https://www.example.com/login/auth_form\nThis may indicate an authentication form where the application requests a username and password.\nThe following parameters represent two access points to the application: https://www.example.com/appx?a=1\u0026amp;b=1\nIn this case, the application shows two access points (parameters a and b). All the input points found in this phase represent a target for testing. Keeping track of the directory or call tree of the application and all the access points may be useful during active testing.\nActive Testing During active testing, a tester begins to use the methodologies described in the follow sections.\nThe set of active tests have been split into 12 categories:\n Information Gathering Configuration and Deployment Management Testing Identity Management Testing Authentication Testing Authorization Testing Session Management Testing Input Validation Testing Error Handling Cryptography Business Logic Testing Client-side Testing API Testing  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/",
	"title": "Information Gathering",
	"tags": [],
	"description": "",
	"content": "Chapter 4.1 Information Gathering "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/",
	"title": "Configuration and Deployment Management Testing",
	"tags": [],
	"description": "",
	"content": "Chapter 4.2 Configuration and Deployment Management Testing "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/03-identity_management_testing/",
	"title": "Identity Management Testing",
	"tags": [],
	"description": "",
	"content": "Chapter 4.3 Identity Management Testing "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/01-conduct_search_engine_descovery_reconnaissanse_for_information_leakage/",
	"title": "Conduct Search Engine Descovery Reconnaissanse for Information Leakage",
	"tags": [],
	"description": "",
	"content": "Conduct Search Engine Discovery Reconnaissance for Information Leakage    ID     WSTG-INFO-01    Summary In order for search engines to work, computer programs (or robots) regularly fetch data (referred to as crawling from billions of pages on the web. These programs find web content and functionality by following links from other pages, or by looking at sitemaps. If a website uses a special file called robots.txt to list pages that it does not want search engines to fetch, then the pages listed there will be ignored. This is a basic overview - Google offers a more in-depth explanation of how a search engine works.\nTesters can use search engines to perform reconnaissance on websites and web applications. There are direct and indirect elements to search engine discovery and reconnaissance: direct methods relate to searching the indexes and the associated content from caches, while indirect methods relate to learning sensitive design and configuration information by searching forums, newsgroups, and tendering websites.\nOnce a search engine robot has completed crawling, it commences indexing the web content based on tags and associated attributes, such as \u0026lt;TITLE\u0026gt;, in order to return relevant search results. If the robots.txt file is not updated during the lifetime of the web site, and in-line HTML meta tags that instruct robots not to index content have not been used, then it is possible for indexes to contain web content not intended to be included by the owners. Website owners may use the previously mentioned robots.txt, HTML meta tags, authentication, and tools provided by search engines to remove such content.\nTest Objectives  Identify what sensitive design and configuration information of the application, system, or organization is exposed directly (on the organization\u0026rsquo;s website) or indirectly (via third-party services).  How to Test Use a search engine to search for potentially sensitive information. This may include:\n network diagrams and configurations; archived posts and emails by administrators or other key staff; logon procedures and username formats; usernames, passwords, and private keys; third-party, or cloud service configuration files; revealing error message content; and development, test, User Acceptance Testing (UAT), and staging versions of sites.  Search Engines Do not limit testing to just one search engine provider, as different search engines may generate different results. Search engine results can vary in a few ways, depending on when the engine last crawled content, and the algorithm the engine uses to determine relevant pages. Consider using the following (alphabetically-listed) search engines:\n Baidu, China\u0026rsquo;s most popular search engine. Bing, a search engine owned and operated by Microsoft, and the second most popular worldwide. Supports advanced search keywords. binsearch.info, a search engine for binary Usenet newsgroups. Common Crawl, \u0026ldquo;an open repository of web crawl data that can be accessed and analyzed by anyone.\u0026rdquo; DuckDuckGo, a privacy-focused search engine that compiles results from many different sources. Supports search syntax. Google, which offers the world\u0026rsquo;s most popular search engine, and uses a ranking system to attempt to return the most relevant results. Supports search operators. Internet Archive Wayback Machine, \u0026ldquo;building a digital library of Internet sites and other cultural artifacts in digital form.\u0026rdquo; Startpage, a search engine that uses Google\u0026rsquo;s results without collecting personal information through trackers and logs. Supports search operators. Shodan, a service for searching Internet-connected devices and services. Usage options include a limited free plan as well as paid subscription plans.  Both DuckDuckGo and Startpage offer some increased privacy to users by not utilizing trackers or keeping logs. This can provide reduced information leakage about the tester.\nSearch Operators A search operator is a special keyword or syntax that extends the capabilities of regular search queries, and can help obtain more specific results. They generally take the form of operator:query. Here are some commonly supported search operators:\n site: will limit the search to the provided domain. inurl: will only return results that include the keyword in the URL. intitle: will only return results that have the keyword in the page title. intext: or inbody: will only search for the keyword in the body of pages. filetype: will match only a specific filetype, i.e. png, or php.  For example, to find the web content of owasp.org as indexed by a typical search engine, the syntax required is:\nsite:owasp.org Figure 4.1.1-1: Google Site Operation Search Result Example\nViewing Cached Content To search for content that has previously been indexed, use the cache: operator. This is helpful for viewing content that may have changed since the time it was indexed, or that may no longer be available. Not all search engines provide cached content to search; the most useful source at time of writing is Google.\nTo view owasp.org as it is cached, the syntax is:\ncache:owasp.org Figure 4.1.1-2: Google Cache Operation Search Result Example\nGoogle Hacking, or Dorking Searching with operators can be a very effective discovery technique when combined with the creativity of the tester. Operators can be chained to effectively discover specific kinds of sensitive files and information. This technique, called Google hacking or Dorking, is also possible using other search engines, as long as the search operators are supported.\nA database of dorks, such as Google Hacking Database, is a useful resource that can help uncover specific information. Some categories of dorks available on this database include:\n Footholds Files containing usernames Sensitive Directories Web Server Detection Vulnerable Files Vulnerable Servers Error Messages Files containing juicy info Files containing passwords Sensitive Online Shopping Info  Remediation Carefully consider the sensitivity of design and configuration information before it is posted online.\nPeriodically review the sensitivity of existing design and configuration information that is posted online.\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/02-fingerprint_web_server/",
	"title": "Fingerprint Web Server",
	"tags": [],
	"description": "",
	"content": "Fingerprint Web Server    ID     WSTG-INFO-02    Summary Web server fingerprinting is the task of identifying the type and version of web server that a target is running on. While web server fingerprinting is often encapsulated in automated testing tools, it is important for researchers to understand the fundamentals of how these tools attempt to identify software, and why this is useful.\nAccurately discovering the type of web server that an application runs on can enable security testers to determine if the application is vulnerable to attack. In particular, servers running older versions of software without up-to-date security patches can be susceptible to known version-specific exploits.\nTest Objectives  Determine the version and type of a running web server to enable further discovery of any known vulnerabilities.  How to Test Techniques used for web server fingerprinting include banner grabbing, eliciting responses to malformed requests, and using automated tools to perform more robust scans that use a combination of tactics. The fundamental premise by which all these techniques operate is the same. They all strive to elicit some response from the web server which can then be compared to a database of known responses and behaviors, and thus matched to a known server type.\nBanner Grabbing A banner grab is performed by sending an HTTP request to the web server and examining its response header. This can be accomplished using a variety of tools, including telnet for HTTP requests, or openssl for requests over SSL.\nFor example, here is the response to a request from an Apache server.\nHTTP/1.1 200 OK Date: Thu, 05 Sep 2019 17:42:39 GMT Server: Apache/2.4.41 (Unix) Last-Modified: Thu, 05 Sep 2019 17:40:42 GMT ETag: \u0026#34;75-591d1d21b6167\u0026#34; Accept-Ranges: bytes Content-Length: 117 Connection: close Content-Type: text/html ... Here is another response, this time from nginx.\nHTTP/1.1 200 OK Server: nginx/1.17.3 Date: Thu, 05 Sep 2019 17:50:24 GMT Content-Type: text/html Content-Length: 117 Last-Modified: Thu, 05 Sep 2019 17:40:42 GMT Connection: close ETag: \u0026#34;5d71489a-75\u0026#34; Accept-Ranges: bytes ... Here\u0026rsquo;s what a response from lighttpd looks like.\nHTTP/1.0 200 OK Content-Type: text/html Accept-Ranges: bytes ETag: \u0026#34;4192788355\u0026#34; Last-Modified: Thu, 05 Sep 2019 17:40:42 GMT Content-Length: 117 Connection: close Date: Thu, 05 Sep 2019 17:57:57 GMT Server: lighttpd/1.4.54 In these examples, the server type and version is clearly exposed. However, security-conscious applications may obfuscate their server information by modifying the header. For example, here is an excerpt from the response to a request for a site with a modified header:\nHTTP/1.1 200 OK Server: Website.com Date: Thu, 05 Sep 2019 17:57:06 GMT Content-Type: text/html; charset=utf-8 Status: 200 OK ... In cases where the server information is obscured, testers may guess the type of server based on the ordering of the header fields. Note that in the Apache example above, the fields follow this order:\n Date Server Last-Modified ETag Accept-Ranges Content-Length Connection Content-Type  However, in both the nginx and obscured server examples, the fields in common follow this order:\n Server Date Content-Type  Testers can use this information to guess that the obscured server is nginx. However, considering that a number of different web servers may share the same field ordering and fields can be modified or removed, this method is not definite.\nSending Malformed Requests Web servers may be identified by examining their error responses, and in the cases where they have not been customized, their default error pages. One way to compel a server to present these is by sending intentionally incorrect or malformed requests.\nFor example, here is the response to a request for the non-existent method SANTA CLAUS from an Apache server.\nGET / SANTA CLAUS/1.1 HTTP/1.1 400 Bad Request Date: Fri, 06 Sep 2019 19:21:01 GMT Server: Apache/2.4.41 (Unix) Content-Length: 226 Connection: close Content-Type: text/html; charset=iso-8859-1 \u0026lt;!DOCTYPE HTML PUBLIC \u0026#34;-//IETF//DTD HTML 2.0//EN\u0026#34;\u0026gt; \u0026lt;html\u0026gt;\u0026lt;head\u0026gt; \u0026lt;title\u0026gt;400 Bad Request\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt;\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Bad Request\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Your browser sent a request that this server could not understand.\u0026lt;br /\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; Here is the response to the same request from nginx.\nGET / SANTA CLAUS/1.1 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;404 Not Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.17.3\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Here is the response to the same request from lighttpd.\nGET / SANTA CLAUS/1.1 HTTP/1.0 400 Bad Request Content-Type: text/html Content-Length: 345 Connection: close Date: Sun, 08 Sep 2019 21:56:17 GMT Server: lighttpd/1.4.54 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;iso-8859-1\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE html PUBLIC \u0026#34;-//W3C//DTD XHTML 1.0 Transitional//EN\u0026#34; \u0026#34;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\u0026#34;\u0026gt; \u0026lt;html xmlns=\u0026#34;http://www.w3.org/1999/xhtml\u0026#34; xml:lang=\u0026#34;en\u0026#34; lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;400 Bad Request\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;400 Bad Request\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; As default error pages offer many differentiating factors between types of web servers, their examination can be an effective method for fingerprinting even when server header fields are obscured.\nUsing Automated Scanning Tools As stated earlier, web server fingerprinting is often included as a functionality of automated scanning tools. These tools are able to make requests similar to those demonstrated above, as well as send other more server-specific probes. Automated tools can compare responses from web servers much faster than manual testing, and utilize large databases of known responses to attempt server identification. For these reasons, automated tools are more likely to produce accurate results.\nHere are some commonly-used scan tools that include web server fingerprinting functionality.\n Netcraft, an online tool that scans websites for information, including the web server. Nikto, an Open Source command-line scanning tool. Nmap, an Open Source command-line tool that also has a GUI, Zenmap.  Remediation While exposed server information is not necessarily in itself a vulnerability, it is information that can assist attackers in exploiting other vulnerabilities that may exist. Exposed server information can also lead attackers to find version-specific server vulnerabilities that can be used to exploit unpatched servers. For this reason it is recommended that some precautions be taken. These actions include:\n Obscuring web server information in headers, such as with Apache\u0026rsquo;s mod_headers module. Using a hardened reverse proxy server to create an additional layer of security between the web server and the Internet. Ensuring that web servers are kept up-to-date with the latest software and security patches.  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/03-review_webserver_metafiles_for_information_leakage/",
	"title": "Review Webserver Metafiles for Information Leakage",
	"tags": [],
	"description": "",
	"content": "Review Webserver Metafiles for Information Leakage    ID     WSTG-INFO-03    Summary This section describes how to test various metadata files for information leakage of the web application\u0026rsquo;s path(s), or functionality. Furthermore, the list of directories that are to be avoided by Spiders, Robots, or Crawlers can also be created as a dependency for Map execution paths through application. Other information may also be collected to identify attack surface, technology details, or for use in social engineering engagement.\nTest Objectives  Identify hidden or obfuscated paths and functionality through the analysis of metadata files. Extract and map other information that could lead to better understanding of the systems at hand.  How to Test  Any of the actions performed below with wget could also be done with curl. Many Dynamic Application Security Testing (DAST) tools such as ZAP and Burp Suite include checks or parsing for these resources as part of their spider/crawler functionality. They can also be identified using various Google Dorks or leveraging advanced search features such as inurl:.\n Robots Web Spiders, Robots, or Crawlers retrieve a web page and then recursively traverse hyperlinks to retrieve further web content. Their accepted behavior is specified by the Robots Exclusion Protocol of the robots.txt file in the web root directory.\nAs an example, the beginning of the robots.txt file from Google sampled on 2020 May 5 is quoted below:\nUser-agent: * Disallow: /search Allow: /search/about Allow: /search/static Allow: /search/howsearchworks Disallow: /sdch ... The User-Agent directive refers to the specific web spider/robot/crawler. For example, the User-Agent: Googlebot refers to the spider from Google while User-Agent: bingbot refers to a crawler from Microsoft. User-Agent: * in the example above applies to all web spiders/robots/crawlers.\nThe Disallow directive specifies which resources are prohibited by spiders/robots/crawlers. In the example above, the following are prohibited:\n... Disallow: /search ... Disallow: /sdch ... Web spiders/robots/crawlers can intentionally ignore the Disallow directives specified in a robots.txt file, such as those from Social Networks to ensure that shared linked are still valid. Hence, robots.txt should not be considered as a mechanism to enforce restrictions on how web content is accessed, stored, or republished by third parties.\nThe robots.txt file is retrieved from the web root directory of the web server. For example, to retrieve the robots.txt from www.google.com using wget or curl:\n$ curl -O -Ss http://www.google.com/robots.txt \u0026amp;\u0026amp; head -n5 robots.txt User-agent: * Disallow: /search Allow: /search/about Allow: /search/static Allow: /search/howsearchworks ... Analyze robots.txt Using Google Webmaster Tools Web site owners can use the Google \u0026ldquo;Analyze robots.txt\u0026rdquo; function to analyze the website as part of its Google Webmaster Tools. This tool can assist with testing and the procedure is as follows:\n Sign into Google Webmaster Tools with a Google account. On the dashboard, enter the URL for the site to be analyzed. Choose between the available methods and follow the on screen instruction.  META Tags \u0026lt;META\u0026gt; tags are located within the HEAD section of each HTML document and should be consistent across a web site in the event that the robot/spider/crawler start point does not begin from a document link other than webroot i.e. a deep link. Robots directive can also be specified through use of a specific META tag.\nRobots META Tag If there is no \u0026lt;META NAME=\u0026quot;ROBOTS\u0026quot; ... \u0026gt; entry then the \u0026ldquo;Robots Exclusion Protocol\u0026rdquo; defaults to INDEX,FOLLOW respectively. Therefore, the other two valid entries defined by the \u0026ldquo;Robots Exclusion Protocol\u0026rdquo; are prefixed with NO... i.e. NOINDEX and NOFOLLOW.\nBased on the Disallow directive(s) listed within the robots.txt file in webroot, a regular expression search for \u0026lt;META NAME=\u0026quot;ROBOTS\u0026quot; within each web page is undertaken and the result compared to the robots.txt file in webroot.\nMiscellaneous META Information Tags Organizations often embed informational META tags in web content to support various technologies such as screen readers, social networking previews, search engine indexing, etc. Such meta-information can be of value to testers in identifying technologies used, and additional paths/functionality to explore and test. The following meta information was retrieved from www.whitehouse.gov via View Page Source on 2020 May 05:\n... \u0026lt;meta property=\u0026#34;og:locale\u0026#34; content=\u0026#34;en_US\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:type\u0026#34; content=\u0026#34;website\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:title\u0026#34; content=\u0026#34;The White House\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:description\u0026#34; content=\u0026#34;We, the citizens of America, are now joined in a great national effort to rebuild our country and to restore its promise for all. – President Donald Trump.\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:url\u0026#34; content=\u0026#34;https://www.whitehouse.gov/\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:site_name\u0026#34; content=\u0026#34;The White House\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;fb:app_id\u0026#34; content=\u0026#34;1790466490985150\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:image\u0026#34; content=\u0026#34;https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:image:secure_url\u0026#34; content=\u0026#34;https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;twitter:card\u0026#34; content=\u0026#34;summary_large_image\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;twitter:description\u0026#34; content=\u0026#34;We, the citizens of America, are now joined in a great national effort to rebuild our country and to restore its promise for all. – President Donald Trump.\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;twitter:title\u0026#34; content=\u0026#34;The White House\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;twitter:site\u0026#34; content=\u0026#34;@whitehouse\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;twitter:image\u0026#34; content=\u0026#34;https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;twitter:creator\u0026#34; content=\u0026#34;@whitehouse\u0026#34; /\u0026gt; ... \u0026lt;meta name=\u0026#34;apple-mobile-web-app-title\u0026#34; content=\u0026#34;The White House\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;application-name\u0026#34; content=\u0026#34;The White House\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;msapplication-TileColor\u0026#34; content=\u0026#34;#0c2644\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#f5f5f5\u0026#34;\u0026gt; ... Sitemaps A sitemap is a file where a developer or organization can provide information about the pages, videos, and other files offered by the site or application, and the relationship between them. Search engines can use this file to more intelligently explore your site. Testers can use sitemap.xml files to learn more about the site or application to explore it more completely.\nThe following excerpt is from Google\u0026rsquo;s primary sitemap retrieved 2020 May 05.\n$ wget --no-verbose https://www.google.com/sitemap.xml \u0026amp;\u0026amp; head -n8 sitemap.xml 2020-05-05 12:23:30 URL:https://www.google.com/sitemap.xml [2049] -\u0026gt; \u0026#34;sitemap.xml\u0026#34; [1] \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;sitemapindex xmlns=\u0026#34;http://www.google.com/schemas/sitemap/0.84\u0026#34;\u0026gt; \u0026lt;sitemap\u0026gt; \u0026lt;loc\u0026gt;https://www.google.com/gmail/sitemap.xml\u0026lt;/loc\u0026gt; \u0026lt;/sitemap\u0026gt; \u0026lt;sitemap\u0026gt; \u0026lt;loc\u0026gt;https://www.google.com/forms/sitemaps.xml\u0026lt;/loc\u0026gt; \u0026lt;/sitemap\u0026gt; ... Exploring from there a tester may wish to retrieve the gmail sitemap https://www.google.com/gmail/sitemap.xml:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;urlset xmlns=\u0026#34;http://www.sitemaps.org/schemas/sitemap/0.9\u0026#34; xmlns:xhtml=\u0026#34;http://www.w3.org/1999/xhtml\u0026#34;\u0026gt; \u0026lt;url\u0026gt; \u0026lt;loc\u0026gt;https://www.google.com/intl/am/gmail/about/\u0026lt;/loc\u0026gt; \u0026lt;xhtml:link href=\u0026#34;https://www.google.com/gmail/about/\u0026#34; hreflang=\u0026#34;x-default\u0026#34; rel=\u0026#34;alternate\u0026#34;/\u0026gt; \u0026lt;xhtml:link href=\u0026#34;https://www.google.com/intl/el/gmail/about/\u0026#34; hreflang=\u0026#34;el\u0026#34; rel=\u0026#34;alternate\u0026#34;/\u0026gt; \u0026lt;xhtml:link href=\u0026#34;https://www.google.com/intl/it/gmail/about/\u0026#34; hreflang=\u0026#34;it\u0026#34; rel=\u0026#34;alternate\u0026#34;/\u0026gt; \u0026lt;xhtml:link href=\u0026#34;https://www.google.com/intl/ar/gmail/about/\u0026#34; hreflang=\u0026#34;ar\u0026#34; rel=\u0026#34;alternate\u0026#34;/\u0026gt; ... Security TXT security.txt is a proposed standard which allows websites to define security policies and contact details. There are multiple reasons this might be of interest in testing scenarios, including but not limited to:\n Identifying further paths or resources to include in discovery/analysis. Open Source intelligence gathering. Finding information on Bug Bounties, etc. Social Engineering.  The file may be present either in the root of the webserver or in the .well-known/ directory. Ex:\n https://example.com/security.txt https://example.com/.well-known/security.txt  Here is a real world example retrieved from LinkedIn 2020 May 05:\n$ wget --no-verbose https://www.linkedin.com/.well-known/security.txt \u0026amp;\u0026amp; cat security.txt 2020-05-07 12:56:51 URL:https://www.linkedin.com/.well-known/security.txt [333/333] -\u0026gt; \u0026#34;security.txt\u0026#34; [1] # Conforms to IETF `draft-foudil-securitytxt-07` Contact: mailto:security@linkedin.com Contact: https://www.linkedin.com/help/linkedin/answer/62924 Encryption: https://www.linkedin.com/help/linkedin/answer/79676 Canonical: https://www.linkedin.com/.well-known/security.txt Policy: https://www.linkedin.com/help/linkedin/answer/62924 Humans TXT humans.txt is an initiative for knowing the people behind a website. It takes the form of a text file that contains information about the different people who have contributed to building the website. See humanstxt for more info. This file often (though not always) contains information for career or job sites/paths.\nThe following example was retrieved from Google 2020 May 05:\n$ wget --no-verbose https://www.google.com/humans.txt \u0026amp;\u0026amp; cat humans.txt 2020-05-07 12:57:52 URL:https://www.google.com/humans.txt [286/286] -\u0026gt; \u0026#34;humans.txt\u0026#34; [1] Google is built by a large team of engineers, designers, researchers, robots, and others in many different sites across the globe. It is updated continuously, and built with more tools and technologies than we can shake a stick at. If you\u0026#39;d like to help us out, see careers.google.com. Other .well-known Information Sources There are other RFCs and Internet drafts which suggest standardized uses of files within the .well-known/ directory. Lists of which can be found here or here.\nIt would be fairly simple for a tester to review the RFC/drafts are create a list to be supplied to a crawler or fuzzer, in order to verify the existence or content of such files.\nTools  Browser (View Source or Dev Tools functionality) curl wget Burp Suite ZAP  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/04-enumerate_applications_on_webserver/",
	"title": "Enumerate Applications on Webserver",
	"tags": [],
	"description": "",
	"content": "Enumerate Applications on Webserver    ID     WSTG-INFO-04    Summary A paramount step in testing for web application vulnerabilities is to find out which particular applications are hosted on a web server. Many applications have known vulnerabilities and known attack strategies that can be exploited in order to gain remote control or to exploit data. In addition, many applications are often misconfigured or not updated, due to the perception that they are only used \u0026ldquo;internally\u0026rdquo; and therefore no threat exists. With the proliferation of virtual web servers, the traditional 1:1-type relationship between an IP address and a web server is losing much of its original significance. It is not uncommon to have multiple web sites or applications whose symbolic names resolve to the same IP address. This scenario is not limited to hosting environments, but also applies to ordinary corporate environments as well.\nSecurity professionals are sometimes given a set of IP addresses as a target to test. It is arguable that this scenario is more akin to a penetration test-type engagement, but in any case it is expected that such an assignment would test all web applications accessible through this target. The problem is that the given IP address hosts an HTTP service on port 80, but if a tester should access it by specifying the IP address (which is all they know) it reports \u0026ldquo;No web server configured at this address\u0026rdquo; or a similar message. But that system could \u0026ldquo;hide\u0026rdquo; a number of web applications, associated to unrelated symbolic (DNS) names. Obviously, the extent of the analysis is deeply affected by the tester tests all applications or only tests the applications that they are aware of.\nSometimes, the target specification is richer. The tester may be given a list of IP addresses and their corresponding symbolic names. Nevertheless, this list might convey partial information, i.e., it could omit some symbolic names and the client may not even being aware of that (this is more likely to happen in large organizations).\nOther issues affecting the scope of the assessment are represented by web applications published at non-obvious URLs (e.g., http://www.example.com/some-strange-URL), which are not referenced elsewhere. This may happen either by error (due to misconfigurations), or intentionally (for example, unadvertised administrative interfaces).\nTo address these issues, it is necessary to perform web application discovery.\nTest Objectives  Enumerate the applications within scope that exist on a web server.  How to Test Web application discovery is a process aimed at identifying web applications on a given infrastructure. The latter is usually specified as a set of IP addresses (maybe a net block), but may consist of a set of DNS symbolic names or a mix of the two. This information is handed out prior to the execution of an assessment, be it a classic-style penetration test or an application-focused assessment. In both cases, unless the rules of engagement specify otherwise (e.g., test only the application located at the URL http://www.example.com/), the assessment should strive to be the most comprehensive in scope, i.e. it should identify all the applications accessible through the given target. The following examples examine a few techniques that can be employed to achieve this goal.\n Some of the following techniques apply to Internet-facing web servers, namely DNS and reverse-IP web-based search services and the use of search engines. Examples make use of private IP addresses (such as 192.168.1.100), which, unless indicated otherwise, represent generic IP addresses and are used only for anonymity purposes.\n There are three factors influencing how many applications are related to a given DNS name (or an IP address):\n  Different Base URL\nThe obvious entry point for a web application is www.example.com, i.e., with this shorthand notation we think of the web application originating at http://www.example.com/ (the same applies for https). However, even though this is the most common situation, there is nothing forcing the application to start at /.\nFor example, the same symbolic name may be associated to three web applications such as: http://www.example.com/url1 http://www.example.com/url2 http://www.example.com/url3\nIn this case, the URL http://www.example.com/ would not be associated with a meaningful page, and the three applications would be hidden, unless the tester explicitly knows how to reach them, i.e., the tester knows url1, url2 or url3. There is usually no need to publish web applications in this way, unless the owner doesn’t want them to be accessible in a standard way, and is prepared to inform the users about their exact location. This doesn’t mean that these applications are secret, just that their existence and location is not explicitly advertised.\n  Non-standard Ports\nWhile web applications usually live on port 80 (http) and 443 (https), there is nothing magic about these port numbers. In fact, web applications may be associated with arbitrary TCP ports, and can be referenced by specifying the port number as follows: http[s]://www.example.com:port/. For example, http://www.example.com:20000/.\n  Virtual Hosts\nDNS allows a single IP address to be associated with one or more symbolic names. For example, the IP address 192.168.1.100 might be associated to DNS names www.example.com, helpdesk.example.com, webmail.example.com. It is not necessary that all the names belong to the same DNS domain. This 1-to-N relationship may be reflected to serve different content by using so called virtual hosts. The information specifying the virtual host we are referring to is embedded in the HTTP 1.1 Host header.\nOne would not suspect the existence of other web applications in addition to the obvious www.example.com, unless they know of helpdesk.example.com and webmail.example.com.\n  Approaches to Address Issue 1 - Non-standard URLs There is no way to fully ascertain the existence of non-standard-named web applications. Being non-standard, there is no fixed criteria governing the naming convention, however there are a number of techniques that the tester can use to gain some additional insight.\nFirst, if the web server is mis-configured and allows directory browsing, it may be possible to spot these applications. Vulnerability scanners may help in this respect.\nSecond, these applications may be referenced by other web pages and there is a chance that they have been spidered and indexed by web search engines. If testers suspect the existence of such hidden applications on www.example.com they could search using the site operator and examining the result of a query for site: www.example.com. Among the returned URLs there could be one pointing to such a non-obvious application.\nAnother option is to probe for URLs which might be likely candidates for non-published applications. For example, a web mail front end might be accessible from URLs such as https://www.example.com/webmail, https://webmail.example.com/, or https://mail.example.com/. The same holds for administrative interfaces, which may be published at hidden URLs (for example, a Tomcat administrative interface), and yet not referenced anywhere. So doing a bit of dictionary-style searching (or \u0026ldquo;intelligent guessing\u0026rdquo;) could yield some results. Vulnerability scanners may help in this respect.\nApproaches to Address Issue 2 - Non-standard Ports It is easy to check for the existence of web applications on non-standard ports. A port scanner such as nmap is capable of performing service recognition by means of the -sV option, and will identify http[s] services on arbitrary ports. What is required is a full scan of the whole 64k TCP port address space.\nFor example, the following command will look up, with a TCP connect scan, all open ports on IP 192.168.1.100 and will try to determine what services are bound to them (only essential switches are shown – nmap features a broad set of options, whose discussion is out of scope):\nnmap –Pn –sT –sV –p0-65535 192.168.1.100\nIt is sufficient to examine the output and look for http or the indication of SSL-wrapped services (which should be probed to confirm that they are https). For example, the output of the previous command could look like:\nInteresting ports on 192.168.1.100: (The 65527 ports scanned but not shown below are in state: closed) PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 3.5p1 (protocol 1.99) 80/tcp open http Apache httpd 2.0.40 ((Red Hat Linux)) 443/tcp open ssl OpenSSL 901/tcp open http Samba SWAT administration server 1241/tcp open ssl Nessus security scanner 3690/tcp open unknown 8000/tcp open http-alt? 8080/tcp open http Apache Tomcat/Coyote JSP engine 1.1 From this example, one see that:\n There is an Apache HTTP server running on port 80. It looks like there is an HTTPS server on port 443 (but this needs to be confirmed, for example, by visiting https://192.168.1.100 with a browser). On port 901 there is a Samba SWAT web interface. The service on port 1241 is not HTTPS, but is the SSL-wrapped Nessus daemon. Port 3690 features an unspecified service (nmap gives back its fingerprint - here omitted for clarity - together with instructions to submit it for incorporation in the nmap fingerprint database, provided you know which service it represents). Another unspecified service on port 8000; this might possibly be HTTP, since it is not uncommon to find HTTP servers on this port. Let\u0026rsquo;s examine this issue:  $ telnet 192.168.10.100 8000 Trying 192.168.1.100... Connected to 192.168.1.100. Escape character is \u0026#39;^]\u0026#39;. GET / HTTP/1.0 HTTP/1.0 200 OK pragma: no-cache Content-Type: text/html Server: MX4J-HTTPD/1.0 expires: now Cache-Control: no-cache \u0026lt;html\u0026gt; ... This confirms that in fact it is an HTTP server. Alternatively, testers could have visited the URL with a web browser; or used the GET or HEAD Perl commands, which mimic HTTP interactions such as the one given above (however HEAD requests may not be honored by all servers).\n Apache Tomcat running on port 8080.  The same task may be performed by vulnerability scanners, but first check that the scanner of choice is able to identify HTTP[S] services running on non-standard ports. For example, Nessus is capable of identifying them on arbitrary ports (provided it is instructed to scan all the ports), and will provide, with respect to nmap, a number of tests on known web server vulnerabilities, as well as on the SSL configuration of HTTPS services. As hinted before, Nessus is also able to spot popular applications or web interfaces which could otherwise go unnoticed (for example, a Tomcat administrative interface).\nApproaches to Address Issue 3 - Virtual Hosts There are a number of techniques which may be used to identify DNS names associated to a given IP address x.y.z.t.\nDNS Zone Transfers This technique has limited use nowadays, given the fact that zone transfers are largely not honored by DNS servers. However, it may be worth a try. First of all, testers must determine the name servers serving x.y.z.t. If a symbolic name is known for x.y.z.t (let it be www.example.com), its name servers can be determined by means of tools such as nslookup, host, or dig, by requesting DNS NS records.\nIf no symbolic names are known for x.y.z.t, but the target definition contains at least a symbolic name, testers may try to apply the same process and query the name server of that name (hoping that x.y.z.t will be served as well by that name server). For example, if the target consists of the IP address x.y.z.t and the name mail.example.com, determine the name servers for domain example.com.\nThe following example shows how to identify the name servers for www.owasp.org by using the host command:\n$ host -t ns www.owasp.org www.owasp.org is an alias for owasp.org. owasp.org name server ns1.secure.net. owasp.org name server ns2.secure.net. A zone transfer may now be requested to the name servers for domain example.com. If the tester is lucky, they will get back a list of the DNS entries for this domain. This will include the obvious www.example.com and the not-so-obvious helpdesk.example.com and webmail.example.com (and possibly others). Check all names returned by the zone transfer and consider all of those which are related to the target being evaluated.\nTrying to request a zone transfer for owasp.org from one of its name servers:\n$ host -l www.owasp.org ns1.secure.net Using domain server: Name: ns1.secure.net Address: 192.220.124.10#53 Aliases: Host www.owasp.org not found: 5(REFUSED) ; Transfer failed. DNS Inverse Queries This process is similar to the previous one, but relies on inverse (PTR) DNS records. Rather than requesting a zone transfer, try setting the record type to PTR and issue a query on the given IP address. If the testers are lucky, they may get back a DNS name entry. This technique relies on the existence of IP-to-symbolic name maps, which is not guaranteed.\nWeb-based DNS Searches This kind of search is akin to DNS zone transfer, but relies on web-based services that enable name-based searches on DNS. One such service is the Netcraft Search DNS service. The tester may query for a list of names belonging to your domain of choice, such as example.com. Then they will check whether the names they obtained are pertinent to the target they are examining.\nReverse-IP Services Reverse-IP services are similar to DNS inverse queries, with the difference that the testers query a web-based application instead of a name server. There are a number of such services available. Since they tend to return partial (and often different) results, it is better to use multiple services to obtain a more comprehensive analysis.\nDomain Tools Reverse IP (requires free membership)\nBing, syntax: ip:x.x.x.x\nWebhosting Info, syntax: http://whois.webhosting.info/x.x.x.x\nDNSstuff (multiple services available)\nNet Square (multiple queries on domains and IP addresses, requires installation)\nThe following example shows the result of a query to one of the above reverse-IP services to 216.48.3.18, the IP address of www.owasp.org. Three additional non-obvious symbolic names mapping to the same address have been revealed.\nFigure 4.1.4-1: OWASP Whois Info\nGoogling Following information gathering from the previous techniques, testers can rely on search engines to possibly refine and increment their analysis. This may yield evidence of additional symbolic names belonging to the target, or applications accessible via non-obvious URLs.\nFor instance, considering the previous example regarding www.owasp.org, the tester could query Google and other search engines looking for information (hence, DNS names) related to the newly discovered domains of webgoat.org, webscarab.com, and webscarab.net.\nGoogling techniques are explained in Testing: Spiders, Robots, and Crawlers.\nTools  DNS lookup tools such as nslookup, dig and similar. Search engines (Google, Bing and other major search engines). Specialized DNS-related web-based search service: see text. Nmap Nessus Vulnerability Scanner Nikto  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/05-review_webpage_content_for_information_leakage/",
	"title": "Review Webpage Content for Information Leakage",
	"tags": [],
	"description": "",
	"content": "Review Webpage Content for Information Leakage    ID     WSTG-INFO-05    Summary It is very common, and even recommended, for programmers to include detailed comments and metadata on their source code. However, comments and metadata included into the HTML code might reveal internal information that should not be available to potential attackers. Comments and metadata review should be done in order to determine if any information is being leaked.\nFor modern web apps, the use of client-Side JavaScript for the front-end is becoming more popular. Popular front-end construction technologies use client-side JavaScript like ReactJS, AngularJS, or Vue. Similar to the comments and metadata in HTML code, many programmers also hardcod sensitive information in JavaScript variables on the front-end. Sensitive information can include (but is not limited to): Private API Keys (e.g. an unrestricted Google Map API Key), internal IP addresses, sensitive routes (e.g. route to hidden admin pages or functionality), or even credentials. This sensitive information can be leaked from such front-end JavaScript code. A review should be done in order to determine if any sensitive information leaked which could be used by attackers for abuse.\nFor large web applications, performance issues are a big concern to programmers. Programmers have used different methods to optimize front-end performance, including Syntactically Awesome Style Sheets (SASS), Sassy CSS (SCSS), webpack, etc. Using these technologies, front-end code will sometimes become harder to understand and difficult to debug, and because of it, programmers often deploy source map files for debugging purposes. A \u0026ldquo;source map\u0026rdquo; is a special file that connects a minified/uglified version of an asset (CSS or JavaScript) to the original authored version. Programmers are still debating whether or not to bring source map files to the production environment. However, it is undeniable that source map files or files for debugging if released to the production environment will make their source more human-readable. It can make it easier for attackers to find vulnerabilities from the front-end or collect sensitive information from it. JavaScript code review should be done in order to determine if any debug files are exposed from the front-end. Depending on the context and sensitivity of the project, a security expert should decide whether the files should exist in the production environment or not.\nTest Objectives  Review webpage comments and metadata to find any information leakage. Gather JavaScript files and review the JS code to better understand the application and to find any information leakage. Identify if source map files or other front-end debug files exist.  How to Test Review webpage comments and metadata HTML comments are often used by the developers to include debugging information about the application. Sometimes, they forget about the comments and they leave them in production environments. Testers should look for HTML comments which start with \u0026lt;!--.\nCheck HTML source code for comments containing sensitive information that can help the attacker gain more insight about the application. It might be SQL code, usernames and passwords, internal IP addresses, or debugging information.\n... \u0026lt;div class=\u0026#34;table2\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col1\u0026#34;\u0026gt;1\u0026lt;/div\u0026gt;\u0026lt;div class=\u0026#34;col2\u0026#34;\u0026gt;Mary\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col1\u0026#34;\u0026gt;2\u0026lt;/div\u0026gt;\u0026lt;div class=\u0026#34;col2\u0026#34;\u0026gt;Peter\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;col1\u0026#34;\u0026gt;3\u0026lt;/div\u0026gt;\u0026lt;div class=\u0026#34;col2\u0026#34;\u0026gt;Joe\u0026lt;/div\u0026gt; \u0026lt;!-- Query: SELECT id, name FROM app.users WHERE active=\u0026#39;1\u0026#39; --\u0026gt; \u0026lt;/div\u0026gt; ... The tester may even find something like this:\n\u0026lt;!-- Use the DB administrator password for testing: f@keP@a$$w0rD --\u0026gt; Check HTML version information for valid version numbers and Data Type Definition (DTD) URLs\n\u0026lt;!DOCTYPE HTML PUBLIC \u0026#34;-//W3C//DTD HTML 4.01//EN\u0026#34; \u0026#34;http://www.w3.org/TR/html4/strict.dtd\u0026#34;\u0026gt;  strict.dtd \u0026ndash; default strict DTD loose.dtd \u0026ndash; loose DTD frameset.dtd \u0026ndash; DTD for frameset documents  Some META tags do not provide active attack vectors but instead allow an attacker to profile an application:\n\u0026lt;META name=\u0026#34;Author\u0026#34; content=\u0026#34;Andrew Muller\u0026#34;\u0026gt; A common (but not WCAG compliant) META tag is Refresh.\n\u0026lt;META http-equiv=\u0026#34;Refresh\u0026#34; content=\u0026#34;15;URL=https://www.owasp.org/index.html\u0026#34;\u0026gt; A common use for META tag is to specify keywords that a search engine may use to improve the quality of search results.\n\u0026lt;META name=\u0026#34;keywords\u0026#34; lang=\u0026#34;en-us\u0026#34; content=\u0026#34;OWASP, security, sunshine, lollipops\u0026#34;\u0026gt; Although most web servers manage search engine indexing via the robots.txt file, it can also be managed by META tags. The tag below will advise robots to not index and not follow links on the HTML page containing the tag.\n\u0026lt;META name=\u0026#34;robots\u0026#34; content=\u0026#34;none\u0026#34;\u0026gt; The Platform for Internet Content Selection (PICS) and Protocol for Web Description Resources (POWDER) provide infrastructure for associating metadata with Internet content.\nIdentifying JavaScript Code and Gathering JavaScript Files Programmers often hardcode sensitive information with JavaScript variables on the front-end. Testers should check HTML source code and look for JavaScript code between \u0026lt;script\u0026gt; and \u0026lt;/script\u0026gt; tags. Testers should also identify external JavaScript files to review the code (JavaScript files have the file extension .js and name of the JavaScript file usually put in the src (source) attribute of a \u0026lt;script\u0026gt; tag).\nCheck JavaScript code for any sensitive information leaks which could be used by attackers to further abuse or manipulate the system. Look for values such as: API keys, internal IP addresses, sensitive routes, or credentials. For example:\nconst myS3Credentials = { accessKeyId: config(\u0026#39;AWSS3AccessKeyID\u0026#39;), secretAcccessKey: config(\u0026#39;AWSS3SecretAccessKey\u0026#39;), }; The tester may even find something like this:\nvar conString = \u0026#34;tcp://postgres:1234@localhost/postgres\u0026#34;; When an API Key is found, testers can check if the API Key restrictions are set per service or by IP, HTTP referrer, application, SDK, etc.\nFor example, if testers found a Google Map API Key, they can check if this API Key is restricted by IP or restricted only per the Google Map APIs. If the Google API Key is restricted only per the Google Map APIs, attackers can still use that API Key to query unrestricted Google Map APIs and the application owner must to pay for that.\n\u0026lt;script type=\u0026#34;application/json\u0026#34;\u0026gt; ... {\u0026#34;GOOGLE_MAP_API_KEY\u0026#34;:\u0026#34;AIzaSyDUEBnKgwiqMNpDplT6ozE4Z0XxuAbqDi4\u0026#34;, \u0026#34;RECAPTCHA_KEY\u0026#34;:\u0026#34;6LcPscEUiAAAAHOwwM3fGvIx9rsPYUq62uRhGjJ0\u0026#34;} ... \u0026lt;/script\u0026gt; In some cases, testers may find sensitive routes from JavaScript code, such as links to internal or hidden admin pages.\n\u0026lt;script type=\u0026#34;application/json\u0026#34;\u0026gt; ... \u0026#34;runtimeConfig\u0026#34;:{\u0026#34;BASE_URL_VOUCHER_API\u0026#34;:\u0026#34;https://staging-voucher.victim.net/api\u0026#34;, \u0026#34;BASE_BACKOFFICE_API\u0026#34;:\u0026#34;https://10.10.10.2/api\u0026#34;, \u0026#34;ADMIN_PAGE\u0026#34;:\u0026#34;/hidden_administrator\u0026#34;} ... \u0026lt;/script\u0026gt; Identifying Source Map Files Source map files will usually be loaded when DevTools open. Testers can also find source map files by adding the \u0026ldquo;.map\u0026rdquo; extension after the extension of each external JavaScript file. For example, if a tester sees a /static/js/main.chunk.js file, they can then check for its source map file by visiting /static/js/main.chunk.js.map.\nBlack-Box Testing Check source map files for any sensitive information that can help the attacker gain more insight about the application. For example:\n{ \u0026#34;version\u0026#34;: 3, \u0026#34;file\u0026#34;: \u0026#34;static/js/main.chunk.js\u0026#34;, \u0026#34;sources\u0026#34;: [ \u0026#34;/home/sysadmin/cashsystem/src/actions/index.js\u0026#34;, \u0026#34;/home/sysadmin/cashsystem/src/actions/reportAction.js\u0026#34;, \u0026#34;/home/sysadmin/cashsystem/src/actions/cashoutAction.js\u0026#34;, \u0026#34;/home/sysadmin/cashsystem/src/actions/userAction.js\u0026#34;, \u0026#34;...\u0026#34; ], \u0026#34;...\u0026#34; } When websites load source map files, the front-end source code will become readable and easier to debug.\nTools  Wget Browser \u0026ldquo;view source\u0026rdquo; function Eyeballs Curl Burp Suite Waybackurls Google Maps API Scanner  References  KeyHacks  Whitepapers  HTML version 4.01 XHTML HTML version 5  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/06-identify_application_entry_points/",
	"title": "Identify Application Entry Points",
	"tags": [],
	"description": "",
	"content": "Identify Application Entry Points    ID     WSTG-INFO-06    Summary Enumerating the application and its attack surface is a key precursor before any thorough testing can be undertaken, as it allows the tester to identify likely areas of weakness. This section aims to help identify and map out areas within the application that should be investigated once enumeration and mapping have been completed.\nTest Objectives  Identify possible entry and injection points through request and response analysis.  How to Test Before any testing begins, the tester should always get a good understanding of the application and how the user and browser communicates with it. As the tester walks through the application, they should pay attention to all HTTP requests as well as every parameter and form field that is passed to the application. They should pay special attention to when GET requests are used and when POST requests are used to pass parameters to the application. In addition, they also need to pay attention to when other methods for RESTful services are used.\nNote that in order to see the parameters sent in the body of requests such as a POST request, the tester may want to use a tool such as an intercepting proxy (See tools). Within the POST request, the tester should also make special note of any hidden form fields that are being passed to the application, as these usually contain sensitive information, such as state information, quantity of items, the price of items, that the developer never intended for anyone to see or change.\nIn the author\u0026rsquo;s experience, it has been very useful to use an intercepting proxy and a spreadsheet for this stage of testing. The proxy will keep track of every request and response between the tester and the application as they explore it. Additionally, at this point, testers usually trap every request and response so that they can see exactly every header, parameter, etc. that is being passed to the application and what is being returned. This can be quite tedious at times, especially on large interactive sites (think of a banking application). However, experience will show what to look for and this phase can be significantly reduced.\nAs the tester walks through the application, they should take note of any interesting parameters in the URL, custom headers, or body of the requests/responses, and save them in a spreadsheet. The spreadsheet should include the page requested (it might be good to also add the request number from the proxy, for future reference), the interesting parameters, the type of request (GET, POST, etc), if access is authenticated/unauthenticated, if TLS is used, if it\u0026rsquo;s part of a multi-step process, if WebSockers are used, and any other relevant notes. Once they have every area of the application mapped out, then they can go through the application and test each of the areas that they have identified and make notes for what worked and what didn\u0026rsquo;t work. The rest of this guide will identify how to test each of these areas of interest, but this section must be undertaken before any of the actual testing can commence.\nBelow are some points of interests for all requests and responses. Within the requests section, focus on the GET and POST methods, as these appear the majority of the requests. Note that other methods, such as PUT and DELETE, can be used. Often, these more rare requests, if allowed, can expose vulnerabilities. There is a special section in this guide dedicated for testing these HTTP methods.\nRequests  Identify where GETs are used and where POSTs are used. Identify all parameters used in a POST request (these are in the body of the request). Within the POST request, pay special attention to any hidden parameters. When a POST is sent all the form fields (including hidden parameters) will be sent in the body of the HTTP message to the application. These typically aren\u0026rsquo;t seen unless a proxy or view the HTML source code is used. In addition, the next page shown, its data, and the level of access can all be different depending on the value of the hidden parameter(s). Identify all parameters used in a GET request (i.e., URL), in particular the query string (usually after a ? mark). Identify all the parameters of the query string. These usually are in a pair format, such as foo=bar. Also note that many parameters can be in one query string such as separated by a \u0026amp;, \\~, :, or any other special character or encoding. A special note when it comes to identifying multiple parameters in one string or within a POST request is that some or all of the parameters will be needed to execute the attacks. The tester needs to identify all of the parameters (even if encoded or encrypted) and identify which ones are processed by the application. Later sections of the guide will identify how to test these parameters. At this point, just make sure each one of them is identified. Also pay attention to any additional or custom type headers not typically seen (such as debug: false).  Responses  Identify where new cookies are set (Set-Cookie header), modified, or added to. Identify where there are any redirects (3xx HTTP status code), 400 status codes, in particular 403 Forbidden, and 500 internal server errors during normal responses (i.e., unmodified requests). Also note where any interesting headers are used. For example, Server: BIG-IP indicates that the site is load balanced. Thus, if a site is load balanced and one server is incorrectly configured, then the tester might have to make multiple requests to access the vulnerable server, depending on the type of load balancing used.  Black-Box Testing Testing for Application Entry Points The following are two examples on how to check for application entry points.\nExample 1 This example shows a GET request that would purchase an item from an online shopping application.\nGET /shoppingApp/buyme.asp?CUSTOMERID=100\u0026amp;ITEM=z101a\u0026amp;PRICE=62.50\u0026amp;IP=x.x.x.x HTTP/1.1 Host: x.x.x.x Cookie: SESSIONID=Z29vZCBqb2IgcGFkYXdhIG15IHVzZXJuYW1lIGlzIGZvbyBhbmQgcGFzc3dvcmQgaXMgYmFy  Here the tester would note all the parameters of the request such as CUSTOMERID, ITEM, PRICE, IP, and the Cookie (which could just be encoded parameters or used for session state).\n Example 2 This example shows a POST request that would log you into an application.\nPOST /KevinNotSoGoodApp/authenticate.asp?service=login HTTP/1.1 Host: x.x.x.x Cookie: SESSIONID=dGhpcyBpcyBhIGJhZCBhcHAgdGhhdCBzZXRzIHByZWRpY3RhYmxlIGNvb2tpZXMgYW5kIG1pbmUgaXMgMTIzNA==;CustomCookie=00my00trusted00ip00is00x.x.x.x00 user=admin\u0026amp;pass=pass123\u0026amp;debug=true\u0026amp;fromtrustIP=true  In this example the tester would note all the parameters as they have before, however the majority of the parameters are passed in the body of the request and not in the URL. Additionally, note that there is a custom HTTP header (CustomCookie) being used.\n Gray-Box Testing Testing for application entry points via a gray-box methodology would consist of everything already identified above with one addition. In cases where there are external sources from which the application receives data and processes it (such as SNMP traps, syslog messages, SMTP, or SOAP messages from other servers) a meeting with the application developers could identify any functions that would accept or expect user input and how they are formatted. For example, the developer could help in understanding how to formulate a correct SOAP request that the application would accept and where the web service resides (if the web service or any other function hasn\u0026rsquo;t already been identified during the black-box testing).\nOWASP Attack Surface Detector The Attack Surface Detector (ASD) tool investigates the source code and uncovers the endpoints of a web application, the parameters these endpoints accept, and the data type of those parameters. This includes the unlinked endpoints a spider will not be able to find, or optional parameters totally unused in client-side code. It also has the capability to calculate the changes in attack surface between two versions of an application.\nThe Attack Surface Detector is available as a plugin to both ZAP and Burp Suite, and a command-line tool is also available. The command-line tool exports the attack surface as a JSON output, which can then be used by the ZAP and Burp Suite plugin. This is helpful for cases where the source code is not provided to the penetration tester directly. For example, the penetration tester can get the json output file from a customer who does not want to provide the source code itself.\nHow to Use The CLI jar file is available for download from https://github.com/secdec/attack-surface-detector-cli/releases.\nYou can run the following command for ASD to identify endpoints from the source code of the target web application.\njava -jar attack-surface-detector-cli-1.3.5.jar \u0026lt;source-code-path\u0026gt; [flags]\nHere is an example of running the command against OWASP RailsGoat.\n$ java -jar attack-surface-detector-cli-1.3.5.jar railsgoat/ Beginning endpoint detection for \u0026#39;\u0026lt;...\u0026gt;/railsgoat\u0026#39; with 1 framework types Using framework=RAILS [0] GET: /login (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_contro ller.rb (lines \u0026#39;6\u0026#39;-\u0026#39;9\u0026#39;) [1] GET: /logout (0 variants): PARAMETERS={}; FILE=/app/controllers/sessions_controller.rb (lines \u0026#39;33\u0026#39;-\u0026#39;37\u0026#39;) [2] POST: /forgot_password (0 variants): PARAMETERS={email=name=email, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/ password_resets_controller.rb (lines \u0026#39;29\u0026#39;-\u0026#39;38\u0026#39;) [3] GET: /password_resets (0 variants): PARAMETERS={token=name=token, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/p assword_resets_controller.rb (lines \u0026#39;19\u0026#39;-\u0026#39;27\u0026#39;) [4] POST: /password_resets (0 variants): PARAMETERS={password=name=password, paramType=QUERY_STRING, dataType=STRING, user=name=user, paramType=QUERY_STRING, dataType=STRING, confirm_password=name=confirm_password, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/password_resets_controller.rb (lines \u0026#39;5\u0026#39;-\u0026#39;17\u0026#39;) [5] GET: /sessions/new (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines \u0026#39;6\u0026#39;-\u0026#39;9\u0026#39;) [6] POST: /sessions (0 variants): PARAMETERS={password=name=password, paramType=QUERY_STRING, dataType=STRING, user_id=name=user_id, paramType=SESSION, dataType=STRING, remember_me=name=remember_me, paramType=QUERY_STRING, dataType=STRING, url=name=url, paramType=QUERY_STRING, dataType=STRING, email=name=email, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines \u0026#39;11\u0026#39;-\u0026#39;31\u0026#39;) [7] DELETE: /sessions/{id} (0 variants): PARAMETERS={}; FILE=/app/controllers/sessions_controller.rb (lines \u0026#39;33\u0026#39;-\u0026#39;37\u0026#39;) [8] GET: /users (0 variants): PARAMETERS={}; FILE=/app/controllers/api/v1/users_controller.rb (lines \u0026#39;9\u0026#39;-\u0026#39;11\u0026#39;) [9] GET: /users/{id} (0 variants): PARAMETERS={}; FILE=/app/controllers/api/v1/users_controller.rb (lines \u0026#39;13\u0026#39;-\u0026#39;15\u0026#39;) ... snipped ... [38] GET: /api/v1/mobile/{id} (0 variants): PARAMETERS={id=name=id, paramType=QUERY_STRING, dataType=STRING, class=name=class, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/api/v1/mobile_controller.rb (lines \u0026#39;8\u0026#39;-\u0026#39;13\u0026#39;) [39] GET: / (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines \u0026#39;6\u0026#39;-\u0026#39;9\u0026#39;) Generated 40 distinct endpoints with 0 variants for a total of 40 endpoints Successfully validated serialization for these endpoints 0 endpoints were missing code start line 0 endpoints were missing code end line 0 endpoints had the same code start and end line Generated 36 distinct parameters Generated 36 total parameters - 36/36 have their data type - 0/36 have a list of accepted values - 36/36 have their parameter type --- QUERY_STRING: 35 --- SESSION: 1 Finished endpoint detection for \u0026#39;\u0026lt;...\u0026gt;/railsgoat\u0026#39; ---------- -- DONE -- 0 projects had duplicate endpoints Generated 40 distinct endpoints Generated 40 total endpoints Generated 36 distinct parameters Generated 36 total parameters 1/1 projects had endpoints generated To enable logging include the -debug argument You can also generate a JSON output file using the -json flag, which can be used by the plugin to both ZAP and Burp Suite. See the following links for more details.\n Home of ASD Plugin for OWASP ZAP Home of ASD Plugin for PortSwigger Burp  Tools  OWASP Zed Attack Proxy (ZAP) Burp Suite Fiddler  References  RFC 2616 – Hypertext Transfer Protocol – HTTP 1.1 OWASP Attack Surface Detector  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/07-map_execution_paths_through_application/",
	"title": "Map Execution Paths Through Application",
	"tags": [],
	"description": "",
	"content": "Map Execution Paths Through Application    ID     WSTG-INFO-07    Summary Before commencing security testing, understanding the structure of the application is paramount. Without a thorough understanding of the layout of the application, it is unlikely that it will be tested thoroughly.\nTest Objectives  Map the target application and understand the principal workflows.  How to Test In black-box testing it is extremely difficult to test the entire codebase. Not just because the tester has no view of the code paths through the application, but even if they did, to test all code paths would be very time consuming. One way to reconcile this is to document what code paths were discovered and tested.\nThere are several ways to approach the testing and measurement of code coverage:\n Path - test each of the paths through an application that includes combinatorial and boundary value analysis testing for each decision path. While this approach offers thoroughness, the number of testable paths grows exponentially with each decision branch. Data Flow (or Taint Analysis) - tests the assignment of variables via external interaction (normally users). Focuses on mapping the flow, transformation and use of data throughout an application. Race - tests multiple concurrent instances of the application manipulating the same data.  The trade off as to what method is used and to what degree each method is used should be negotiated with the application owner. Simpler approaches could also be adopted, including asking the application owner what functions or code sections they are particularly concerned about and how those code segments can be reached.\nTo demonstrate code coverage to the application owner, the tester can start with a spreadsheet and document all the links discovered by spidering the application (either manually or automatically). Then the tester can look more closely at decision points in the application and investigate how many significant code paths are discovered. These should then be documented in the spreadsheet with URLs, prose and screenshot descriptions of the paths discovered.\nCode Review Ensuring sufficient code coverage for the application owner is far easier with gray-box and white-box approach to testing. Information solicited by and provided to the tester will ensure the minimum requirements for code coverage are met.\nMany modern Dynamic Application Security Testing (DAST) tools facilitate the use of a web server agent or could be paired with a third-party agent to monitor web application coverage specifics.\nAutomatic Spidering The automatic spider is a tool used to automatically discover new resources (URLs) on a particular website. It begins with a list of URLs to visit, called the seeds, which depends on how the Spider is started. While there are a lot of Spidering tools, the following example uses the Zed Attack Proxy (ZAP):\nFigure 4.1.7-1: Zed Attack Proxy Screen\nZAP offers various automatic spidering options, which can leveraged based on the tester\u0026rsquo;s needs:\n Spider AJAX Spider OpenAPI Support  Tools  Zed Attack Proxy (ZAP) List of spreadsheet software Diagramming software  References  Code Coverage  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/08-fingerprint_web_application_framework/",
	"title": "Fingerprint Web Application Framework",
	"tags": [],
	"description": "",
	"content": "Fingerprint Web Application Framework    ID     WSTG-INFO-08    Summary There is nothing new under the sun, and nearly every web application that one may think of developing has already been developed. With the vast number of free and Open Source software projects that are actively developed and deployed around the world, it is very likely that an application security test will face a target that is entirely or partly dependent on these well known applications or frameworks (e.g. WordPress, phpBB, Mediawiki, etc). Knowing the web application components that are being tested significantly helps in the testing process and will also drastically reduce the effort required during the test. These well known web applications have known HTML headers, cookies, and directory structures that can be enumerated to identify the application. Most of the web frameworks have several markers in those locations which help an attacker or tester to recognize them. This is basically what all automatic tools do, they look for a marker from a predefined location and then compare it to the database of known signatures. For better accuracy several markers are usually used.\nTest Objectives  Fingerprint the components being used by the web applications.  How to Test Black-Box Testing There are several common locations to consider in order to identify frameworks or components:\n HTTP headers Cookies HTML source code Specific files and folders File extensions Error messages  HTTP Headers The most basic form of identifying a web framework is to look at the X-Powered-By field in the HTTP response header. Many tools can be used to fingerprint a target, the simplest one is netcat.\nConsider the following HTTP Request-Response:\n$ nc 127.0.0.1 80 HEAD / HTTP/1.0 HTTP/1.1 200 OK Server: nginx/1.0.14 [...] X-Powered-By: Mono From the X-Powered-By field, we understand that the web application framework is likely to be Mono. However, although this approach is simple and quick, this methodology doesn\u0026rsquo;t work in 100% of cases. It is possible to easily disable X-Powered-By header by a proper configuration. There are also several techniques that allow a web site to obfuscate HTTP headers (see an example in the Remediation section). In the example above we can also note a specific version of nginx is being used to serve the content.\nSo in the same example the tester could either miss the X-Powered-By header or obtain an answer like the following:\nHTTP/1.1 200 OK Server: nginx/1.0.14 Date: Sat, 07 Sep 2013 08:19:15 GMT Content-Type: text/html;charset=ISO-8859-1 Connection: close Vary: Accept-Encoding X-Powered-By: Blood, sweat and tears Sometimes there are more HTTP-headers that point at a certain framework. In the following example, according to the information from HTTP-request, one can see that X-Powered-By header contains PHP version. However, the X-Generator header points out the used framework is actually Swiftlet, which helps a penetration tester to expand their attack vectors. When performing fingerprinting, carefully inspect every HTTP-header for such leaks.\nHTTP/1.1 200 OK Server: nginx/1.4.1 Date: Sat, 07 Sep 2013 09:22:52 GMT Content-Type: text/html Connection: keep-alive Vary: Accept-Encoding X-Powered-By: PHP/5.4.16-1~dotdeb.1 Expires: Thu, 19 Nov 1981 08:52:00 GMT Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0 Pragma: no-cache X-Generator: Swiftlet Cookies Another similar and somewhat more reliable way to determine the current web framework are framework-specific cookies.\nConsider the following HTTP-request:\nFigure 4.1.8-7: Cakephp HTTP Request\nThe cookie CAKEPHP has automatically been set, which gives information about the framework being used. A list of common cookie names is presented in Cookies section. Limitations still exist in relying on this identification mechanism - it is possible to change the name of cookies. For example, for the selected CakePHP framework this could be done via the following configuration (excerpt from core.php):\n/** * The name of CakePHP\u0026#39;s session cookie. * * Note the guidelines for Session names states: \u0026#34;The session name references * the session id in cookies and URLs. It should contain only alphanumeric * characters.\u0026#34; * @link http://php.net/session_name */ Configure::write(\u0026#39;Session.cookie\u0026#39;, \u0026#39;CAKEPHP\u0026#39;); However, these changes are less likely to be made than changes to the X-Powered-By header, so this approach to identification can be considered as more reliable.\nHTML Source Code This technique is based on finding certain patterns in the HTML page source code. Often one can find a lot of information which helps a tester to recognize a specific component. One of the common markers are HTML comments that directly lead to framework disclosure. More often certain framework-specific paths can be found, i.e. links to framework-specific CSS or JS folders. Finally, specific script variables might also point to a certain framework.\nFrom the screenshot below one can easily learn the used framework and its version by the mentioned markers. The comment, specific paths and script variables can all help an attacker to quickly determine an instance of ZK framework.\nFigure 4.1.8-2: ZK Framework HTML Source Sample\nFrequently such information is positioned in the \u0026lt;head\u0026gt; section of HTTP responses, in \u0026lt;meta\u0026gt; tags, or at the end of the page. Nevertheless, entire responses should be analyzed since it can be useful for other purposes such as inspection of other useful comments and hidden fields. Sometimes, web developers do not care much about hiding information about the frameworks or components used. It is still possible to stumble upon something like this at the bottom of the page:\nFigure 4.1.8-3: Banshee Bottom Page\nSpecific Files and Folders There is another approach which greatly helps an attacker or tester to identify applications or components with high accuracy. Every web component has its own specific file and folder structure on the server. It has been noted that one can see the specific path from the HTML page source but sometimes they are not explicitly presented there and still reside on the server.\nIn order to uncover them a technique known as forced browsing or \u0026ldquo;dirbusting\u0026rdquo; is used. Dirbusting is brute forcing a target with known folder and filenames and monitoring HTTP-responses to enumerate server content. This information can be used both for finding default files and attacking them, and for fingerprinting the web application. Dirbusting can be done in several ways, the example below shows a successful dirbusting attack against a WordPress-powered target with the help of defined list and intruder functionality of Burp Suite.\nFigure 4.1.8-4: Dirbusting with Burp\nWe can see that for some WordPress-specific folders (for instance, /wp-includes/, /wp-admin/ and /wp-content/) HTTP responses are 403 (Forbidden), 302 (Found, redirection to wp-login.php), and 200 (OK) respectively. This is a good indicator that the target is WordPress powered. The same way it is possible to dirbust different application plugin folders and their versions. In the screenshot below one can see a typical CHANGELOG file of a Drupal plugin, which provides information on the application being used and discloses a vulnerable plugin version.\nFigure 4.1.8-5: Drupal Botcha Disclosure\nTip: before starting with dirbusting, check the robots.txt file first. Sometimes application specific folders and other sensitive information can be found there as well. An example of such a robots.txt file is presented on a screenshot below.\nFigure 4.1.8-6: Robots Info Disclosure\nSpecific files and folders are different for each specific application. If the identified application or component is Open Source there may be value in setting up a temporary installation during penetration tests in order to gain a better understanding of what infrastructure or functionality is presented, and what files might be left on the server. However, several good file lists already exist; one good example is FuzzDB wordlists of predictable files/folders.\nFile Extensions URLs may include file extensions, which can also help to identify the web platform or technology.\nFor example, the OWASP wiki used PHP:\nhttps://wiki.owasp.org/index.php?title=Fingerprint_Web_Application_Framework\u0026amp;action=edit\u0026amp;section=4 Here are some common web file extensions and associated technologies:\n .php \u0026ndash; PHP .aspx \u0026ndash; Microsoft ASP.NET .jsp \u0026ndash; Java Server Pages  Error Messages As can be seen in the following screenshot the listed file system path points to use of WordPress (wp-content). Also testers should be aware that WordPress is PHP based (functions.php).\nFigure 4.1.8-7: WordPress Parse Error\nCommon Identifiers Cookies    Framework Cookie name     Zope zope3   CakePHP cakephp   Kohana kohanasession   Laravel laravel_session   phpBB phpbb3_   WordPress wp-settings   1C-Bitrix BITRIX_   AMPcms AMP   Django CMS django   DotNetNuke DotNetNukeAnonymous   e107 e107_tz   EPiServer EPiTrace, EPiServer   Graffiti CMS graffitibot   Hotaru CMS hotaru_mobile   ImpressCMS ICMSession   Indico MAKACSESSION   InstantCMS InstantCMS[logdate]   Kentico CMS CMSPreferredCulture   MODx SN4[12symb]   TYPO3 fe_typo_user   Dynamicweb Dynamicweb   LEPTON lep[some_numeric_value]+sessionid   Wix Domain=.wix.com   VIVVO VivvoSessionId    HTML Source Code    Application Keyword     WordPress \u0026lt;meta name=\u0026quot;generator\u0026quot; content=\u0026quot;WordPress 3.9.2\u0026quot; /\u0026gt;   phpBB \u0026lt;body id=\u0026quot;phpbb\u0026quot;   Mediawiki \u0026lt;meta name=\u0026quot;generator\u0026quot; content=\u0026quot;MediaWiki 1.21.9\u0026quot; /\u0026gt;   Joomla \u0026lt;meta name=\u0026quot;generator\u0026quot; content=\u0026quot;Joomla! - Open Source Content Management\u0026quot; /\u0026gt;   Drupal \u0026lt;meta name=\u0026quot;Generator\u0026quot; content=\u0026quot;Drupal 7 (http://drupal.org)\u0026quot; /\u0026gt;   DotNetNuke DNN Platform - [http://www.dnnsoftware.com](http://www.dnnsoftware.com)    General Markers  %framework_name% powered by built upon running  Specific Markers    Framework Keyword     Adobe ColdFusion \u0026lt;!-- START headerTags.cfm   Microsoft ASP.NET __VIEWSTATE   ZK \u0026lt;!-- ZK   Business Catalyst \u0026lt;!-- BC_OBNW --\u0026gt;   Indexhibit ndxz-studio    Remediation While efforts can be made to use different cookie names (through changing configs), hiding or changing file/directory paths (through rewriting or source code changes), removing known headers, etc. such efforts boil down to \u0026ldquo;security through obscurity\u0026rdquo;. System owners/admins should recognize that those efforts only slow down the most basic of adversaries. The time/effort may be better used on stakeholder awareness and solution maintenance activities.\nTools A list of general and well-known tools is presented below. There are also a lot of other utilities, as well as framework-based fingerprinting tools.\nWhatWeb Website: https://github.com/urbanadventurer/WhatWeb\nCurrently one of the best fingerprinting tools on the market. Included in a default Kali Linux build. Language: Ruby Matches for fingerprinting are made with:\n Text strings (case sensitive) Regular expressions Google Hack Database queries (limited set of keywords) MD5 hashes URL recognition HTML tag patterns Custom ruby code for passive and aggressive operations  Sample output is presented on a screenshot below:\nFigure 4.1.8-8: Whatweb Output sample\nWappalyzer Website: https://www.wappalyzer.com/\nWapplyzer is available in multiple usage models, the most popular of which is likely the Firefox/Chrome extensions. They work only on regular expression matching and doesn\u0026rsquo;t need anything other than the page to be loaded in browser. It works completely at the browser level and gives results in the form of icons. Although sometimes it has false positives, this is very handy to have notion of what technologies were used to construct a target website immediately after browsing a page.\nSample output of a plug-in is presented on a screenshot below.\nFigure 4.1.8-9: Wappalyzer Output for OWASP Website\nReferences Whitepapers  Saumil Shah: \u0026ldquo;An Introduction to HTTP fingerprinting\u0026rdquo; Anant Shrivastava : \u0026ldquo;Web Application Finger Printing\u0026rdquo;  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/09-fingerprint_web_application/",
	"title": "Fingerprint Web Application",
	"tags": [],
	"description": "",
	"content": "Fingerprint Web Application    ID     WSTG-INFO-09    This content has been merged into: Fingerprint Web Application Framework.\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/01-information_gathering/10-map_application_architecture/",
	"title": "Map Application Architecture",
	"tags": [],
	"description": "",
	"content": "Map Application Architecture    ID     WSTG-INFO-10    Summary The complexity of interconnected and heterogeneous web infrastructure can include hundreds of web applications and makes configuration management and review a fundamental step in testing and deploying every single application. In fact it takes only a single vulnerability to undermine the security of the entire infrastructure, and even small and seemingly unimportant problems may evolve into severe risks for another application in the same infrastructure.\nTo address these problems, it is of utmost importance to perform an in-depth review of configuration and known security issues. Before performing an in-depth review it is necessary to map the network and application architecture. The different elements that make up the infrastructure need to be determined to understand how they interact with a web application and how they affect security.\nTest Objectives  Generate a map of the application at hand based on the research conducted.  How to Test Map the Application Architecture The application architecture needs to be mapped through some test to determine what different components are used to build the web application. In small setups, such as a simple PHP application, a single server might be used that serves the PHP application, and perhaps also the authentication mechanism.\nOn more complex setups, such as an online bank system, multiple servers might be involved. These may include a reverse proxy, a front-end web server, an application server, and a database server or LDAP server. Each of these servers will be used for different purposes and might even be segregated in different networks with firewalls between them. This creates different network zones so that access to the web server will not necessarily grant a remote user access to the authentication mechanism itself, and so that compromises of the different elements of the architecture can be isolated so that they will not compromise the whole architecture.\nGetting knowledge of the application architecture can be easy if this information is provided to the testing team by the application developers in document form or through interviews, but can also prove to be very difficult if doing a blind penetration test.\nIn the latter case, a tester will first start with the assumption that there is a simple setup (a single server). Then they will retrieve information from other tests and derive the different elements, question this assumption, and extend the architecture map. The tester will start by asking simple questions such as: \u0026ldquo;Is there a firewall protecting the web server?\u0026rdquo;. This question will be answered based on the results of network scans targeted at the web server and the analysis of whether the network ports of the web server are being filtered in the network edge (no answer or ICMP unreachables are received) or if the server is directly connected to the Internet (i.e. returns RST packets for all non-listening ports). This analysis can be enhanced to determine the type of firewall used based on network packet tests. Is it a stateful firewall or is it an access list filter on a router? How is it configured? Can it be bypassed? Is it a full fledged web application firewall?\nDetecting a reverse proxy in front of the web server can be done by analysis of the web server banner, which might directly disclose the existence of a reverse proxy. It can also be determined by obtaining the answers given by the web server to requests and comparing them to the expected answers. For example, some reverse proxies act as Intrusion Prevention Systems (IPS) by blocking known attacks targeted at the web server. If the web server is known to answer with a 404 message to a request that targets an unavailable page and returns a different error message for some common web attacks like those done by vulnerability scanners, it might be an indication of a reverse proxy (or an application-level firewall) which is filtering the requests and returning a different error page than the one expected. Another example: if the web server returns a set of available HTTP methods (including TRACE) but the expected methods return errors then there is probably something in between blocking them.\nIn some cases, even the protection system gives itself away. Here\u0026rsquo;s an example of mod_security self identifying:\nFigure 4.1.10-1: Example mod_security Error Page\nReverse proxies can also be introduced as proxy-caches to accelerate the performance of back-end application servers. Detecting these proxies can be done based on the server header. They can also be detected by timing requests that should be cached by the server and comparing the time taken to server the first request with subsequent requests.\nAnother element that can be detected is network load balancers. Typically, these systems will balance a given TCP/IP port to multiple servers based on different algorithms (round-robin, web server load, number of requests, etc.). Thus, the detection of this architecture element needs to be done by examining multiple requests and comparing results to determine if the requests are going to the same or different web servers. For example, based on the Date header if the server clocks are not synchronized. In some cases, the network load balance process might inject new information in the headers that will make it stand out distinctly, like the BIGipServer prefixed cookie introduced by F5 BIG-IP load balancers.\nApplication web servers are usually easy to detect. The request for several resources is handled by the application server itself (not the web server) and the response header will vary significantly (including different or additional values in the answer header). Another way to detect these is to see if the web server tries to set cookies which are indicative of an application web server being used (such as the JSESSIONID provided by various J2EE servers), or to rewrite URLs automatically to do session tracking.\nAuthentication back ends (such as LDAP directories, relational databases, or RADIUS servers) however, are not as easy to detect from an external point of view in an immediate way, since they will be hidden by the application itself.\nThe use of a back end database can be determined simply by navigating an application. If there is highly dynamic content generated \u0026ldquo;on the fly\u0026rdquo; it is probably being extracted from some sort of database by the application itself. Sometimes the way information is requested might give insight to the existence of a database back end. For example, an online shopping application that uses numeric identifiers (id) when browsing the different articles in the shop. However, when doing a blind application test, knowledge of the underlying database is usually only available when a vulnerability surfaces in the application, such as poor exception handling or susceptibility to SQL injection.\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/01-test_network_infrastructure_configuration/",
	"title": "Test Network Infrastructure Configuration",
	"tags": [],
	"description": "",
	"content": "Test Network Infrastructure Configuration    ID     WSTG-CONF-01    Summary The intrinsic complexity of interconnected and heterogeneous web server infrastructure, which can include hundreds of web applications, makes configuration management and review a fundamental step in testing and deploying every single application. It takes only a single vulnerability to undermine the security of the entire infrastructure, and even small and seemingly unimportant problems may evolve into severe risks for another application on the same server. In order to address these problems, it is of utmost importance to perform an in-depth review of configuration and known security issues, after having mapped the entire architecture.\nProper configuration management of the web server infrastructure is very important in order to preserve the security of the application itself. If elements such as the web server software, the back-end database servers, or the authentication servers are not properly reviewed and secured, they might introduce undesired risks or introduce new vulnerabilities that might compromise the application itself.\nFor example, a web server vulnerability that would allow a remote attacker to disclose the source code of the application itself (a vulnerability that has arisen a number of times in both web servers or application servers) could compromise the application, as anonymous users could use the information disclosed in the source code to leverage attacks against the application or its users.\nThe following steps need to be taken to test the configuration management infrastructure:\n The different elements that make up the infrastructure need to be determined in order to understand how they interact with a web application and how they affect its security. All the elements of the infrastructure need to be reviewed in order to make sure that they don\u0026rsquo;t contain any known vulnerabilities. A review needs to be made of the administrative tools used to maintain all the different elements. The authentication systems, need to reviewed in order to assure that they serve the needs of the application and that they cannot be manipulated by external users to leverage access. A list of defined ports which are required for the application should be maintained and kept under change control.  After having mapped the different elements that make up the infrastructure (see Map Network and Application Architecture) it is possible to review the configuration of each element founded and test for any known vulnerabilities.\nTest Objectives  Review the applications' configurations set across the network and validate that they are not vulnerable. Validate that used frameworks and systems are secure and not susceptible to known vulnerabilities due to unmaintained software or default settings and credentials.  How to Test Known Server Vulnerabilities Vulnerabilities found in the different areas of the application architecture, be it in the web server or in the back end database, can severely compromise the application itself. For example, consider a server vulnerability that allows a remote, unauthenticated user to upload files to the web server or even to replace files. This vulnerability could compromise the application, since a rogue user may be able to replace the application itself or introduce code that would affect the back end servers, as its application code would be run just like any other application.\nReviewing server vulnerabilities can be hard to do if the test needs to be done through a blind penetration test. In these cases, vulnerabilities need to be tested from a remote site, typically using an automated tool. However, testing for some vulnerabilities can have unpredictable results on the web server, and testing for others (like those directly involved in denial of service attacks) might not be possible due to the service downtime involved if the test was successful.\nSome automated tools will flag vulnerabilities based on the web server version retrieved. This leads to both false positives and false negatives. On one hand, if the web server version has been removed or obscured by the local site administrator the scan tool will not flag the server as vulnerable even if it is. On the other hand, if the vendor providing the software does not update the web server version when vulnerabilities are fixed, the scan tool will flag vulnerabilities that do not exist. The latter case is actually very common as some operating system vendors back port patches of security vulnerabilities to the software they provide in the operating system, but do not do a full upload to the latest software version. This happens in most GNU/Linux distributions such as Debian, Red Hat or SuSE. In most cases, vulnerability scanning of an application architecture will only find vulnerabilities associated with the \u0026ldquo;exposed\u0026rdquo; elements of the architecture (such as the web server) and will usually be unable to find vulnerabilities associated to elements which are not directly exposed, such as the authentication back ends, the back end database, or reverse proxies in use.\nFinally, not all software vendors disclose vulnerabilities in a public way, and therefore these weaknesses do not become registered within publicly known vulnerability databases [2]. This information is only disclosed to customers or published through fixes that do not have accompanying advisories. This reduces the usefulness of vulnerability scanning tools. Typically, vulnerability coverage of these tools will be very good for common products (such as the Apache web server, Microsoft\u0026rsquo;s Internet Information Server, or IBM\u0026rsquo;s Lotus Domino) but will be lacking for lesser known products.\nThis is why reviewing vulnerabilities is best done when the tester is provided with internal information of the software used, including versions and releases used and patches applied to the software. With this information, the tester can retrieve the information from the vendor itself and analyze what vulnerabilities might be present in the architecture and how they can affect the application itself. When possible, these vulnerabilities can be tested to determine their real effects and to detect if there might be any external elements (such as intrusion detection or prevention systems) that might reduce or negate the possibility of successful exploitation. Testers might even determine, through a configuration review, that the vulnerability is not even present, since it affects a software component that is not in use.\nIt is also worthwhile to note that vendors will sometimes silently fix vulnerabilities and make the fixes available with new software releases. Different vendors will have different release cycles that determine the support they might provide for older releases. A tester with detailed information of the software versions used by the architecture can analyse the risk associated to the use of old software releases that might be unsupported in the short term or are already unsupported. This is critical, since if a vulnerability were to surface in an old software version that is no longer supported, the systems personnel might not be directly aware of it. No patches will be ever made available for it and advisories might not list that version as vulnerable as it is no longer supported. Even in the event that they are aware that the vulnerability is present and the system is vulnerable, they will need to do a full upgrade to a new software release, which might introduce significant downtime in the application architecture or might force the application to be re-coded due to incompatibilities with the latest software version.\nAdministrative Tools Any web server infrastructure requires the existence of administrative tools to maintain and update the information used by the application. This information includes static content (web pages, graphic files), application source code, user authentication databases, etc. Administrative tools will differ depending on the site, technology, or software used. For example, some web servers will be managed using administrative interfaces which are, themselves, web servers (such as the iPlanet web server) or will be administrated by plain text configuration files (in the Apache case [3]) or use operating-system GUI tools (when using Microsoft\u0026rsquo;s IIS server or ASP.Net).\nIn most cases the server configuration will be handled using different file maintenance tools used by the web server, which are managed through FTP servers, WebDAV, network file systems (NFS, CIFS) or other mechanisms. Obviously, the operating system of the elements that make up the application architecture will also be managed using other tools. Applications may also have administrative interfaces embedded in them that are used to manage the application data itself (users, content, etc.).\nAfter having mapped the administrative interfaces used to manage the different parts of the architecture it is important to review them since if an attacker gains access to any of them he can then compromise or damage the application architecture. To do this it is important to:\n Determine the mechanisms that control access to these interfaces and their associated susceptibilities. This information may be available online. Change the default username and password.  Some companies choose not to manage all aspects of their web server applications, but may have other parties managing the content delivered by the web application. This external company might either provide only parts of the content (news updates or promotions) or might manage the web server completely (including content and code). It is common to find administrative interfaces available from the Internet in these situations, since using the Internet is cheaper than providing a dedicated line that will connect the external company to the application infrastructure through a management-only interface. In this situation, it is very important to test if the administrative interfaces can be vulnerable to attacks.\nReferences  [1] WebSEAL, also known as Tivoli Authentication Manager, is a reverse proxy from IBM which is part of the Tivoli framework. [2] Such as Symantec\u0026rsquo;s Bugtraq, ISS' X-Force, or NIST\u0026rsquo;s National Vulnerability Database (NVD). [3] There are some GUI-based administration tools for Apache (like NetLoony) but they are not in widespread use yet.  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/02-test_application_platform_configuration/",
	"title": "Test Application Platform Configuration",
	"tags": [],
	"description": "",
	"content": "Test Application Platform Configuration    ID     WSTG-CONF-02    Summary Proper configuration of the single elements that make up an application architecture is important in order to prevent mistakes that might compromise the security of the whole architecture.\nConfiguration review and testing is a critical task in creating and maintaining an architecture. This is because many different systems will be usually provided with generic configurations that might not be suited to the task they will perform on the specific site they\u0026rsquo;re installed on.\nWhile the typical web and application server installation will contain a lot of functionality (like application examples, documentation, test pages) what is not essential should be removed before deployment to avoid post-install exploitation.\nTest Objectives  Ensure that defaults and known files have been removed. Validate that no debugging code or extensions are left in the production environments. Review the logging mechanisms set in place for the application.  How to Test Black-Box Testing Sample and Known Files and Directories Many web servers and application servers provide, in a default installation, sample applications and files for the benefit of the developer and in order to test that the server is working properly right after installation. However, many default web server applications have been later known to be vulnerable. This was the case, for example, for CVE-1999-0449 (Denial of Service in IIS when the Exair sample site had been installed), CAN-2002-1744 (Directory traversal vulnerability in CodeBrws.asp in Microsoft IIS 5.0), CAN-2002-1630 (Use of sendmail.jsp in Oracle 9iAS), or CAN-2003-1172 (Directory traversal in the view-source sample in Apache’s Cocoon).\nCGI scanners include a detailed list of known files and directory samples that are provided by different web or application servers and might be a fast way to determine if these files are present. However, the only way to be really sure is to do a full review of the contents of the web server or application server and determine of whether they are related to the application itself or not.\nComment Review It is very common for programmers to add comments when developing large web-based applications. However, comments included inline in HTML code might reveal internal information that should not be available to an attacker. Sometimes, even source code is commented out since a functionality is no longer required, but this comment is leaked out to the HTML pages returned to the users unintentionally.\nComment review should be done in order to determine if any information is being leaked through comments. This review can only be thoroughly done through an analysis of the web server static and dynamic content and through file searches. It can be useful to browse the site either in an automatic or guided fashion and store all the content retrieved. This retrieved content can then be searched in order to analyse any HTML comments available in the code.\nSystem Configuration Various tools, documents, or checklists can be used to give IT and security professionals a detailed assessment of target systems' conformance to various configuration baselines or benchmarks. Such tools include (but are not limited to):\n CIS-CAT Lite Microsoft\u0026rsquo;s Attack Surface Analyzer NIST\u0026rsquo;s National Checklist Program  Gray-Box Testing Configuration Review The web server or application server configuration takes an important role in protecting the contents of the site and it must be carefully reviewed in order to spot common configuration mistakes. Obviously, the recommended configuration varies depending on the site policy, and the functionality that should be provided by the server software. In most cases, however, configuration guidelines (either provided by the software vendor or external parties) should be followed to determine if the server has been properly secured.\nIt is impossible to generically say how a server should be configured, however, some common guidelines should be taken into account:\n Only enable server modules (ISAPI extensions in the case of IIS) that are needed for the application. This reduces the attack surface since the server is reduced in size and complexity as software modules are disabled. It also prevents vulnerabilities that might appear in the vendor software from affecting the site if they are only present in modules that have been already disabled. Handle server errors (40x or 50x) with custom-made pages instead of with the default web server pages. Specifically make sure that any application errors will not be returned to the end user and that no code is leaked through these errors since it will help an attacker. It is actually very common to forget this point since developers do need this information in pre-production environments. Make sure that the server software runs with minimized privileges in the operating system. This prevents an error in the server software from directly compromising the whole system, although an attacker could elevate privileges once running code as the web server. Make sure the server software properly logs both legitimate access and errors. Make sure that the server is configured to properly handle overloads and prevent Denial of Service attacks. Ensure that the server has been performance-tuned properly. Never grant non-administrative identities (with the exception of NT SERVICE\\WMSvc) access to applicationHost.config, redirection.config, and administration.config (either Read or Write access). This includes Network Service, IIS_IUSRS, IUSR, or any custom identity used by IIS application pools. IIS worker processes are not meant to access any of these files directly. Never share out applicationHost.config, redirection.config, and administration.config on the network. When using Shared Configuration, prefer to export applicationHost.config to another location (see the section titled \u0026ldquo;Setting Permissions for Shared Configuration). Keep in mind that all users can read .NET Framework machine.config and root web.config files by default. Do not store sensitive information in these files if it should be for administrator eyes only. Encrypt sensitive information that should be read by the IIS worker processes only and not by other users on the machine. Do not grant Write access to the identity that the Web server uses to access the shared applicationHost.config. This identity should have only Read access. Use a separate identity to publish applicationHost.config to the share. Do not use this identity for configuring access to the shared configuration on the Web servers. Use a strong password when exporting the encryption keys for use with shared -configuration. Maintain restricted access to the share containing the shared configuration and encryption keys. If this share is compromised, an attacker will be able to read and write any IIS configuration for your Web servers, redirect traffic from your Web site to malicious sources, and in some cases gain control of all web servers by loading arbitrary code into IIS worker processes. Consider protecting this share with firewall rules and IPsec policies to allow only the member web servers to connect.  Logging Logging is an important asset of the security of an application architecture, since it can be used to detect flaws in applications (users constantly trying to retrieve a file that does not really exist) as well as sustained attacks from rogue users. Logs are typically properly generated by web and other server software. It is not common to find applications that properly log their actions to a log and, when they do, the main intention of the application logs is to produce debugging output that could be used by the programmer to analyze a particular error.\nIn both cases (server and application logs) several issues should be tested and analyzed based on the log contents:\n Do the logs contain sensitive information? Are the logs stored in a dedicated server? Can log usage generate a Denial of Service condition? How are they rotated? Are logs kept for the sufficient time? How are logs reviewed? Can administrators use these reviews to detect targeted attacks? How are log backups preserved? Is the data being logged data validated (min/max length, chars etc) prior to being logged?  Sensitive Information in Logs Some applications might, for example, use GET requests to forward form data which will be seen in the server logs. This means that server logs might contain sensitive information (such as usernames as passwords, or bank account details). This sensitive information can be misused by an attacker if they obtained the logs, for example, through administrative interfaces or known web server vulnerabilities or misconfiguration (like the well-known server-status misconfiguration in Apache-based HTTP servers).\nEvent logs will often contain data that is useful to an attacker (information leakage) or can be used directly in exploits:\n Debug information Stack traces Usernames System component names Internal IP addresses Less sensitive personal data (e.g. email addresses, postal addresses and telephone numbers associated with named individuals) Business data  Also, in some jurisdictions, storing some sensitive information in log files, such as personal data, might oblige the enterprise to apply the data protection laws that they would apply to their back-end databases to log files too. And failure to do so, even unknowingly, might carry penalties under the data protection laws that apply.\nA wider list of sensitive information is:\n Application source code Session identification values Access tokens Sensitive personal data and some forms of personally identifiable information (PII) Authentication passwords Database connection strings Encryption keys Bank account or payment card holder data Data of a higher security classification than the logging system is allowed to store Commercially-sensitive information Information it is illegal to collect in the relevant jurisdiction Information a user has opted out of collection, or not consented to e.g. use of do not track, or where consent to collect has expired  Log Location Typically servers will generate local logs of their actions and errors, consuming the disk of the system the server is running on. However, if the server is compromised its logs can be wiped out by the intruder to clean up all the traces of its attack and methods. If this were to happen the system administrator would have no knowledge of how the attack occurred or where the attack source was located. Actually, most attacker tool kits include a \u0026lsquo;\u0026lsquo;log zapper '\u0026rsquo; that is capable of cleaning up any logs that hold given information (like the IP address of the attacker) and are routinely used in attacker’s system-level root kits.\nConsequently, it is wiser to keep logs in a separate location and not in the web server itself. This also makes it easier to aggregate logs from different sources that refer to the same application (such as those of a web server farm) and it also makes it easier to do log analysis (which can be CPU intensive) without affecting the server itself.\nLog Storage Logs can introduce a Denial of Service condition if they are not properly stored. Any attacker with sufficient resources could be able to produce a sufficient number of requests that would fill up the allocated space to log files, if they are not specifically prevented from doing so. However, if the server is not properly configured, the log files will be stored in the same disk partition as the one used for the operating system software or the application itself. This means that if the disk were to be filled up the operating system or the application might fail because it is unable to write on disk.\nTypically in UNIX systems logs will be located in /var (although some server installations might reside in /opt or /usr/local) and it is important to make sure that the directories in which logs are stored are in a separate partition. In some cases, and in order to prevent the system logs from being affected, the log directory of the server software itself (such as /var/log/apache in the Apache web server) should be stored in a dedicated partition.\nThis is not to say that logs should be allowed to grow to fill up the file system they reside in. Growth of server logs should be monitored in order to detect this condition since it may be indicative of an attack.\nTesting this condition is as easy, and as dangerous in production environments, as firing off a sufficient and sustained number of requests to see if these requests are logged and if there is a possibility to fill up the log partition through these requests. In some environments where QUERY_STRING parameters are also logged regardless of whether they are produced through GET or POST requests, big queries can be simulated that will fill up the logs faster since, typically, a single request will cause only a small amount of data to be logged, such as date and time, source IP address, URI request, and server result.\nLog Rotation Most servers (but few custom applications) will rotate logs in order to prevent them from filling up the file system they reside on. The assumption when rotating logs is that the information in them is only necessary for a limited amount of time.\nThis feature should be tested in order to ensure that:\n Logs are kept for the time defined in the security policy, not more and not less. Logs are compressed once rotated (this is a convenience, since it will mean that more logs will be stored for the same available disk space). File system permission of rotated log files are the same (or stricter) that those of the log files itself. For example, web servers will need to write to the logs they use but they don’t actually need to write to rotated logs, which means that the permissions of the files can be changed upon rotation to prevent the web server process from modifying these.  Some servers might rotate logs when they reach a given size. If this happens, it must be ensured that an attacker cannot force logs to rotate in order to hide his tracks.\nLog Access Control Event log information should never be visible to end users. Even web administrators should not be able to see such logs since it breaks separation of duty controls. Ensure that any access control schema that is used to protect access to raw logs and any applications providing capabilities to view or search the logs is not linked with access control schemas for other application user roles. Neither should any log data be viewable by unauthenticated users.\nLog Review Review of logs can be used for more than extraction of usage statistics of files in the web servers (which is typically what most log-based application will focus on), but also to determine if attacks take place at the web server.\nIn order to analyze web server attacks the error log files of the server need to be analyzed. Review should concentrate on:\n 40x (not found) error messages. A large amount of these from the same source might be indicative of a CGI scanner tool being used against the web server 50x (server error) messages. These can be an indication of an attacker abusing parts of the application which fail unexpectedly. For example, the first phases of a SQL injection attack will produce these error message when the SQL query is not properly constructed and its execution fails on the back end database.  Log statistics or analysis should not be generated, nor stored, in the same server that produces the logs. Otherwise, an attacker might, through a web server vulnerability or improper configuration, gain access to them and retrieve similar information as would be disclosed by log files themselves.\nReferences   Apache\n Apache Security, by Ivan Ristic, O’reilly, March 2005. Apache Security Secrets: Revealed (Again), Mark Cox, November 2003 Apache Security Secrets: Revealed, ApacheCon 2002, Las Vegas, Mark J Cox, October 2002 Performance Tuning    Lotus Domino\n Lotus Security Handbook, William Tworek et al., April 2004, available in the IBM Redbooks collection Lotus Domino Security, an X-force white-paper, Internet Security Systems, December 2002 Hackproofing Lotus Domino Web Server, David Litchfield, October 2001    Microsoft IIS\n Security Best Practices for IIS 8 CIS Microsoft IIS Benchmarks Securing Your Web Server (Patterns and Practices), Microsoft Corporation, January 2004 IIS Security and Programming Countermeasures, by Jason Coombs From Blueprint to Fortress: A Guide to Securing IIS 5.0, by John Davis, Microsoft Corporation, June 2001 Secure Internet Information Services 5 Checklist, by Michael Howard, Microsoft Corporation, June 2000    Red Hat’s (formerly Netscape’s) iPlanet\n Guide to the Secure Configuration and Administration of iPlanet Web Server, Enterprise Edition 4.1, by James M Hayes, The Network Applications Team of the Systems and Network Attack Center (SNAC), NSA, January 2001    WebSphere\n IBM WebSphere V5.0 Security, WebSphere Handbook Series, by Peter Kovari et al., IBM, December 2002. IBM WebSphere V4.0 Advanced Edition Security, by Peter Kovari et al., IBM, March 2002.    General\n Logging Cheat Sheet, OWASP SP 800-92 Guide to Computer Security Log Management, NIST PCI DSS v3.2.1 Requirement 10 and PA-DSS v3.2 Requirement 4, PCI Security Standards Council    Generic:\n  CERT Security Improvement Modules: Securing Public Web Servers\n  How To: Use IISLockdown.exe\n    "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/03-test_file_extensions_handling_for_sensitive_information/",
	"title": "Test File Extensions Handling for Sensitive Information",
	"tags": [],
	"description": "",
	"content": "Test File Extensions Handling for Sensitive Information    ID     WSTG-CONF-03    Summary File extensions are commonly used in web servers to easily determine which technologies, languages and plugins must be used to fulfill the web request. While this behavior is consistent with RFCs and Web Standards, using standard file extensions provides the penetration tester useful information about the underlying technologies used in a web appliance and greatly simplifies the task of determining the attack scenario to be used on particular technologies. In addition, mis-configuration of web servers could easily reveal confidential information about access credentials.\nExtension checking is often used to validate files to be uploaded, which can lead to unexpected results because the content is not what is expected, or because of unexpected OS filename handling.\nDetermining how web servers handle requests corresponding to files having different extensions may help in understanding web server behavior depending on the kind of files that are accessed. For example, it can help to understand which file extensions are returned as text or plain versus those that cause server-side execution. The latter are indicative of technologies, languages or plugins that are used by web servers or application servers, and may provide additional insight on how the web application is engineered. For example, a \u0026ldquo;.pl\u0026rdquo; extension is usually associated with server-side Perl support. However, the file extension alone may be deceptive and not fully conclusive. For example, Perl server-side resources might be renamed to conceal the fact that they are indeed Perl related. See the next section on \u0026ldquo;web server components\u0026rdquo; for more on identifying server-side technologies and components.\nTest Objectives  Dirbust sensitive file extensions, or extensions that might contain raw data (e.g. scripts, raw data, credentials, etc.). Validate that no system framework bypasses exist on the rules set.  How to Test Forced Browsing Submit requests with different file extensions and verify how they are handled. The verification should be on a per web directory basis. Verify directories that allow script execution. Web server directories can be identified by scanning tools which look for the presence of well-known directories. In addition, mirroring the web site structure allows the tester to reconstruct the tree of web directories served by the application.\nIf the web application architecture is load-balanced, it is important to assess all of the web servers. This may or may not be easy, depending on the configuration of the balancing infrastructure. In an infrastructure with redundant components there may be slight variations in the configuration of individual web or application servers. This may happen if the web architecture employs heterogeneous technologies (think of a set of IIS and Apache web servers in a load-balancing configuration, which may introduce slight asymmetric behavior between them, and possibly different vulnerabilities).\nExample The tester has identified the existence of a file named connection.inc. Trying to access it directly gives back its contents, which are:\n\u0026lt;? mysql_connect(\u0026#34;127.0.0.1\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;) or die(\u0026#34;Could not connect\u0026#34;); ?\u0026gt;The tester determines the existence of a MySQL DBMS back end, and the (weak) credentials used by the web application to access it.\nThe following file extensions should never be returned by a web server, since they are related to files which may contain sensitive information or to files for which there is no reason to be served.\n .asa .inc .config  The following file extensions are related to files which, when accessed, are either displayed or downloaded by the browser. Therefore, files with these extensions must be checked to verify that they are indeed supposed to be served (and are not leftovers), and that they do not contain sensitive information.\n .zip, .tar, .gz, .tgz, .rar, etc.: (Compressed) archive files .java: No reason to provide access to Java source files .txt: Text files .pdf: PDF documents .docx, .rtf, .xlsx, .pptx, etc.: Office documents .bak, .old and other extensions indicative of backup files (for example: ~ for Emacs backup files)  The list given above details only a few examples, since file extensions are too many to be comprehensively treated here. Refer to FILExt for a more thorough database of extensions.\nTo identify files having a given extensions a mix of techniques can be employed. These techniques can include Vulnerability Scanners, spidering and mirroring tools, manually inspecting the application (this overcomes limitations in automatic spidering), querying search engines (see Testing: Spidering and googling). See also Testing for Old, Backup and Unreferenced Files which deals with the security issues related to \u0026ldquo;forgotten\u0026rdquo; files.\nFile Upload Windows 8.3 legacy file handling can sometimes be used to defeat file upload filters.\nUsage Examples:\n file.phtml gets processed as PHP code. FILE~1.PHT is served, but not processed by the PHP ISAPI handler. shell.phPWND can be uploaded. SHELL~1.PHP will be expanded and returned by the OS shell, then processed by the PHP ISAPI handler.  Gray-Box Testing Performing white-box testing against file extensions handling amounts to checking the configurations of web servers or application servers taking part in the web application architecture, and verifying how they are instructed to serve different file extensions.\nIf the web application relies on a load-balanced, heterogeneous infrastructure, determine whether this may introduce different behavior.\nTools Vulnerability scanners, such as Nessus and Nikto check for the existence of well-known web directories. They may allow the tester to download the web site structure, which is helpful when trying to determine the configuration of web directories and how individual file extensions are served. Other tools that can be used for this purpose include:\n wget curl google for \u0026ldquo;web mirroring tools\u0026rdquo;.  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/04-review_old_backup_and_unreferenced_files_for_sensitive_information/",
	"title": "Review Old Backup and Unreferenced Files for Sensitive Information",
	"tags": [],
	"description": "",
	"content": "Review Old Backup and Unreferenced Files for Sensitive Information    ID     WSTG-CONF-04    Summary While most of the files within a web server are directly handled by the server itself, it isn\u0026rsquo;t uncommon to find unreferenced or forgotten files that can be used to obtain important information about the infrastructure or the credentials.\nMost common scenarios include the presence of renamed old versions of modified files, inclusion files that are loaded into the language of choice and can be downloaded as source, or even automatic or manual backups in form of compressed archives. Backup files can also be generated automatically by the underlying file system the application is hosted on, a feature usually referred to as \u0026ldquo;snapshots\u0026rdquo;.\nAll these files may grant the tester access to inner workings, back doors, administrative interfaces, or even credentials to connect to the administrative interface or the database server.\nAn important source of vulnerability lies in files which have nothing to do with the application, but are created as a consequence of editing application files, or after creating on-the-fly backup copies, or by leaving in the web tree old files or unreferenced files.Performing in-place editing or other administrative actions on production web servers may inadvertently leave backup copies, either generated automatically by the editor while editing files, or by the administrator who is zipping a set of files to create a backup.\nIt is easy to forget such files and this may pose a serious security threat to the application. That happens because backup copies may be generated with file extensions differing from those of the original files. A .tar, .zip or .gz archive that we generate (and forget\u0026hellip;) has obviously a different extension, and the same happens with automatic copies created by many editors (for example, emacs generates a backup copy named file~ when editing file). Making a copy by hand may produce the same effect (think of copying file to file.old). The underlying file system the application is on could be making snapshots of your application at different points in time without your knowledge, which may also be accessible via the web, posing a similar but different backup file style threat to your application.\nAs a result, these activities generate files that are not needed by the application and may be handled differently than the original file by the web server. For example, if we make a copy of login.asp named login.asp.old, we are allowing users to download the source code of login.asp. This is because login.asp.old will be typically served as text or plain, rather than being executed because of its extension. In other words, accessing login.asp causes the execution of the server-side code of login.asp, while accessing login.asp.old causes the content of login.asp.old (which is, again, server-side code) to be plainly returned to the user and displayed in the browser. This may pose security risks, since sensitive information may be revealed.\nGenerally, exposing server-side code is a bad idea. Not only are you unnecessarily exposing business logic, but you may be unknowingly revealing application-related information which may help an attacker (path names, data structures, etc.). Not to mention the fact that there are too many scripts with embedded username and password in clear text (which is a careless and very dangerous practice).\nOther causes of unreferenced files are due to design or configuration choices when they allow diverse kind of application-related files such as data files, configuration files, log files, to be stored in file system directories that can be accessed by the web server. These files have normally no reason to be in a file system space that could be accessed via web, since they should be accessed only at the application level, by the application itself (and not by the casual user browsing around).\nThreats Old, backup and unreferenced files present various threats to the security of a web application:\n Unreferenced files may disclose sensitive information that can facilitate a focused attack against the application; for example include files containing database credentials, configuration files containing references to other hidden content, absolute file paths, etc. Unreferenced pages may contain powerful functionality that can be used to attack the application; for example an administration page that is not linked from published content but can be accessed by any user who knows where to find it. Old and backup files may contain vulnerabilities that have been fixed in more recent versions; for example viewdoc.old.jsp may contain a directory traversal vulnerability that has been fixed in viewdoc.jsp but can still be exploited by anyone who finds the old version. Backup files may disclose the source code for pages designed to execute on the server; for example requesting viewdoc.bak may return the source code for viewdoc.jsp, which can be reviewed for vulnerabilities that may be difficult to find by making blind requests to the executable page. While this threat obviously applies to scripted languages, such as Perl, PHP, ASP, shell scripts, JSP, etc., it is not limited to them, as shown in the example provided in the next bullet. Backup archives may contain copies of all files within (or even outside) the webroot. This allows an attacker to quickly enumerate the entire application, including unreferenced pages, source code, include files, etc. For example, if you forget a file named myservlets.jar.old file containing (a backup copy of) your servlet implementation classes, you are exposing a lot of sensitive information which is susceptible to decompilation and reverse engineering. In some cases copying or editing a file does not modify the file extension, but modifies the filename. This happens for example in Windows environments, where file copying operations generate filenames prefixed with \u0026ldquo;Copy of \u0026quot; or localized versions of this string. Since the file extension is left unchanged, this is not a case where an executable file is returned as plain text by the web server, and therefore not a case of source code disclosure. However, these files too are dangerous because there is a chance that they include obsolete and incorrect logic that, when invoked, could trigger application errors, which might yield valuable information to an attacker, if diagnostic message display is enabled. Log files may contain sensitive information about the activities of application users, for example sensitive data passed in URL parameters, session IDs, URLs visited (which may disclose additional unreferenced content), etc. Other log files (e.g. ftp logs) may contain sensitive information about the maintenance of the application by system administrators. File system snapshots may contain copies of the code that contain vulnerabilities that have been fixed in more recent versions. For example /.snapshot/monthly.1/view.php may contain a directory traversal vulnerability that has been fixed in /view.php but can still be exploited by anyone who finds the old version.  Test Objectives  Find and analyse unreferenced files that might contain sensitive information.  How to Test Black-Box Testing Testing for unreferenced files uses both automated and manual techniques, and typically involves a combination of the following:\nInference from the Naming Scheme Used for Published Content Enumerate all of the application’s pages and functionality. This can be done manually using a browser, or using an application spidering tool. Most applications use a recognizable naming scheme, and organize resources into pages and directories using words that describe their function. From the naming scheme used for published content, it is often possible to infer the name and location of unreferenced pages. For example, if a page viewuser.asp is found, then look also for edituser.asp, adduser.asp and deleteuser.asp. If a directory /app/user is found, then look also for /app/admin and /app/manager.\nOther Clues in Published Content Many web applications leave clues in published content that can lead to the discovery of hidden pages and functionality. These clues often appear in the source code of HTML and JavaScript files. The source code for all published content should be manually reviewed to identify clues about other pages and functionality. For example:\nProgrammers' comments and commented-out sections of source code may refer to hidden content:\n\u0026lt;!-- \u0026lt;A HREF=\u0026#34;uploadfile.jsp\u0026#34;\u0026gt;Upload a document to the server\u0026lt;/A\u0026gt; --\u0026gt; \u0026lt;!-- Link removed while bugs in uploadfile.jsp are fixed --\u0026gt; JavaScript may contain page links that are only rendered within the user’s GUI under certain circumstances:\nvar adminUser=false; if (adminUser) menu.add (new menuItem (\u0026#34;Maintain users\u0026#34;, \u0026#34;/admin/useradmin.jsp\u0026#34;)); HTML pages may contain FORMs that have been hidden by disabling the SUBMIT element:\n\u0026lt;form action=\u0026#34;forgotPassword.jsp\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;userID\u0026#34; value=\u0026#34;123\u0026#34;\u0026gt; \u0026lt;!-- \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Forgot Password\u0026#34;\u0026gt; --\u0026gt; \u0026lt;/form\u0026gt; Another source of clues about unreferenced directories is the /robots.txt file used to provide instructions to web robots:\nUser-agent: * Disallow: /Admin Disallow: /uploads Disallow: /backup Disallow: /~jbloggs Disallow: /include Blind Guessing In its simplest form, this involves running a list of common filenames through a request engine in an attempt to guess files and directories that exist on the server. The following netcat wrapper script will read a wordlist from stdin and perform a basic guessing attack:\n#!/bin/bash  server=example.org port=80 while read url do echo -ne \u0026#34;$url\\t\u0026#34; echo -e \u0026#34;GET /$urlHTTP/1.0\\nHost: $server\\n\u0026#34; | netcat $server $port | head -1 done | tee outputfile Depending upon the server, GET may be replaced with HEAD for faster results. The output file specified can be grepped for \u0026ldquo;interesting\u0026rdquo; response codes. The response code 200 (OK) usually indicates that a valid resource has been found (provided the server does not deliver a custom \u0026ldquo;not found\u0026rdquo; page using the 200 code). But also look out for 301 (Moved), 302 (Found), 401 (Unauthorized), 403 (Forbidden) and 500 (Internal error), which may also indicate resources or directories that are worthy of further investigation.\nThe basic guessing attack should be run against the webroot, and also against all directories that have been identified through other enumeration techniques. More advanced/effective guessing attacks can be performed as follows:\n Identify the file extensions in use within known areas of the application (e.g. jsp, aspx, html), and use a basic wordlist appended with each of these extensions (or use a longer list of common extensions if resources permit). For each file identified through other enumeration techniques, create a custom wordlist derived from that filename. Get a list of common file extensions (including ~, bak, txt, src, dev, old, inc, orig, copy, tmp, swp, etc.) and use each extension before, after, and instead of, the extension of the actual filename.  Note: Windows file copying operations generate filenames prefixed with \u0026ldquo;Copy of \u0026quot; or localized versions of this string, hence they do not change file extensions. While \u0026ldquo;Copy of \u0026quot; files typically do not disclose source code when accessed, they might yield valuable information in case they cause errors when invoked.\nInformation Obtained Through Server Vulnerabilities and Misconfiguration The most obvious way in which a misconfigured server may disclose unreferenced pages is through directory listing. Request all enumerated directories to identify any which provide a directory listing.\nNumerous vulnerabilities have been found in individual web servers which allow an attacker to enumerate unreferenced content, for example:\n Apache ?M=D directory listing vulnerability. Various IIS script source disclosure vulnerabilities. IIS WebDAV directory listing vulnerabilities.  Use of Publicly Available Information Pages and functionality in Internet-facing web applications that are not referenced from within the application itself may be referenced from other public domain sources. There are various sources of these references:\n Pages that used to be referenced may still appear in the archives of Internet search engines. For example, 1998results.asp may no longer be linked from a company’s website, but may remain on the server and in search engine databases. This old script may contain vulnerabilities that could be used to compromise the entire site. The site: Google search operator may be used to run a query only against the domain of choice, such as in: site:www.example.com. Using search engines in this way has lead to a broad array of techniques which you may find useful and that are described in the Google Hacking section of this Guide. Check it to hone your testing skills via Google. Backup files are not likely to be referenced by any other files and therefore may have not been indexed by Google, but if they lie in browsable directories the search engine might know about them. In addition, Google and Yahoo keep cached versions of pages found by their robots. Even if 1998results.asp has been removed from the target server, a version of its output may still be stored by these search engines. The cached version may contain references to, or clues about, additional hidden content that still remains on the server. Content that is not referenced from within a target application may be linked to by third-party websites. For example, an application which processes online payments on behalf of third-party traders may contain a variety of bespoke functionality which can (normally) only be found by following links within the web sites of its customers.  Filename Filter Bypass Because deny list filters are based on regular expressions, one can sometimes take advantage of obscure OS filename expansion features in which work in ways the developer didn\u0026rsquo;t expect. The tester can sometimes exploit differences in ways that filenames are parsed by the application, web server, and underlying OS and it\u0026rsquo;s filename conventions.\nExample: Windows 8.3 filename expansion c:\\\\program files becomes C:\\\\PROGRA\\~1\n Remove incompatible characters Convert spaces to underscores Take the first six characters of the basename Add ~\u0026lt;digit\u0026gt; which is used to distinguish files with names using the same six initial characters This convention changes after the first 3 cname ollisions Truncate file extension to three characters Make all the characters uppercase  Gray-Box Testing Performing gray box testing against old and backup files requires examining the files contained in the directories belonging to the set of web directories served by the web server(s) of the web application infrastructure. Theoretically the examination should be performed by hand to be thorough. However, since in most cases copies of files or backup files tend to be created by using the same naming conventions, the search can be easily scripted. For example, editors leave behind backup copies by naming them with a recognizable extension or ending and humans tend to leave behind files with a .old or similar predictable extensions. A good strategy is that of periodically scheduling a background job checking for files with extensions likely to identify them as copy or backup files, and performing manual checks as well on a longer time basis.\nRemediation To guarantee an effective protection strategy, testing should be compounded by a security policy which clearly forbids dangerous practices, such as:\n Editing files in-place on the web server or application server file systems. This is a particularly bad habit, since it is likely to generate backup or temporary files by the editors. It is amazing to see how often this is done, even in large organizations. If you absolutely need to edit files on a production system, do ensure that you don’t leave behind anything which is not explicitly intended, and consider that you are doing it at your own risk. Carefully check any other activity performed on file systems exposed by the web server, such as spot administration activities. For example, if you occasionally need to take a snapshot of a couple of directories (which you should not do on a production system), you may be tempted to zip them first. Be careful not to leave behind those archive files. Appropriate configuration management policies should help prevent obsolete and un-referenced files. Applications should be designed not to create (or rely on) files stored under the web directory trees served by the web server. Data files, log files, configuration files, etc. should be stored in directories not accessible by the web server, to counter the possibility of information disclosure (not to mention data modification if web directory permissions allow writing). File system snapshots should not be accessible via the web if the document root is on a file system using this technology. Configure your web server to deny access to such directories, for example under Apache a location directive such this should be used:  \u0026lt;Location ~ \u0026#34;.snapshot\u0026#34;\u0026gt; Order deny,allow Deny from all \u0026lt;/Location\u0026gt; Tools Vulnerability assessment tools tend to include checks to spot web directories having standard names (such as \u0026ldquo;admin\u0026rdquo;, \u0026ldquo;test\u0026rdquo;, \u0026ldquo;backup\u0026rdquo;, etc.), and to report any web directory which allows indexing. If you can’t get any directory listing, you should try to check for likely backup extensions. Check for example\n Nessus Nikto2  Web spider tools\n wget Wget for Windows Sam Spade Spike proxy includes a web site crawler function Xenu curl  Some of them are also included in standard Linux distributions. Web development tools usually include facilities to identify broken links and unreferenced files.\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/05-enumerate_infrastructure_and_application_admin_interfaces/",
	"title": "Enumerate Infrastructure and Application Admin Interfaces",
	"tags": [],
	"description": "",
	"content": "Enumerate Infrastructure and Application Admin Interfaces    ID     WSTG-CONF-05    Summary Administrator interfaces may be present in the application or on the application server to allow certain users to undertake privileged activities on the site. Tests should be undertaken to reveal if and how this privileged functionality can be accessed by an unauthorized or standard user.\nAn application may require an administrator interface to enable a privileged user to access functionality that may make changes to how the site functions. Such changes may include:\n user account provisioning site design and layout data manipulation configuration changes  In many instances, such interfaces do not have sufficient controls to protect them from unauthorized access. Testing is aimed at discovering these administrator interfaces and accessing functionality intended for the privileged users.\nTest Objectives  Identify hidden administrator interfaces and functionality.  How to Test Black-Box Testing The following section describes vectors that may be used to test for the presence of administrative interfaces. These techniques may also be used to test for related issues including privilege escalation, and are described elsewhere in this guide(for example Testing for bypassing authorization schema and Testing for Insecure Direct Object References in greater detail.\n Directory and file enumeration. An administrative interface may be present but not visibly available to the tester. Attempting to guess the path of the administrative interface may be as simple as requesting: /admin or /administrator etc.. or in some scenarios can be revealed within seconds using Google dorks. There are many tools available to perform brute forcing of server contents, see the tools section below for more information. A tester may have to also identify the filename of the administration page. Forcibly browsing to the identified page may provide access to the interface. Comments and links in source code. Many sites use common code that is loaded for all site users. By examining all source sent to the client, links to administrator functionality may be discovered and should be investigated. Reviewing server and application documentation. If the application server or application is deployed in its default configuration it may be possible to access the administration interface using information described in configuration or help documentation. Default password lists should be consulted if an administrative interface is found and credentials are required. Publicly available information. Many applications such as WordPress have default administrative interfaces . Alternative server port. Administration interfaces may be seen on a different port on the host than the main application. For example, Apache Tomcat\u0026rsquo;s Administration interface can often be seen on port 8080. Parameter tampering. A GET or POST parameter or a cookie variable may be required to enable the administrator functionality. Clues to this include the presence of hidden fields such as:  \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;admin\u0026#34; value=\u0026#34;no\u0026#34;\u0026gt; or in a cookie:\nCookie: session_cookie; useradmin=0\nOnce an administrative interface has been discovered, a combination of the above techniques may be used to attempt to bypass authentication. If this fails, the tester may wish to attempt a brute force attack. In such an instance the tester should be aware of the potential for administrative account lockout if such functionality is present.\nGray-Box Testing A more detailed examination of the server and application components should be undertaken to ensure hardening (i.e. administrator pages are not accessible to everyone through the use of IP filtering or other controls), and where applicable, verification that all components do not use default credentials or configurations. Source code should be reviewed to ensure that the authorization and authentication model ensures clear separation of duties between normal users and site administrators. User interface functions shared between normal and administrator users should be reviewed to ensure clear separation between the drawing of such components and information leakage from such shared functionality.\nEach web framework may have its own admin default pages or path. For example\nWebSphere:\n/admin /admin-authz.xml /admin.conf /admin.passwd /admin/* /admin/logon.jsp /admin/secure/logon.jsp PHP:\n/phpinfo /phpmyadmin/ /phpMyAdmin/ /mysqladmin/ /MySQLadmin /MySQLAdmin /login.php /logon.php /xmlrpc.php /dbadmin FrontPage:\n/admin.dll /admin.exe /administrators.pwd /author.dll /author.exe /author.log /authors.pwd /cgi-bin WebLogic:\n/AdminCaptureRootCA /AdminClients /AdminConnections /AdminEvents /AdminJDBC /AdminLicense /AdminMain /AdminProps /AdminRealm /AdminThreads WordPress:\nwp-admin/ wp-admin/about.php wp-admin/admin-ajax.php wp-admin/admin-db.php wp-admin/admin-footer.php wp-admin/admin-functions.php wp-admin/admin-header.php Tools  OWASP ZAP - Forced Browse is a currently maintained use of OWASP\u0026rsquo;s previous DirBuster project. THC-HYDRA is a tool that allows brute-forcing of many interfaces, including form-based HTTP authentication. A brute forcer is much better when it uses a good dictionary, for example the netsparker dictionary.  References  Cirt: Default Password list FuzzDB can be used to do brute force browsing admin login path Common admin or debugging parameters  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/06-test_http_methods/",
	"title": "Test HTTP Methods",
	"tags": [],
	"description": "",
	"content": "Test HTTP Methods    ID     WSTG-CONF-06    Summary HTTP offers a number of methods that can be used to perform actions on the web server (the HTTP 1.1 standard refers to them as methods but they are also commonly described as verbs). While GET and POST are by far the most common methods that are used to access information provided by a web server, HTTP allows several other (and somewhat less known) methods. Some of these can be used for nefarious purposes if the web server is misconfigured.\nRFC 7231 – Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content defines the following valid HTTP request methods, or verbs:\n GET HEAD POST PUT DELETE CONNECT OPTIONS TRACE  However, most web applications only need to respond to GET and POST requests, receiving user data in the URL query string or appended to the request respectively. The standard \u0026lt;a href=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; style links as well as forms defined without a method trigger a GET request; form data submitted via \u0026lt;form method='POST'\u0026gt;\u0026lt;/form\u0026gt; trigger POST requests. JavaScript and AJAX calls may send methods other than GET and POST but should usually not need to do that. Since the other methods are so rarely used, many developers do not know, or fail to take into consideration, how the web server or application framework\u0026rsquo;s implementation of these methods impact the security features of the application.\nTest Objectives  Enumerate supported HTTP methods. Test for access control bypass. Test XST vulnerabilities. Test HTTP method overriding techniques.  How to Test Discover the Supported Methods To perform this test, the tester needs some way to figure out which HTTP methods are supported by the web server that is being examined. While the OPTIONS HTTP method provides a direct way to do that, verify the server\u0026rsquo;s response by issuing requests using different methods. This can be achieved by manual testing or something like the http-methods Nmap script.\nTo use the http-methods Nmap script to test the endpoint /index.php on the server localhost using HTTPS, issue the command:\nnmap -p 443 --script http-methods --script-args http-methods.url-path=\u0026#39;/index.php\u0026#39; localhost When testing an application that has to accept other methods, e.g. a RESTful Web Service, test it thoroughly to make sure that all endpoints accept only the methods that they require.\nTesting the PUT Method   Capture the base request of the target with a web proxy.\n  Change the request method to PUT and add test.html file and send the request to the application server.\nPUT /test.html HTTP/1.1 Host: testing-website \u0026lt;html\u0026gt; HTTP PUT Method is Enabled \u0026lt;/html\u0026gt;   If the server response with 2XX success codes or 3XX redirections and then confirm by GET request for test.html file. The application is vulnerable.\n  If the HTTP PUT method is not allowed on base URL or request, try other paths in the system.\n NOTE: If you are successful in uploading a web shell you should overwrite it or ensure that the security team of the target are aware and remove the component promptly after your proof-of-concept.\n Leveraging the PUT method an attacker may be able to place arbitrary and potentially malicious content, into the system which may lead to remote code execution, defacing the site or denial of service.\nTesting for Access Control Bypass Find a page to visit that has a security constraint such that a GET request would normally force a 302 redirect to a log in page or force a log in directly. Issue requests using various methods such as HEAD, POST, PUT etc. as well as arbitrarily made up methods such as BILBAO, FOOBAR, CATS, etc. If the web application responds with a HTTP/1.1 200 OK that is not a log in page, it may be possible to bypass authentication or authorization. The following example uses Nmap\u0026rsquo;s ncat.\n$ ncat www.example.com 80 HEAD /admin HTTP/1.1 Host: www.example.com HTTP/1.1 200 OK Date: Mon, 18 Aug 2008 22:44:11 GMT Server: Apache Set-Cookie: PHPSESSID=pKi...; path=/; HttpOnly Expires: Thu, 19 Nov 1981 08:52:00 GMT Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0 Pragma: no-cache Set-Cookie: adminOnlyCookie1=...; expires=Tue, 18-Aug-2009 22:44:31 GMT; domain=www.example.com Set-Cookie: adminOnlyCookie2=...; expires=Mon, 18-Aug-2008 22:54:31 GMT; domain=www.example.com Set-Cookie: adminOnlyCookie3=...; expires=Sun, 19-Aug-2007 22:44:30 GMT; domain=www.example.com Content-Language: EN Connection: close Content-Type: text/html; charset=ISO-8859-1 If the system appears vulnerable, issue CSRF-like attacks such as the following to exploit the issue more fully:\n HEAD /admin/createUser.php?member=myAdmin PUT /admin/changePw.php?member=myAdmin\u0026amp;passwd=foo123\u0026amp;confirm=foo123 CATS /admin/groupEdit.php?group=Admins\u0026amp;member=myAdmin\u0026amp;action=add  Using the above three commands, modified to suit the application under test and testing requirements, a new user would be created, a password assigned, and the user made an administrator, all using blind request submission.\nTesting for Cross-Site Tracing Potential Note: in order to understand the logic and the goals of a cross-site tracing (XST) attack, one must be familiar with cross-site scripting attacks.\nThe TRACE method, intended for testing and debugging, instructs the web server to reflect the received message back to the client. This method, while apparently harmless, can be successfully leveraged in some scenarios to steal legitimate users' credentials. This attack technique was discovered by Jeremiah Grossman in 2003, in an attempt to bypass the HttpOnly attribute that aims to protect cookies from being accessed by JavaScript. However, the TRACE method can be used to bypass this protection and access the cookie even when this attribute is set.\nTest for cross-site tracing potential by issuing a request such as the following:\n$ ncat www.victim.com 80 TRACE / HTTP/1.1 Host: www.victim.com Random: Header HTTP/1.1 200 OK Random: Header ... The web server returned a 200 and reflected the random header that was set in place. To further exploit this issue:\n$ ncat www.victim.com 80 TRACE / HTTP/1.1 Host: www.victim.com Attack: \u0026lt;script\u0026gt;prompt()\u0026lt;/script\u0026gt; The above example works if the response is being reflected in the HTML context.\nIn older browsers, attacks were pulled using XHR technology, which leaked the headers when the server reflects them (e.g. Cookies, Authorization tokens, etc.) and bypassed security measures such as the HttpOnly attribute. This attack can be pulled in recent browsers only if the application integrates with technologies similar to Flash.\nTesting for HTTP Method Overriding Some web frameworks provide a way to override the actual HTTP method in the request by emulating the missing HTTP verbs passing some custom header in the requests. The main purpose of this is to circumvent some middleware (e.g. proxy, firewall) limitation where methods allowed usually do not encompass verbs such as PUT or DELETE. The following alternative headers could be used to do such verb tunneling:\n X-HTTP-Method X-HTTP-Method-Override X-Method-Override  In order to test this, in the scenarios where restricted verbs such as PUT or DELETE return a \u0026ldquo;405 Method not allowed\u0026rdquo;, replay the same request with the addition of the alternative headers for HTTP method overriding, and observe how the system responds. The application should respond with a different status code (e.g. 200) in cases where method overriding is supported.\nThe web server in the following example does not allow the DELETE method and blocks it:\n$ ncat www.example.com 80 DELETE /resource.html HTTP/1.1 Host: www.example.com HTTP/1.1 405 Method Not Allowed Date: Sat, 04 Apr 2020 18:26:53 GMT Server: Apache Allow: GET,HEAD,POST,OPTIONS Content-Length: 320 Content-Type: text/html; charset=iso-8859-1 Vary: Accept-Encoding After adding the X-HTTP-Method header, the server responds to the request with a 200:\n$ ncat www.example.com 80 DELETE /resource.html HTTP/1.1 Host: www.example.com X-HTTP-Method: DELETE HTTP/1.1 200 OK Date: Sat, 04 Apr 2020 19:26:01 GMT Server: Apache Remediation  Ensure that only the required headers are allowed, and that the allowed headers are properly configured. Ensure that no workarounds are implemented to bypass security measures implemented by user-agents, frameworks, or web servers.  Tools  Ncat cURL nmap http-methods NSE script w3af plugin htaccess_methods  References  RFC 2109 and RFC 2965: \u0026ldquo;HTTP State Management Mechanism\u0026rdquo; HTACCESS: BILBAO Method Exposed Amit Klein: \u0026ldquo;XS(T) attack variants which can, in some cases, eliminate the need for TRACE\u0026rdquo; Fortify - Misused HTTP Method Override CAPEC-107: Cross Site Tracing  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/07-test_http_strict_transport_security/",
	"title": "Test HTTP Strict Transport Security",
	"tags": [],
	"description": "",
	"content": "Test HTTP Strict Transport Security    ID     WSTG-CONF-07    Summary The HTTP Strict Transport Security (HSTS) feature lets a web application inform the browser through the use of a special response header that it should never establish a connection to the specified domain servers using un-encrypted HTTP. Instead, it should automatically establish all connection requests to access the site through HTTPS. It also prevents users from overriding certificate errors.\nConsidering the importance of this security measure it is prudent to verify that the web site is using this HTTP header in order to ensure that all the data travels encrypted between the web browser and the server.\nThe HTTP strict transport security header uses two directives:\n max-age: to indicate the number of seconds that the browser should automatically convert all HTTP requests to HTTPS. includeSubDomains: to indicate that all related sub-domains must use HTTPS. preload Unofficial: to indicate that the domain(s) are on the preload list(s) and that browsers should never connect without HTTPS.  This is supported by all major browsers but is not official part of the specification. (See hstspreload.org for more information.)    Here\u0026rsquo;s an example of the HSTS header implementation:\nStrict-Transport-Security: max-age=31536000; includeSubDomains\nThe use of this header by web applications must be checked to find if the following security issues could be produced:\n Attackers sniffing the network traffic and accessing the information transferred through an un-encrypted channel. Attackers exploiting a manipulator in the middle attack because of the problem of accepting certificates that are not trusted. Users who mistakenly entered an address in the browser putting HTTP instead of HTTPS, or users who click on a link in a web application which mistakenly indicated use of the HTTP protocol.  Test Objectives  Review the HSTS header and its validity.  How to Test The presence of the HSTS header can be confirmed by examining the server\u0026rsquo;s response through an intercepting proxy or by using curl as follows:\n$ curl -s -D- https://owasp.org | grep -i strict Strict-Transport-Security: max-age=31536000 References  OWASP HTTP Strict Transport Security OWASP Appsec Tutorial Series - Episode 4: Strict Transport Security HSTS Specification  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/08-test_ria_cross_domain_policy/",
	"title": "Test RIA Cross Domain Policy",
	"tags": [],
	"description": "",
	"content": "Test RIA Cross Domain Policy    ID     WSTG-CONF-08    Summary Rich Internet Applications (RIA) have adopted Adobe\u0026rsquo;s crossdomain.xml policy files to allow for controlled cross domain access to data and service consumption using technologies such as Oracle Java, Silverlight, and Adobe Flash. Therefore, a domain can grant remote access to its services from a different domain. However, often the policy files that describe the access restrictions are poorly configured. Poor configuration of the policy files enables Cross-site Request Forgery attacks, and may allow third parties to access sensitive data meant for the user.\nWhat are cross-domain policy files? A cross-domain policy file specifies the permissions that a web client such as Java, Adobe Flash, Adobe Reader, etc. use to access data across different domains. For Silverlight, Microsoft adopted a subset of the Adobe\u0026rsquo;s crossdomain.xml, and additionally created it\u0026rsquo;s own cross-domain policy file: clientaccesspolicy.xml.\nWhenever a web client detects that a resource has to be requested from other domain, it will first look for a policy file in the target domain to determine if performing cross-domain requests, including headers, and socket-based connections are allowed.\nMaster policy files are located at the domain\u0026rsquo;s root. A client may be instructed to load a different policy file but it will always check the master policy file first to ensure that the master policy file permits the requested policy file.\nCrossdomain.xml vs. Clientaccesspolicy.xml Most RIA applications support crossdomain.xml. However in the case of Silverlight, it will only work if the crossdomain.xml specifies that access is allowed from any domain. For more granular control with Silverlight, clientaccesspolicy.xml must be used.\nPolicy files grant several types of permissions:\n Accepted policy files (Master policy files can disable or restrict specific policy files) Sockets permissions Header permissions HTTP/HTTPS access permissions Allowing access based on cryptographic credentials  An example of an overly permissive policy file:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE cross-domain-policy SYSTEM \u0026#34;http://www.adobe.com/xml/dtds/cross-domain-policy.dtd\u0026#34;\u0026gt; \u0026lt;cross-domain-policy\u0026gt; \u0026lt;site-control permitted-cross-domain-policies=\u0026#34;all\u0026#34;/\u0026gt; \u0026lt;allow-access-from domain=\u0026#34;*\u0026#34; secure=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;allow-http-request-headers-from domain=\u0026#34;*\u0026#34; headers=\u0026#34;*\u0026#34; secure=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/cross-domain-policy\u0026gt; How can cross domain policy files can be abused?  Overly permissive cross-domain policies. Generating server responses that may be treated as cross-domain policy files. Using file upload functionality to upload files that may be treated as cross-domain policy files.  Impact of Abusing Cross-Domain Access  Defeat CSRF protections. Read data restricted or otherwise protected by cross-origin policies.  Test Objectives  Review and validate the policy files.  How to Test Testing for RIA Policy Files Weakness To test for RIA policy file weakness the tester should try to retrieve the policy files crossdomain.xml and clientaccesspolicy.xml from the application\u0026rsquo;s root, and from every folder found.\nFor example, if the application\u0026rsquo;s URL is http://www.owasp.org, the tester should try to download the files http://www.owasp.org/crossdomain.xml and http://www.owasp.org/clientaccesspolicy.xml.\nAfter retrieving all the policy files, the permissions allowed should be be checked under the least privilege principle. Requests should only come from the domains, ports, or protocols that are necessary. Overly permissive policies should be avoided. Policies with * in them should be closely examined.\nExample \u0026lt;cross-domain-policy\u0026gt; \u0026lt;allow-access-from domain=\u0026#34;*\u0026#34; /\u0026gt; \u0026lt;/cross-domain-policy\u0026gt; Result Expected  A list of policy files found. A list of weak settings in the policies.  Tools  Nikto OWASP Zed Attack Proxy Project W3af  References  Adobe: \u0026ldquo;Cross-domain policy file specification\u0026rdquo; Adobe: \u0026ldquo;Cross-domain policy file usage recommendations for Flash Player\u0026rdquo; Oracle: \u0026ldquo;Cross-Domain XML Support\u0026rdquo; MSDN: \u0026ldquo;Making a Service Available Across Domain Boundaries\u0026rdquo; MSDN: \u0026ldquo;Network Security Access Restrictions in Silverlight\u0026rdquo; Stefan Esser: \u0026ldquo;Poking new holes with Flash Crossdomain Policy Files\u0026rdquo; Jeremiah Grossman: \u0026ldquo;Crossdomain.xml Invites Cross-site Mayhem\u0026rdquo; Google Doctype: \u0026ldquo;Introduction to Flash security\u0026rdquo; UCSD: Analyzing the Crossdomain Policies of Flash Applications  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/09-test_file_permission/",
	"title": "Test File Permission",
	"tags": [],
	"description": "",
	"content": "Test File Permission    ID     WSTG-CONF-09    Summary When a resource is given a permissions setting that provides access to a wider range of actors than required, it could lead to the exposure of sensitive information, or the modification of that resource by unintended parties. This is especially dangerous when the resource is related to program configuration, execution, or sensitive user data.\nA clear example is an execution file that is executable by unauthorized users. For another example, account information or a token value to access an API - increasingly seen in modern web services or microservices - may be stored in a configuration file whose permissions are set to world-readable from the installation by default. Such sensitive data can be exposed by internal malicious actors of the host or by a remote attacker who compromised the service with other vulnerabilities but obtained only a normal user privilege.\nTest Objectives  Review and identify any rogue file permissions.  How to Test In Linux, use ls command to check the file permissions. Alternatively, namei can also be used to recursively list file permissions.\n$ namei -l /PathToCheck/\nThe files and directories that require file permission testing include but are not limited to:\n Web files/directory Configuration files/directory Sensitive files (encrypted data, password, key)/directory Log files (security logs, operation logs, admin logs)/directory Executables (scripts, EXE, JAR, class, PHP, ASP)/directory Database files/directory Temp files /directory Upload files/directory  Remediation Set the permissions of the files and directories properly so that unauthorized users cannot access critical resources unnecessarily.\nTools  Windows AccessEnum Windows AccessChk Linux namei  References  CWE-732: Incorrect Permission Assignment for Critical Resource  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/10-test_for_subdomain_takeover/",
	"title": "Test for Subdomain Takeover",
	"tags": [],
	"description": "",
	"content": "Test for Subdomain Takeover    ID     WSTG-CONF-10    Summary A successful exploitation of this kind of vulnerability allows an adversary to claim and take control of the victim\u0026rsquo;s subdomain. This attack relies on the following:\n The victim\u0026rsquo;s external DNS server subdomain record is configured to point to a non-existing or non-active resource/external service/endpoint. The proliferation of XaaS (Anything as a Service) products and public cloud services offer a lot of potential targets to consider. The service provider hosting the resource/external service/endpoint does not handle subdomain ownership verification properly.  If the subdomain takeover is successful a wide variety of attacks are possible (serving malicious content, phising, stealing user session cookies, credentials, etc.). This vulnerability could be exploited for a wide variety of DNS resource records including: A, CNAME, MX, NS, TXT etc. In terms of the attack severity an NS subdomain takeover (although less likely) has the highest impact because a successful attack could result in full control over the whole DNS zone and the victim\u0026rsquo;s domain.\nGitHub  The victim (victim.com) uses GitHub for development and configured a DNS record (coderepo.victim.com) to access it. The victim decides to migrate their code repository from GitHub to a commercial platform and does not remove coderepo.victim.com from their DNS server. An adversary finds out that coderepo.victim.com is hosted on GitHub and uses GitHub Pages to claim coderepo.victim.com using their GitHub account.  Expired Domain  The victim (victim.com) owns another domain (victimotherdomain.com) and uses a CNAME record (www) to reference the other domain (www.victim.com \u0026ndash;\u0026gt; victimotherdomain.com) At some point, victimotherdomain.com expires and is available for registration by anyone. Since the CNAME record is not deleted from the victim.com DNS zone, anyone who registers victimotherdomain.com has full control over www.victim.com until the DNS record is present.  Test Objectives  Enumerate all possible domains (previous and current). Identify forgotten or misconfigured domains.  How to Test Black-Box Testing The first step is to enumerate the victim DNS servers and resource records. There are multiple ways to accomplish this task, for example DNS enumeration using a list of common subdomains dictionary, DNS brute force or using web search engines and other OSINT data sources.\nUsing the dig command the tester looks for the following DNS server response messages that warrant further investigation:\n NXDOMAIN SERVFAIL REFUSED no servers could be reached.  Testing DNS A, CNAME Record Subdomain Takeover Perform a basic DNS enumeration on the victim\u0026rsquo;s domain (victim.com) using dnsrecon:\n$ ./dnsrecon.py -d victim.com [*] Performing General Enumeration of Domain: victim.com ... [-] DNSSEC is not configured for victim.com [*] A subdomain.victim.com 192.30.252.153 [*] CNAME subdomain1.victim.com fictioussubdomain.victim.com ... Identify which DNS resource records are dead and point to inactive/not-used services. Using the dig command for the CNAME record:\n$ dig CNAME fictioussubdomain.victim.com ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.3-P4-Ubuntu \u0026lt;\u0026lt;\u0026gt;\u0026gt; ns victim.com ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NXDOMAIN, id: 42950 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1 The following DNS responses warrant further investigation: NXDOMAIN.\nTo test the A record the tester performs a whois database lookup and identifies GitHub as the service provider:\n$ whois 192.30.252.153 | grep \u0026#34;OrgName\u0026#34; OrgName: GitHub, Inc. The tester visits subdomain.victim.com or issues a HTTP GET request which returns a \u0026ldquo;404 - File not found\u0026rdquo; response which is a clear indication of the vulnerability.\nFigure 4.2.10-1: GitHub 404 File Not Found response\nThe tester claims the domain using GitHub Pages:\nFigure 4.2.10-2: GitHub claim domain\nTesting NS Record Subdomain Takeover Identify all nameservers for the domain in scope:\n$ dig ns victim.com +short ns1.victim.com nameserver.expireddomain.com In this fictious example the tester checks if the domain expireddomain.com is active with a domain registrar search. If the domain is available for purchase the subdomain is vulnerable.\nThe following DNS responses warrant further investigation: SERVFAIL or REFUSED.\nGray-Box Testing The tester has the DNS zone file available which means DNS enumeration is not necessary. The testing methodology is the same.\nRemediation To mitigate the risk of subdomain takeover the vulnerable DNS resource record(s) should be removed from the DNS zone. Continous monitoring and periodic checks are recommended as best practice.\nTools  dig - man page recon-ng - Web Reconnaissance framework theHarvester - OSINT intelligence gathering tool Sublist3r - OSINT subdomain enumeration tool dnsrecon - DNS Enumeration Script OWASP Amass DNS enumeration  References  HackerOne - A Guide To Subdomain Takeovers Subdomain Takeover: Basics Subdomain Takeover: Going beyond CNAME can-i-take-over-xyz - A list of vulnerable services OWASP AppSec Europe 2017 - Frans Rosén: DNS hijacking using cloud providers – no verification needed  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/02-configuration_and_deployment_management_testing/11-test_cloud_storage/",
	"title": "Test Cloud Storage",
	"tags": [],
	"description": "",
	"content": "Test Cloud Storage    ID     WSTG-CONF-11    Summary Cloud storage services facilitate web application and services to store and access objects in the storage service. Improper access control configuration, however, may result in sensitive information exposure, data being tampered, or unauthorized access.\nA known example is where an Amazon S3 bucket is misconfigured, although the other cloud storage services may also be exposed to similar risks. By default, all S3 buckets are private and can be accessed only by users that are explicitly granted access. Users can grant public access to both the bucket itself and to individual objects stored within that bucket. This may lead to an unauthorized user being able to upload new files, modify or read stored files.\nTest Objectives  Assess that the access control configuration for the storage services is properly in place.  How to Test First identify the URL to access the data in the storage service, and then consider the following tests:\n read the unauthorized data upload a new arbitrary file  You may use curl for the tests with the following commands and see if unauthorized actions can be performed successfully.\nTo test the ability to read an object:\ncurl -X GET https://\u0026lt;cloud-storage-service\u0026gt;/\u0026lt;object\u0026gt; To test the ability to upload a file:\ncurl -X PUT -d \u0026#39;test\u0026#39; \u0026#39;https://\u0026lt;cloud-storage-service\u0026gt;/test.txt\u0026#39; Testing for Amazon S3 Bucket Misconfiguration The Amazon S3 bucket URLs follow one of two formats, either virtual host style or path-style.\n Virtual Hosted Style Access  https://bucket-name.s3.Region.amazonaws.com/key-name In the following example, my-bucket is the bucket name, us-west-2 is the region, and puppy.png is the key-name:\nhttps://my-bucket.s3.us-west-2.amazonaws.com/puppy.png  Path-Style Access  https://s3.Region.amazonaws.com/bucket-name/key-name As above, in the following example, my-bucket is the bucket name, us-west-2 is the region, and puppy.png is the key-name:\nhttps://s3.us-west-2.amazonaws.com/my-bucket/puppy.jpg For some regions, the legacy global endpoint that does not specify a region-specific endpoint can be used. Its format is also either virtual hosted style or path-style.\n Virtual Hosted Style Access  https://bucket-name.s3.amazonaws.com  Path-Style Access  https://s3.amazonaws.com/bucket-name Identify Bucket URL For black-box testing, S3 URLs can be found in the HTTP messages. The following example shows a bucket URL is sent in the img tag in a HTTP response.\n... \u0026lt;img src=\u0026#34;https://my-bucket.s3.us-west-2.amazonaws.com/puppy.png\u0026#34;\u0026gt; ... For gray-box testing, you can obtain bucket URLs from Amazon\u0026rsquo;s web interface, documents, source code, or any other available sources.\nTesting with AWS-CLI In addition to testing with curl, you can also test with the AWS Command-line tool. In this case s3:// protocol is used.\nList The following command lists all the objects of the bucket when it is configured public.\naws s3 ls s3://\u0026lt;bucket-name\u0026gt; Upload The following is the command to upload a file\naws s3 cp arbitrary-file s3://bucket-name/path-to-save This example shows the result when the upload has been successful.\n$ aws s3 cp test.txt s3://bucket-name/test.txt upload: ./test.txt to s3://bucket-name/test.txt This example shows the result when the upload has failed.\n$ aws s3 cp test.txt s3://bucket-name/test.txt upload failed: ./test2.txt to s3://bucket-name/test2.txt An error occurred (AccessDenied) when calling the PutObject operation: Access Denied Remove The following is the command to remove an object\naws s3 rm s3://bucket-name/object-to-remove Tools  AWS CLI  References  Working with Amazon S3 Buckets flAWS 2  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/03-identity_management_testing/01-test_role_definitions/",
	"title": "Test Role Definitions",
	"tags": [],
	"description": "",
	"content": "Test Role Definitions    ID     WSTG-IDNT-01    Summary Applications have several types of functionalities and services, and those require access permissions based on the needs of the user. That user could be:\n an administrator, where they manage the application functionalities. an auditor, where they review the application transactions and provide a detailed report. a support engineer, where they help customers debug and fix issues on their accounts. a customer, where they interact with the application and benefit from its services.  In order to handle these uses and any other use case for that application, role definitions are setup (more commonly known as RBAC). Based on these roles, the user is capable of accomplishing the required task.\nTest Objectives  Identify and document roles used by the application. Attempt to switch, change, or access another role. Review the granularity of the roles and the needs behind the permissions given.  How to Test Roles Identification The tester should start by identifying the application roles being tested through any of the following methods:\n Application documentation. Guidance by the developers or administrators of the application. Application comments. Fuzz possible roles:  cookie variable (e.g. role=admin, isAdmin=True) account variable (e.g. Role: manager) hidden directories or files (e.g. /admin, /mod, /backups) switching to well known users (e.g. admin, backups, etc.)    Switching to Available Roles After identifying possible attack vectors, the tester needs to test and validate that they can access the available roles.\n Some applications define the roles of the user on creation, through rigorous checks and policies, or by ensuring that the user\u0026rsquo;s role is properly protected through a signature created by the backend. Finding that roles exist doesn\u0026rsquo;t mean that they\u0026rsquo;re a vulnerability.\n Review Roles Permissions After gaining access to the roles on the system, the tester must understand the permissions provided to each role.\nA support engineer shouldn\u0026rsquo;t be able to conduct administrative functionalities, manage the backups, or conduct any transactions in the place of a user.\nAn administrator shouldn\u0026rsquo;t have full powers on the system. Sensitive admin functionality should leverage a maker-checker principle, or use MFA to ensure that the administrator is conducting the transaction. A clear example on this was the Twitter incident in 2020.\nTools The above mentioned tests can be conducted without the use of any tool, except the one being used to access the system.\nTo make things easier and more documented, one can use:\n Burp\u0026rsquo;s Autorize extension ZAP\u0026rsquo;s Access Control Testing add-on  References  Role Engineering for Enterprise Security Management, E Coyne \u0026amp; J Davis, 2007 Role engineering and RBAC standards  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/03-identity_management_testing/02-test_user_registration_process/",
	"title": "Test User Registration Process",
	"tags": [],
	"description": "",
	"content": "Test User Registration Process    ID     WSTG-IDNT-02    Summary Some websites offer a user registration process that automates (or semi-automates) the provisioning of system access to users. The identity requirements for access vary from positive identification to none at all, depending on the security requirements of the system. Many public applications completely automate the registration and provisioning process because the size of the user base makes it impossible to manage manually. However, many corporate applications will provision users manually, so this test case may not apply.\nTest Objectives  Verify that the identity requirements for user registration are aligned with business and security requirements. Validate the registration process.  How to Test Verify that the identity requirements for user registration are aligned with business and security requirements:\n Can anyone register for access? Are registrations vetted by a human prior to provisioning, or are they automatically granted if the criteria are met? Can the same person or identity register multiple times? Can users register for different roles or permissions? What proof of identity is required for a registration to be successful? Are registered identities verified?  Validate the registration process:\n Can identity information be easily forged or faked? Can the exchange of identity information be manipulated during registration?  Example In the WordPress example below, the only identification requirement is an email address that is accessible to the registrant.\nFigure 4.3.2-1: WordPress Registration Page\nIn contrast, in the Google example below the identification requirements include name, date of birth, country, mobile phone number, email address and CAPTCHA response. While only two of these can be verified (email address and mobile number), the identification requirements are stricter than WordPress.\nFigure 4.3.2-2: Google Registration Page\nRemediation Implement identification and verification requirements that correspond to the security requirements of the information the credentials protect.\nTools A HTTP proxy can be a useful tool to test this control.\nReferences User Registration Design\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/03-identity_management_testing/03-test_account_provisioning_process/",
	"title": "Test Account Provisioning Process",
	"tags": [],
	"description": "",
	"content": "Test Account Provisioning Process    ID     WSTG-IDNT-03    Summary The provisioning of accounts presents an opportunity for an attacker to create a valid account without application of the proper identification and authorization process.\nTest Objectives  Verify which accounts may provision other accounts and of what type.  How to Test Determine which roles are able to provision users and what sort of accounts they can provision.\n Is there any verification, vetting and authorization of provisioning requests? Is there any verification, vetting and authorization of de-provisioning requests? Can an administrator provision other administrators or just users? Can an administrator or other user provision accounts with privileges greater than their own? Can an administrator or user de-provision themselves? How are the files or resources owned by the de-provisioned user managed? Are they deleted? Is access transferred?  Example In WordPress, only a user\u0026rsquo;s name and email address are required to provision the user, as shown below:\nFigure 4.3.3-1: WordPress User Add\nDe-provisioning of users requires the administrator to select the users to be de-provisioned, select Delete from the dropdown menu (circled) and then applying this action. The administrator is then presented with a dialog box asking what to do with the user\u0026rsquo;s posts (delete or transfer them).\nFigure 4.3.3-2: WordPress Auth and Users\nTools While the most thorough and accurate approach to completing this test is to conduct it manually, HTTP proxy tools could be also useful.\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/03-identity_management_testing/04-testing_for_account_enumeration_and_guessable_user_account/",
	"title": "Testing for Account Enumeration and Guessable User Account",
	"tags": [],
	"description": "",
	"content": "Testing for Account Enumeration and Guessable User Account    ID     WSTG-IDNT-04    Summary The scope of this test is to verify if it is possible to collect a set of valid usernames by interacting with the authentication mechanism of the application. This test will be useful for brute force testing, in which the tester verifies if, given a valid username, it is possible to find the corresponding password.\nOften, web applications reveal when a username exists on system, either as a consequence of mis-configuration or as a design decision. For example, sometimes, when we submit wrong credentials, we receive a message that states that either the username is present on the system or the provided password is wrong. The information obtained can be used by an attacker to gain a list of users on system. This information can be used to attack the web application, for example, through a brute force or default username and password attack.\nThe tester should interact with the authentication mechanism of the application to understand if sending particular requests causes the application to answer in different manners. This issue exists because the information released from web application or web server when the user provide a valid username is different than when they use an invalid one.\nIn some cases, a message is received that reveals if the provided credentials are wrong because an invalid username or an invalid password was used. Sometimes, testers can enumerate the existing users by sending a username and an empty password.\nTest Objectives  Review processes that pertain to user identification (e.g. registration, login, etc.). Enumerate users where possible through response analysis.  How to Test In black-box testing, the tester knows nothing about the specific application, username, application logic, error messages on log in page, or password recovery facilities. If the application is vulnerable, the tester receives a response message that reveals, directly or indirectly, some information useful for enumerating users.\nHTTP Response Message Testing for Valid Credentials Record the server answer when you submit a valid user ID and valid password.\n Using a web proxy, notice the information retrieved from this successful authentication (HTTP 200 Response, length of the response).\n Testing for Valid User with Wrong Password Now, the tester should try to insert a valid user ID and a wrong password and record the error message generated by the application.\n The browser should display a message similar to the following one:\nFigure 4.3.4-1: Authentication Failed\nUnlike any message that reveals the existence of the user like the following:\nLogin for User foo: invalid password\nUsing a web proxy, notice the information retrieved from this unsuccessful authentication attempt (HTTP 200 Response, length of the response).\n Testing for a Nonexistent Username Now, the tester should try to insert an invalid user ID and a wrong password and record the server answer (the tester should be confident that the username is not valid in the application). Record the error message and the server answer.\n If the tester enters a nonexistent user ID, they can receive a message similar to:\nFigure 4.3.4-3: This User is Not Active\nor a message like the following one:\nLogin failed for User foo: invalid Account\nGenerally the application should respond with the same error message and length to the different incorrect requests. If the responses are not the same, the tester should investigate and find out the key that creates a difference between the two responses. For example:\n Client request: Valid user/wrong password Server response: The password is not correct Client request: Wrong user/wrong password Server response: User not recognized  The above responses let the client understand that for the first request they have a valid username. So they can interact with the application requesting a set of possible user IDs and observing the answer.\nLooking at the second server response, the tester understand in the same way that they don\u0026rsquo;t hold a valid username. So they can interact in the same manner and create a list of valid user ID looking at the server answers.\n Other Ways to Enumerate Users Testers can enumerate users in several ways, such as:\nAnalyzing the Error Code Received on Login Pages Some web application release a specific error code or message that we can analyze.\nAnalyzing URLs and URLs Re-directions For example:\n http://www.foo.com/err.jsp?User=baduser\u0026amp;Error=0 http://www.foo.com/err.jsp?User=gooduser\u0026amp;Error=2  As is seen above, when a tester provides a user ID and password to the web application, they see a message indication that an error has occurred in the URL. In the first case they have provided a bad user ID and bad password. In the second, a good user ID and a bad password, so they can identify a valid user ID.\nURI Probing Sometimes a web server responds differently if it receives a request for an existing directory or not. For instance in some portals every user is associated with a directory. If testers try to access an existing directory they could receive a web server error.\nSome of the common errors received from web servers are:\n 403 Forbidden error code 404 Not found error code  Example:\n http://www.foo.com/account1 - we receive from web server: 403 Forbidden http://www.foo.com/account2 - we receive from web server: 404 file Not Found  In the first case the user exists, but the tester cannot view the web page, in second case instead the user \u0026ldquo;account2\u0026rdquo; does not exist. By collecting this information testers can enumerate the users.\nAnalyzing Web Page Titles Testers can receive useful information on Title of web page, where they can obtain a specific error code or messages that reveal if the problems are with the username or password.\nFor instance, if a user cannot authenticate to an application and receives a web page whose title is similar to:\n Invalid user Invalid authentication  Analyzing a Message Received from a Recovery Facility When we use a recovery facility (i.e. a forgotten password function) a vulnerable application might return a message that reveals if a username exists or not.\nFor example, messages similar to the following:\n Invalid username: email address is not valid or the specified user was not found. Valid username: Your password has been successfully sent to the email address you registered with.  Friendly 404 Error Message When we request a user within the directory that does not exist, we don\u0026rsquo;t always receive 404 error code. Instead, we may receive \u0026ldquo;200 ok\u0026rdquo; with an image, in this case we can assume that when we receive the specific image the user does not exist. This logic can be applied to other web server response; the trick is a good analysis of web server and web application messages.\nAnalyzing Response Times As well as looking at the content of the responses, the time that the response take should also be considered. Particularly where the request causes an interaction with an external service (such as sending a forgotten password email), this can add several hundred milliseconds to the response, which can be used to determine whether the requested user is valid.\nGuessing Users In some cases the user IDs are created with specific policies of administrator or company. For example we can view a user with a user ID created in sequential order:\nCN000100 CN000101 ... Sometimes the usernames are created with a REALM alias and then a sequential numbers:\n R1001 – user 001 for REALM1 R2001 – user 001 for REALM2  In the above sample we can create simple shell scripts that compose user IDs and submit a request with tool like wget to automate a web query to discern valid user IDs. To create a script we can also use Perl and curl.\nOther possibilities are: - user IDs associated with credit card numbers, or in general numbers with a pattern. - user IDs associated with real names, e.g. if Freddie Mercury has a user ID of \u0026ldquo;fmercury\u0026rdquo;, then you might guess Roger Taylor to have the user ID of \u0026ldquo;rtaylor\u0026rdquo;.\nAgain, we can guess a username from the information received from an LDAP query or from Google information gathering, for example, from a specific domain. Google can help to find domain users through specific queries or through a simple shell script or tool.\n By enumerating user accounts, you risk locking out accounts after a predefined number of failed probes (based on application policy). Also, sometimes, your IP address can be banned by dynamic rules on the application firewall or Intrusion Prevention System.\n Gray-Box Testing Testing for Authentication Error Messages Verify that the application answers in the same manner for every client request that produces a failed authentication. For this issue the black-box testing and gray-box testing have the same concept based on the analysis of messages or error codes received from web application.\n The application should answer in the same manner for every failed attempt of authentication.\nFor Example: Credentials submitted are not valid\n Remediation Ensure the application returns consistent generic error messages in response to invalid account name, password or other user credentials entered during the log in process.\nEnsure default system accounts and test accounts are deleted prior to releasing the system into production (or exposing it to an untrusted network).\nTools  OWASP Zed Attack Proxy (ZAP) curl PERL  References  Marco Mella, Sun Java Access \u0026amp; Identity Manager Users enumeration Username Enumeration Vulnerabilities  "
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/4-web_application_security_testing/03-identity_management_testing/05-testing_for_weak_or_unenforced_username_policy/",
	"title": "Testing for Weak or Unenforced Username Policy",
	"tags": [],
	"description": "",
	"content": "Testing for Weak or Unenforced Username Policy    ID     WSTG-IDNT-05    Summary User account names are often highly structured (e.g. Joe Bloggs account name is jbloggs and Fred Nurks account name is fnurks) and valid account names can easily be guessed.\nTest Objectives  Determine whether a consistent account name structure renders the application vulnerable to account enumeration. Determine whether the application\u0026rsquo;s error messages permit account enumeration.  How to Test  Determine the structure of account names. Evaluate the application\u0026rsquo;s response to valid and invalid account names. Use different responses to valid and invalid account names to enumerate valid account names. Use account name dictionaries to enumerate valid account names.  Remediation Ensure the application returns consistent generic error messages in response to invalid account name, password or other user credentials entered during the log in process.\n"
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://yuk1h1ra.github.io/owasp-wstg-ja/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]